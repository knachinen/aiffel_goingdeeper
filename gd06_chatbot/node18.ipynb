{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84501d60",
   "metadata": {},
   "source": [
    "평가문항\t상세기준\n",
    "\n",
    "1. 챗봇 훈련데이터 전처리 과정이 체계적으로 진행되었는가?\t\n",
    "> 챗봇 훈련데이터를 위한 전처리와 augmentation이 적절히 수행되어 3만개 가량의 훈련데이터셋이 구축되었다.\n",
    "\n",
    "2. transformer 모델을 활용한 챗봇 모델이 과적합을 피해 안정적으로 훈련되었는가?\t\n",
    "> 과적합을 피할 수 있는 하이퍼파라미터 셋이 적절히 제시되었다.\n",
    "\n",
    "3. 챗봇이 사용자의 질문에 그럴듯한 형태로 답하는 사례가 있는가?\n",
    "> 주어진 예문을 포함하여 챗봇에 던진 질문에 적절히 답하는 사례가 제출되었다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8c24bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일 저장 커스텀 모듈\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../custom\")\n",
    "\n",
    "from importlib import reload\n",
    "import custom_utils\n",
    "reload(custom_utils)\n",
    "\n",
    "from custom_utils import save_var, load_var\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f0fff27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import re\n",
    "import os\n",
    "import io\n",
    "import random\n",
    "import logging\n",
    "import math\n",
    "\n",
    "from tqdm import tqdm\n",
    "# from tqdm.notebook import tqdm\n",
    "\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from nltk.translate.bleu_score import SmoothingFunction\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "import sentencepiece as spm\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e7d9ae",
   "metadata": {},
   "source": [
    "# Step 1. 데이터 다운로드"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ca4b67",
   "metadata": {},
   "source": [
    "읽어 온 데이터의 질문과 답변을 각각 questions, answers 변수에 나눠서 저장하세요!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9bade0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/ChatbotData.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "fc3c440c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11823 entries, 0 to 11822\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Q       11823 non-null  object\n",
      " 1   A       11823 non-null  object\n",
      " 2   label   11823 non-null  int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 277.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f2fd62d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = df[\"Q\"]\n",
    "answers = df[\"A\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4a2c854e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'12시 땡!'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ae19a1e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'하루가 또 가네요.'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e68972d",
   "metadata": {},
   "source": [
    "# Step 2. 데이터 정제"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742ba1be",
   "metadata": {},
   "source": [
    "아래 조건을 만족하는 preprocess_sentence() 함수를 구현하세요.\n",
    "\n",
    "- 영문자의 경우, 모두 소문자로 변환합니다.\n",
    "- 영문자와 한글, 숫자, 그리고 주요 특수문자를 제외하곤 정규식을 활용하여 모두 제거합니다.\n",
    "\n",
    "문장부호 양옆에 공백을 추가하는 등 이전과 다르게 생략된 기능들은 우리가 사용할 토크나이저가 지원하기 때문에 굳이 구현하지 않아도 괜찮습니다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d89c870",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextCleaner:\n",
    "    def __init__(self):\n",
    "        self.punct_space_re = re.compile(r\"([?.!,])\")\n",
    "        self.multiple_spaces_re = re.compile(r'[\" \"]+')\n",
    "        self.allowed_chars_re = re.compile(r\"[^a-zA-Z가-힣?.!,]+\")\n",
    "        self.email_re = re.compile(r'([a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+)')\n",
    "        self.url_re = re.compile(r'(http|ftp|https)://(?:[-\\w.]|(?:%[\\da-fA-F]{2}))+')\n",
    "        self.korean_chars_re = re.compile(r'([ㄱ-ㅎㅏ-ㅣ]+)')\n",
    "        self.html_tag_re = re.compile(r'<[^>]*>')\n",
    "        self.special_chars_re = re.compile(r'[-=+,#/\\?:^$.@*\\\"※~&%ㆍ!』\\\\‘|\\(\\)\\[\\]\\<\\>`\\'…》]')\n",
    "        \n",
    "    def clean_text(self, text):\n",
    "        try:\n",
    "            text = text.strip().lower()\n",
    "            text = self.punct_space_re.sub(r\" \\1 \", text)\n",
    "            text = self.multiple_spaces_re.sub(\" \", text)\n",
    "            text = self.allowed_chars_re.sub(\" \", text)\n",
    "            text = self.email_re.sub(\"\", text)\n",
    "            text = self.url_re.sub(\"\", text)\n",
    "            text = self.korean_chars_re.sub(\"\", text)\n",
    "            text = self.html_tag_re.sub(\"\", text)\n",
    "            text = self.special_chars_re.sub(\"\", text)\n",
    "            text = text.replace('\\n', '.')\n",
    "            return text\n",
    "        except TypeError:\n",
    "            print(\"Warning: Input was not a string or bytes-like object.\")\n",
    "            print(text)\n",
    "            return text\n",
    "\n",
    "    # 데이터 정제\n",
    "    def clean_corpus(self, corpus):\n",
    "        \n",
    "        self.corpus_cleaned = []\n",
    "        \n",
    "        for sentence in corpus:\n",
    "            self.corpus_cleaned.append(self.clean_text(sentence))\n",
    "    \n",
    "        return self.corpus_cleaned\n",
    "\n",
    "    # get unique data for the corpus1 \n",
    "    def get_unique_corpus1(self, corpus1, corpus2):\n",
    "        seen_sentences = set()\n",
    "        unique_corpus1 = []\n",
    "        unique_corpus2 = []\n",
    "        original_length = len(corpus1)\n",
    "        for sent1, sent2 in zip(corpus1, corpus2):\n",
    "            sent1_str = ' '.join(sent1)\n",
    "            if sent1_str not in seen_sentences:\n",
    "                seen_sentences.add(sent1_str)\n",
    "                unique_corpus1.append(sent1)\n",
    "                unique_corpus2.append(sent2)\n",
    "        removed_length = original_length - len(unique_corpus1)\n",
    "        print(f\"removed: {removed_length}\")\n",
    "        return [unique_corpus1, unique_corpus2]\n",
    "\n",
    "\n",
    "    # get unique data for the corpus1,2\n",
    "    def get_unique_corpus_both(self, corpus):\n",
    "\n",
    "        self.unique_corpus = self.get_unique_corpus1(corpus[1], corpus[0])  # for corpus2.\n",
    "        self.unique_corpus = self.get_unique_corpus1(self.unique_corpus[1], self.unique_corpus[0])  # for corpus1.\n",
    "    \n",
    "        return self.unique_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3118ae71",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaner = TextCleaner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "df77991b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' 시 땡  ', ' 지망 학교 떨어졌어', ' 박 일 놀러가고 싶다']\n"
     ]
    }
   ],
   "source": [
    "tmp = cleaner.clean_corpus(df[\"Q\"].iloc[:3])\n",
    "print(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d9b52497",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Q_cleaned\"] = cleaner.clean_corpus(df[\"Q\"])\n",
    "df[\"A_cleaned\"] = cleaner.clean_corpus(df[\"A\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5b4f77dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11823 entries, 0 to 11822\n",
      "Data columns (total 5 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   Q          11823 non-null  object\n",
      " 1   A          11823 non-null  object\n",
      " 2   label      11823 non-null  int64 \n",
      " 3   Q_cleaned  11823 non-null  object\n",
      " 4   A_cleaned  11823 non-null  object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 462.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "de904880",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "      <th>label</th>\n",
       "      <th>Q_cleaned</th>\n",
       "      <th>A_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12시 땡!</td>\n",
       "      <td>하루가 또 가네요.</td>\n",
       "      <td>0</td>\n",
       "      <td>시 땡</td>\n",
       "      <td>하루가 또 가네요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1지망 학교 떨어졌어</td>\n",
       "      <td>위로해 드립니다.</td>\n",
       "      <td>0</td>\n",
       "      <td>지망 학교 떨어졌어</td>\n",
       "      <td>위로해 드립니다</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3박4일 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "      <td>박 일 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Q            A  label     Q_cleaned     A_cleaned\n",
       "0        12시 땡!   하루가 또 가네요.      0         시 땡     하루가 또 가네요  \n",
       "1   1지망 학교 떨어졌어    위로해 드립니다.      0    지망 학교 떨어졌어    위로해 드립니다  \n",
       "2  3박4일 놀러가고 싶다  여행은 언제나 좋죠.      0   박 일 놀러가고 싶다  여행은 언제나 좋죠  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea1ebd5",
   "metadata": {},
   "source": [
    "# Step 3. 데이터 토큰화"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4812b79e",
   "metadata": {},
   "source": [
    "토큰화에는 KoNLPy의 mecab 클래스를 사용합니다.  \n",
    "아래 조건을 만족하는 build_corpus() 함수를 구현하세요!  \n",
    "\n",
    "1. 소스 문장 데이터와 타겟 문장 데이터를 입력으로 받습니다.\n",
    "2. 데이터를 앞서 정의한 preprocess_sentence() 함수로 정제하고, 토큰화합니다.\n",
    "3. 토큰화는 전달받은 토크나이즈 함수를 사용합니다. 이번엔 mecab.morphs 함수를 전달하시면 됩니다.\n",
    "4. 토큰의 개수가 일정 길이 이상인 문장은 데이터에서 제외합니다.\n",
    "5. 중복되는 문장은 데이터에서 제외합니다. 소스 : 타겟 쌍을 비교하지 않고 소스는 소스대로 타겟은 타겟대로 검사합니다. 중복 쌍이 흐트러지지 않도록 유의하세요!\n",
    "\n",
    "구현한 함수를 활용하여 questions 와 answers 를 각각 que_corpus , ans_corpus 에 토큰화하여 저장합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd848c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Mecab\n",
    "\n",
    "mecab = Mecab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "28924329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['시', '땡']\n"
     ]
    }
   ],
   "source": [
    "res = mecab.morphs(tmp[0])\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96ced508",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokenized_sentence(sentence, tokenizer):\n",
    "    return tokenizer.morphs(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be0aebe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokenized_corpus(corpus, tokenizer):\n",
    "    corpus_tokenized = []\n",
    "    for sentence in corpus:\n",
    "        corpus_tokenized.append(get_tokenized_sentence(sentence, tokenizer))\n",
    "    return corpus_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7b75866",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_358/3627444872.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mque_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_tokenized_corpus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Q_cleaned\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmecab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mans_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_tokenized_corpus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"A_cleaned\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmecab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "que_tokens = get_tokenized_corpus(df[\"Q_cleaned\"], mecab)\n",
    "ans_tokens = get_tokenized_corpus(df[\"A_cleaned\"], mecab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "ca7943e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['시', '땡'],\n",
       " ['지망', '학교', '떨어졌', '어'],\n",
       " ['박', '일', '놀', '러', '가', '고', '싶', '다'],\n",
       " ['박', '일', '정도', '놀', '러', '가', '고', '싶', '다'],\n",
       " ['ppl', '심하', '네'],\n",
       " ['sd', '카드', '망가졌', '어'],\n",
       " ['sd', '카드', '안', '돼'],\n",
       " ['sns', '맞', '팔', '왜', '안', '하', '지'],\n",
       " ['sns', '시간', '낭비', '인', '거', '아', '는데', '매일', '하', '는', '중'],\n",
       " ['sns', '시간', '낭비', '인데', '자꾸', '보', '게', '됨']]"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "que_tokens[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d4cea7",
   "metadata": {},
   "source": [
    "### 토큰수 제한"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8e6f3437",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:, \"Q_length\"] = df[\"Q_tokenized\"].apply(lambda x: len(x))\n",
    "df.loc[:, \"A_length\"] = df[\"A_tokenized\"].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "443d24ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "      <th>label</th>\n",
       "      <th>Q_cleaned</th>\n",
       "      <th>A_cleaned</th>\n",
       "      <th>Q_tokenized</th>\n",
       "      <th>A_tokenized</th>\n",
       "      <th>Q_length</th>\n",
       "      <th>A_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12시 땡!</td>\n",
       "      <td>하루가 또 가네요.</td>\n",
       "      <td>0</td>\n",
       "      <td>시 땡</td>\n",
       "      <td>하루가 또 가네요</td>\n",
       "      <td>[시, 땡]</td>\n",
       "      <td>[하루, 가, 또, 가, 네요]</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1지망 학교 떨어졌어</td>\n",
       "      <td>위로해 드립니다.</td>\n",
       "      <td>0</td>\n",
       "      <td>지망 학교 떨어졌어</td>\n",
       "      <td>위로해 드립니다</td>\n",
       "      <td>[지망, 학교, 떨어졌, 어]</td>\n",
       "      <td>[위로, 해, 드립니다]</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3박4일 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "      <td>박 일 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠</td>\n",
       "      <td>[박, 일, 놀, 러, 가, 고, 싶, 다]</td>\n",
       "      <td>[여행, 은, 언제나, 좋, 죠]</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Q            A  label     Q_cleaned     A_cleaned  \\\n",
       "0        12시 땡!   하루가 또 가네요.      0         시 땡     하루가 또 가네요     \n",
       "1   1지망 학교 떨어졌어    위로해 드립니다.      0    지망 학교 떨어졌어    위로해 드립니다     \n",
       "2  3박4일 놀러가고 싶다  여행은 언제나 좋죠.      0   박 일 놀러가고 싶다  여행은 언제나 좋죠     \n",
       "\n",
       "                Q_tokenized         A_tokenized  Q_length  A_length  \n",
       "0                    [시, 땡]   [하루, 가, 또, 가, 네요]         2         5  \n",
       "1          [지망, 학교, 떨어졌, 어]       [위로, 해, 드립니다]         4         3  \n",
       "2  [박, 일, 놀, 러, 가, 고, 싶, 다]  [여행, 은, 언제나, 좋, 죠]         8         5  "
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "e52b161f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[\"label\"].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "45b708d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[\"Q_length\"].hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "754913df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[\"A_length\"].hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "68e5f692",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_org = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "63a27948",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_org.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c03a3d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"Q_length\"] < 20]\n",
    "df = df[df[\"A_length\"] < 20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f4df48f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 11687 entries, 0 to 11686\n",
      "Data columns (total 9 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   Q            11687 non-null  object\n",
      " 1   A            11687 non-null  object\n",
      " 2   label        11687 non-null  int64 \n",
      " 3   Q_cleaned    11687 non-null  object\n",
      " 4   A_cleaned    11687 non-null  object\n",
      " 5   Q_tokenized  11687 non-null  object\n",
      " 6   A_tokenized  11687 non-null  object\n",
      " 7   Q_length     11687 non-null  int64 \n",
      " 8   A_length     11687 non-null  int64 \n",
      "dtypes: int64(3), object(6)\n",
      "memory usage: 913.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e05b96e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[\"Q_length\"].hist(bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "eb5802f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[\"A_length\"].hist(bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "17adcb24",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "      <th>label</th>\n",
       "      <th>Q_cleaned</th>\n",
       "      <th>A_cleaned</th>\n",
       "      <th>Q_tokenized</th>\n",
       "      <th>A_tokenized</th>\n",
       "      <th>Q_length</th>\n",
       "      <th>A_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12시 땡!</td>\n",
       "      <td>하루가 또 가네요.</td>\n",
       "      <td>0</td>\n",
       "      <td>시 땡</td>\n",
       "      <td>하루가 또 가네요</td>\n",
       "      <td>[시, 땡]</td>\n",
       "      <td>[하루, 가, 또, 가, 네요]</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1지망 학교 떨어졌어</td>\n",
       "      <td>위로해 드립니다.</td>\n",
       "      <td>0</td>\n",
       "      <td>지망 학교 떨어졌어</td>\n",
       "      <td>위로해 드립니다</td>\n",
       "      <td>[지망, 학교, 떨어졌, 어]</td>\n",
       "      <td>[위로, 해, 드립니다]</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3박4일 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "      <td>박 일 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠</td>\n",
       "      <td>[박, 일, 놀, 러, 가, 고, 싶, 다]</td>\n",
       "      <td>[여행, 은, 언제나, 좋, 죠]</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3박4일 정도 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "      <td>박 일 정도 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠</td>\n",
       "      <td>[박, 일, 정도, 놀, 러, 가, 고, 싶, 다]</td>\n",
       "      <td>[여행, 은, 언제나, 좋, 죠]</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PPL 심하네</td>\n",
       "      <td>눈살이 찌푸려지죠.</td>\n",
       "      <td>0</td>\n",
       "      <td>ppl 심하네</td>\n",
       "      <td>눈살이 찌푸려지죠</td>\n",
       "      <td>[ppl, 심하, 네]</td>\n",
       "      <td>[눈살, 이, 찌푸려, 지, 죠]</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SD카드 망가졌어</td>\n",
       "      <td>다시 새로 사는 게 마음 편해요.</td>\n",
       "      <td>0</td>\n",
       "      <td>sd카드 망가졌어</td>\n",
       "      <td>다시 새로 사는 게 마음 편해요</td>\n",
       "      <td>[sd, 카드, 망가졌, 어]</td>\n",
       "      <td>[다시, 새로, 사, 는, 게, 마음, 편해요]</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SD카드 안돼</td>\n",
       "      <td>다시 새로 사는 게 마음 편해요.</td>\n",
       "      <td>0</td>\n",
       "      <td>sd카드 안돼</td>\n",
       "      <td>다시 새로 사는 게 마음 편해요</td>\n",
       "      <td>[sd, 카드, 안, 돼]</td>\n",
       "      <td>[다시, 새로, 사, 는, 게, 마음, 편해요]</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SNS 맞팔 왜 안하지ㅠㅠ</td>\n",
       "      <td>잘 모르고 있을 수도 있어요.</td>\n",
       "      <td>0</td>\n",
       "      <td>sns 맞팔 왜 안하지</td>\n",
       "      <td>잘 모르고 있을 수도 있어요</td>\n",
       "      <td>[sns, 맞, 팔, 왜, 안, 하, 지]</td>\n",
       "      <td>[잘, 모르, 고, 있, 을, 수, 도, 있, 어요]</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SNS 시간낭비인 거 아는데 매일 하는 중</td>\n",
       "      <td>시간을 정하고 해보세요.</td>\n",
       "      <td>0</td>\n",
       "      <td>sns 시간낭비인 거 아는데 매일 하는 중</td>\n",
       "      <td>시간을 정하고 해보세요</td>\n",
       "      <td>[sns, 시간, 낭비, 인, 거, 아, 는데, 매일, 하, 는, 중]</td>\n",
       "      <td>[시간, 을, 정하, 고, 해, 보, 세요]</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SNS 시간낭비인데 자꾸 보게됨</td>\n",
       "      <td>시간을 정하고 해보세요.</td>\n",
       "      <td>0</td>\n",
       "      <td>sns 시간낭비인데 자꾸 보게됨</td>\n",
       "      <td>시간을 정하고 해보세요</td>\n",
       "      <td>[sns, 시간, 낭비, 인데, 자꾸, 보, 게, 됨]</td>\n",
       "      <td>[시간, 을, 정하, 고, 해, 보, 세요]</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Q                   A  label  \\\n",
       "0                   12시 땡!          하루가 또 가네요.      0   \n",
       "1              1지망 학교 떨어졌어           위로해 드립니다.      0   \n",
       "2             3박4일 놀러가고 싶다         여행은 언제나 좋죠.      0   \n",
       "3          3박4일 정도 놀러가고 싶다         여행은 언제나 좋죠.      0   \n",
       "4                  PPL 심하네          눈살이 찌푸려지죠.      0   \n",
       "5                SD카드 망가졌어  다시 새로 사는 게 마음 편해요.      0   \n",
       "6                  SD카드 안돼  다시 새로 사는 게 마음 편해요.      0   \n",
       "7           SNS 맞팔 왜 안하지ㅠㅠ    잘 모르고 있을 수도 있어요.      0   \n",
       "8  SNS 시간낭비인 거 아는데 매일 하는 중       시간을 정하고 해보세요.      0   \n",
       "9        SNS 시간낭비인데 자꾸 보게됨       시간을 정하고 해보세요.      0   \n",
       "\n",
       "                 Q_cleaned            A_cleaned  \\\n",
       "0                    시 땡            하루가 또 가네요     \n",
       "1               지망 학교 떨어졌어           위로해 드립니다     \n",
       "2              박 일 놀러가고 싶다         여행은 언제나 좋죠     \n",
       "3           박 일 정도 놀러가고 싶다         여행은 언제나 좋죠     \n",
       "4                  ppl 심하네          눈살이 찌푸려지죠     \n",
       "5                sd카드 망가졌어  다시 새로 사는 게 마음 편해요     \n",
       "6                  sd카드 안돼  다시 새로 사는 게 마음 편해요     \n",
       "7            sns 맞팔 왜 안하지     잘 모르고 있을 수도 있어요     \n",
       "8  sns 시간낭비인 거 아는데 매일 하는 중       시간을 정하고 해보세요     \n",
       "9        sns 시간낭비인데 자꾸 보게됨       시간을 정하고 해보세요     \n",
       "\n",
       "                               Q_tokenized                    A_tokenized  \\\n",
       "0                                   [시, 땡]              [하루, 가, 또, 가, 네요]   \n",
       "1                         [지망, 학교, 떨어졌, 어]                  [위로, 해, 드립니다]   \n",
       "2                 [박, 일, 놀, 러, 가, 고, 싶, 다]             [여행, 은, 언제나, 좋, 죠]   \n",
       "3             [박, 일, 정도, 놀, 러, 가, 고, 싶, 다]             [여행, 은, 언제나, 좋, 죠]   \n",
       "4                             [ppl, 심하, 네]             [눈살, 이, 찌푸려, 지, 죠]   \n",
       "5                         [sd, 카드, 망가졌, 어]     [다시, 새로, 사, 는, 게, 마음, 편해요]   \n",
       "6                           [sd, 카드, 안, 돼]     [다시, 새로, 사, 는, 게, 마음, 편해요]   \n",
       "7                  [sns, 맞, 팔, 왜, 안, 하, 지]  [잘, 모르, 고, 있, 을, 수, 도, 있, 어요]   \n",
       "8  [sns, 시간, 낭비, 인, 거, 아, 는데, 매일, 하, 는, 중]       [시간, 을, 정하, 고, 해, 보, 세요]   \n",
       "9           [sns, 시간, 낭비, 인데, 자꾸, 보, 게, 됨]       [시간, 을, 정하, 고, 해, 보, 세요]   \n",
       "\n",
       "   Q_length  A_length  \n",
       "0         2         5  \n",
       "1         4         3  \n",
       "2         8         5  \n",
       "3         9         5  \n",
       "4         3         5  \n",
       "5         4         7  \n",
       "6         4         7  \n",
       "7         7         9  \n",
       "8        11         7  \n",
       "9         8         7  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "08b4974f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "      <th>label</th>\n",
       "      <th>Q_cleaned</th>\n",
       "      <th>A_cleaned</th>\n",
       "      <th>Q_tokenized</th>\n",
       "      <th>A_tokenized</th>\n",
       "      <th>Q_length</th>\n",
       "      <th>A_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Q, A, label, Q_cleaned, A_cleaned, Q_tokenized, A_tokenized, Q_length, A_length]\n",
       "Index: []"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"Q\"].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d06fd92e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 11687 entries, 0 to 11686\n",
      "Data columns (total 9 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   Q            11687 non-null  object\n",
      " 1   A            11687 non-null  object\n",
      " 2   label        11687 non-null  int64 \n",
      " 3   Q_cleaned    11687 non-null  object\n",
      " 4   A_cleaned    11687 non-null  object\n",
      " 5   Q_tokenized  11687 non-null  object\n",
      " 6   A_tokenized  11687 non-null  object\n",
      " 7   Q_length     11687 non-null  int64 \n",
      " 8   A_length     11687 non-null  int64 \n",
      "dtypes: int64(3), object(6)\n",
      "memory usage: 913.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ab1afd11",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "dc14531a",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_var(df, \"df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f242be6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_var(\"df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7941ba4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f787127c",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = df[\"Q_tokenized\"]\n",
    "answers = df[\"A_tokenized\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eadece2",
   "metadata": {},
   "source": [
    "# Step 4. Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c23b3bd",
   "metadata": {},
   "source": [
    "우리에게 주어진 데이터는 1만 개가량으로 적은 편에 속합니다.   \n",
    "이럴 때에 사용할 수 있는 테크닉을 배웠으니 활용해 봐야겠죠?   \n",
    "Lexical Substitution을 실제로 적용해 보도록 하겠습니다.  \n",
    "\n",
    "아래 링크를 참고하여 한국어로 사전 훈련된 Embedding 모델을 다운로드합니다.   \n",
    "Korean (w) 가 Word2Vec으로 학습한 모델이며 용량도 적당하므로 사이트에서 Korean (w)를 찾아 다운로드하고, ko.bin 파일을 얻으세요!  \n",
    "\n",
    "Kyubyong/wordvectors  \n",
    "\n",
    "다운로드한 모델을 활용해 데이터를 Augmentation 하세요! 앞서 정의한 lexical_sub() 함수를 참고하면 도움이 많이 될 겁니다.  \n",
    "\n",
    "Augmentation된 que_corpus 와 원본 ans_corpus 가 병렬을 이루도록,   \n",
    "이후엔 반대로 원본 que_corpus 와 Augmentation된 ans_corpus 가 병렬을 이루도록 하여 전체 데이터가 원래의 3배가량으로 늘어나도록 합니다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7a1da427",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "47ccd959",
   "metadata": {},
   "outputs": [],
   "source": [
    "wv = Word2Vec.load(\"./data/word2vec_ko.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "c4716523",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('사본', 0.838905930519104),\n",
       " ('원문', 0.809522807598114),\n",
       " ('본문', 0.7485238909721375),\n",
       " ('필사본', 0.743165910243988),\n",
       " ('복사본', 0.7308973073959351),\n",
       " ('판본', 0.7296765446662903),\n",
       " ('인쇄물', 0.68619704246521),\n",
       " ('번역본', 0.6790832281112671),\n",
       " ('대본', 0.6752506494522095),\n",
       " ('문헌', 0.6715538501739502)]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.wv.most_similar(\"원본\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd6302ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lexical_sub(sentence, wv, sentence_num=2, verbose=False):\n",
    "    if verbose: print(sentence)\n",
    "        \n",
    "    sentences = []\n",
    "    for _ in range(sentence_num):\n",
    "        sentences.append(\" \".join(sentence).split())  # to avoid overwriting the sentence\n",
    "    \n",
    "    if not sentences[0]: return None\n",
    "    \n",
    "#     res = mecab.pos(\" \".join(sentence))\n",
    "#     if verbose: print(res)\n",
    "#     indices_exchange = [i for i, word in enumerate(res) if word[1] in [\"NNG\", \"VV\", \"VV+EP\"]]\n",
    "#     if verbose: print(indices_exchange, end=' --> ')        \n",
    "#     random.shuffle(indices_exchange)\n",
    "#     unique_indices = indices_exchange[:sentence_num]\n",
    "#     if verbose: print(indices_exchange, unique_indices)\n",
    "\n",
    "    indices = list(range(len(sentence)))\n",
    "    random.shuffle(indices)    \n",
    "    unique_indices = indices[:sentence_num]\n",
    "\n",
    "    for i, index in enumerate(unique_indices):\n",
    "        word = sentences[i][index]\n",
    "        if word in wv:\n",
    "            similar_word = wv.most_similar(word)\n",
    "            if not similar_word:\n",
    "                return None\n",
    "            if verbose: print(similar_word[0][0], end=\", \")\n",
    "\n",
    "            word_sub = similar_word[0][0]\n",
    "            sentences[i][index] = word_sub\n",
    "    \n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6220931c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['나', '만', '일시', '켜', '서', '짜증', '폭발']\n",
      "이상, 든, [['나', '이상', '일시', '켜', '서', '짜증', '폭발'], ['든', '만', '일시', '켜', '서', '짜증', '폭발']]\n"
     ]
    }
   ],
   "source": [
    "res = lexical_sub(questions[633], wv.wv, sentence_num=2, verbose=True)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b6832e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "74cafe76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11687 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "corpus_aug = []\n",
    "count_none = 0\n",
    "\n",
    "for que, ans in tqdm(zip(questions, answers), total=len(questions)):\n",
    "    corpus_aug.append((que, ans))\n",
    "    sentences = lexical_sub(que, wv.wv, sentence_num=1)\n",
    "    for sentence in sentences:\n",
    "        if sentence is not None: \n",
    "            corpus_aug.append((sentence, ans))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "b9626eb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba7ba6cc309a431685f20af404a315b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11687 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "corpus_aug = []\n",
    "count_none = 0\n",
    "\n",
    "for que, ans in tqdm(zip(que_tokens, ans_tokens), total=len(que_tokens)):\n",
    "    corpus_aug.append((que, ans))\n",
    "    sentences = lexical_sub(que, wv.wv, sentence_num=2)\n",
    "    for sentence in sentences:\n",
    "        if sentence is not None: \n",
    "            corpus_aug.append((sentence, ans))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "5e9b4634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35061\n",
      " 0 ['시', '땡']\n",
      " 1 ['시', '돌이']\n",
      " 2 ['시경', '땡']\n",
      " 3 ['지망', '학교', '떨어졌', '어']\n",
      " 4 ['전업', '학교', '떨어졌', '어']\n",
      " 5 ['지망', '학교', '떨어졌', '어서']\n",
      " 6 ['박', '일', '놀', '러', '가', '고', '싶', '다']\n",
      " 7 ['김', '일', '놀', '러', '가', '고', '싶', '다']\n",
      " 8 ['박', '일', '놀', '러', '가', '고', '싶', '는데']\n",
      " 9 ['박', '일', '정도', '놀', '러', '가', '고', '싶', '다']\n",
      "10 ['박', '일', '정도', '놀', '러', '가', '고', '싶', '는데']\n",
      "11 ['박', '월', '정도', '놀', '러', '가', '고', '싶', '다']\n"
     ]
    }
   ],
   "source": [
    "print(len(corpus_aug))\n",
    "for index, sentence in enumerate(corpus_aug):\n",
    "    print(f\"{index:2}\", sentence[0])\n",
    "    if index > 10: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "36fb1ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_var(corpus_aug, \"corpus_aug_x2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "75bd7c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_aug = load_var(\"corpus_aug_x3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500acba3",
   "metadata": {},
   "source": [
    "### 중복 데이터 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9c7d5457",
   "metadata": {},
   "outputs": [],
   "source": [
    "que_corpus, ans_corpus = zip(*corpus_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d5d979",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_var(que_corpus, \"que_corpus_x2\")\n",
    "save_var(ans_corpus, \"ans_corpus_x2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0e2593c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "que_corpus = load_var(\"que_corpus_x3\")\n",
    "ans_corpus = load_var(\"ans_corpus_x3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8c4df968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['시', '땡'], ['시', '돌이'], ['시경', '땡'])\n",
      "(['하루', '가', '또', '가', '네요'], ['하루', '가', '또', '가', '네요'], ['하루', '가', '또', '가', '네요'])\n"
     ]
    }
   ],
   "source": [
    "print(que_corpus[:3])\n",
    "print(ans_corpus[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "90b7b2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corpus = pd.DataFrame({'questions': que_corpus, 'answers': ans_corpus})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "c927f8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corpus[\"questions\"] = df_corpus[\"questions\"].apply(tuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ac915d16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>questions</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(시, 땡)</td>\n",
       "      <td>[하루, 가, 또, 가, 네요]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(시, 돌이)</td>\n",
       "      <td>[하루, 가, 또, 가, 네요]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(시경, 땡)</td>\n",
       "      <td>[하루, 가, 또, 가, 네요]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  questions            answers\n",
       "0    (시, 땡)  [하루, 가, 또, 가, 네요]\n",
       "1   (시, 돌이)  [하루, 가, 또, 가, 네요]\n",
       "2   (시경, 땡)  [하루, 가, 또, 가, 네요]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_corpus.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "90344a94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>questions</th>\n",
       "      <th>answers</th>\n",
       "      <th>target_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [questions, answers, target_tokens]\n",
       "Index: []"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_corpus[df_corpus.duplicated(subset=['questions'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "da71a618",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corpus = df_corpus.drop_duplicates(subset=\"questions\", keep=\"first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "8e7d7a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corpus_copy = df_corpus.copy()\n",
    "df_corpus_copy[\"questions\"] = df_corpus_copy[\"questions\"].apply(list)\n",
    "df_corpus = df_corpus.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d27e44",
   "metadata": {},
   "source": [
    "# Step 5. 데이터 벡터화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fbf7e3d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<start>', '12', '시', '땡', '!', '<end>']\n"
     ]
    }
   ],
   "source": [
    "sample_data = [\"12\", \"시\", \"땡\", \"!\"]\n",
    "\n",
    "print([\"<start>\"] + sample_data + [\"<end>\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b7d2db",
   "metadata": {},
   "source": [
    "1. 위 소스를 참고하여 타겟 데이터 전체에 <start> 토큰과 <end> 토큰을 추가해 주세요!   \n",
    "\n",
    "챗봇 훈련 데이터의 가장 큰 특징 중 하나라고 하자면 바로 소스 데이터와 타겟 데이터가 같은 언어를 사용한다는 것이겠죠.  \n",
    "앞서 배운 것처럼 이는 Embedding 층을 공유했을 때 많은 이점을 얻을 수 있습니다.  \n",
    "\n",
    "2. 특수 토큰을 더함으로써 ans_corpus 또한 완성이 되었으니, que_corpus 와 결합하여 전체 데이터에 대한 단어 사전을 구축하고 벡터화하여 enc_train 과 dec_train 을 얻으세요!  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fbc60641",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf158bc9",
   "metadata": {},
   "source": [
    "### df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "5059aef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corpus_copy = df_corpus.copy()\n",
    "df_corpus_copy[\"target_tokens\"] = [[\"<start>\"] + s + [\"<end>\"] for s in df_corpus_copy[\"answers\"]]\n",
    "df_corpus = df_corpus_copy.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "b2562f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corpus[\"questions\"] = df_corpus[\"questions\"].apply(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "1a8c4ba1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>questions</th>\n",
       "      <th>answers</th>\n",
       "      <th>target_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['시', '땡']</td>\n",
       "      <td>['하루', '가', '또', '가', '네요']</td>\n",
       "      <td>['&lt;start&gt;', '하루', '가', '또', '가', '네요', '&lt;end&gt;']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['시', '돌이']</td>\n",
       "      <td>['하루', '가', '또', '가', '네요']</td>\n",
       "      <td>['&lt;start&gt;', '하루', '가', '또', '가', '네요', '&lt;end&gt;']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['앵커', '심상소학교', '떨어졌', '어']</td>\n",
       "      <td>['위로', '해', '드립니다']</td>\n",
       "      <td>['&lt;start&gt;', '위로', '해', '드립니다', '&lt;end&gt;']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     questions                      answers  \\\n",
       "0                   ['시', '땡']  ['하루', '가', '또', '가', '네요']   \n",
       "1                  ['시', '돌이']  ['하루', '가', '또', '가', '네요']   \n",
       "2  ['앵커', '심상소학교', '떨어졌', '어']          ['위로', '해', '드립니다']   \n",
       "\n",
       "                                     target_tokens  \n",
       "0  ['<start>', '하루', '가', '또', '가', '네요', '<end>']  \n",
       "1  ['<start>', '하루', '가', '또', '가', '네요', '<end>']  \n",
       "2          ['<start>', '위로', '해', '드립니다', '<end>']  "
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_corpus.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "84ca9c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corpus.to_csv(\"df_corpus_x2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "a8f180a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corpus = pd.read_csv(\"df_corpus_x3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "6a5cba17",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_var(df_corpus, \"df_corpus_x2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f5c04aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corpus = load_var(\"df_corpus_x3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "9a8b640b",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_corpus = df_corpus[\"questions\"].to_list() + df_corpus[\"target_tokens\"].to_list()\n",
    "\n",
    "tokenizer = Tokenizer(filters=\"\", lower=False, oov_token=\"<unk>\")\n",
    "tokenizer.fit_on_texts(total_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3a6bfaa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7164"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "f29c81b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "que_seqs = tokenizer.texts_to_sequences(df_corpus[\"questions\"])\n",
    "ans_seqs = tokenizer.texts_to_sequences(df_corpus[\"target_tokens\"])\n",
    "\n",
    "enc_train = pad_sequences(que_seqs, padding=\"post\")\n",
    "dec_train = pad_sequences(ans_seqs, padding=\"post\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976a00d8",
   "metadata": {},
   "source": [
    "### list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7b89bdb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['<start>', '시', '땡', '<end>'],\n",
       " ['<start>', '시', '돌이', '<end>'],\n",
       " ['<start>', '앵커', '심상소학교', '떨어졌', '어', '<end>']]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgt_tokens = [[\"<start>\"] + s + [\"<end>\"] for s in que_corpus]\n",
    "tgt_tokens[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a504a39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_var(tgt_tokens, \"tgt_tokens_x2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9d74b69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tgt_tokens = load_var(\"tgt_tokens_x3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "39f1456c",
   "metadata": {},
   "outputs": [],
   "source": [
    "que_corpus = list(que_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5320bda3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['<start>', '시', '땡', '<end>'], ['<start>', '시', '돌이', '<end>'], ['<start>', '시경', '땡', '<end>']]\n"
     ]
    }
   ],
   "source": [
    "print(tgt_tokens[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "70d4c6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_corpus = que_corpus + tgt_tokens\n",
    "\n",
    "tokenizer = Tokenizer(filters=\"\", lower=False, oov_token=\"<unk>\")\n",
    "tokenizer.fit_on_texts(total_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2c4b2162",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7164"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "015a9b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "que_seqs = tokenizer.texts_to_sequences(que_corpus)\n",
    "ans_seqs = tokenizer.texts_to_sequences(tgt_tokens)\n",
    "\n",
    "enc_train = pad_sequences(que_seqs, padding=\"post\")\n",
    "dec_train = pad_sequences(ans_seqs, padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "55afbe02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[979, 5225], [979, 6164], [3431, 5225]]\n",
      "\n",
      "[[2, 979, 5225, 3], [2, 979, 6164, 3], [2, 3431, 5225, 3]]\n"
     ]
    }
   ],
   "source": [
    "print(que_seqs[:3])\n",
    "print()\n",
    "print(ans_seqs[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "73d16693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 979 5225    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0]\n",
      " [ 979 6164    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0]\n",
      " [3431 5225    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0]]\n",
      "\n",
      "[[   2  979 5225    3    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0]\n",
      " [   2  979 6164    3    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0]\n",
      " [   2 3431 5225    3    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0]]\n"
     ]
    }
   ],
   "source": [
    "print(enc_train[:3])\n",
    "print()\n",
    "print(dec_train[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f14f3b91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('<start>', '<end>')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.index_word[2], tokenizer.index_word[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5b8d35c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35061"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(enc_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0070bfba",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_var(enc_train, \"enc_train_t7\")\n",
    "save_var(dec_train, \"dec_train_t7\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "44eaaf05",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_train = load_var(\"enc_train\")\n",
    "dec_train = load_var(\"dec_train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9cfde34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((enc_train, dec_train)).batch(batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9b7ed5",
   "metadata": {},
   "source": [
    "# Step 6. 훈련하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eacc33ab",
   "metadata": {},
   "source": [
    "## transformer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e70bd92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def positional_encoding(pos, d_model):\n",
    "    def cal_angle(position, i):\n",
    "        return position / np.power(10000, (2*(i//2)) / np.float32(d_model))\n",
    "\n",
    "    def get_posi_angle_vec(position):\n",
    "        return [cal_angle(position, i) for i in range(d_model)]\n",
    "\n",
    "    sinusoid_table = np.array([get_posi_angle_vec(pos_i) for pos_i in range(pos)])\n",
    "\n",
    "    sinusoid_table[:, 0::2] = np.sin(sinusoid_table[:, 0::2])\n",
    "    sinusoid_table[:, 1::2] = np.cos(sinusoid_table[:, 1::2])\n",
    "\n",
    "    return sinusoid_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "869b9f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_padding_mask(seq):\n",
    "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "    return seq[:, tf.newaxis, tf.newaxis, :]\n",
    "\n",
    "def generate_lookahead_mask(size):\n",
    "    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
    "    return mask\n",
    "\n",
    "def generate_masks(src, tgt):\n",
    "    enc_mask = generate_padding_mask(src)\n",
    "    dec_enc_mask = generate_padding_mask(src)\n",
    "\n",
    "    dec_lookahead_mask = generate_lookahead_mask(tgt.shape[1])\n",
    "    dec_tgt_padding_mask = generate_padding_mask(tgt)\n",
    "    dec_mask = tf.maximum(dec_tgt_padding_mask, dec_lookahead_mask)\n",
    "\n",
    "    return enc_mask, dec_enc_mask, dec_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d78f34f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "        \n",
    "        self.depth = d_model // self.num_heads\n",
    "        \n",
    "        self.W_q = tf.keras.layers.Dense(d_model)\n",
    "        self.W_k = tf.keras.layers.Dense(d_model)\n",
    "        self.W_v = tf.keras.layers.Dense(d_model)\n",
    "        \n",
    "        self.linear = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "    def scaled_dot_product_attention(self, Q, K, V, mask):\n",
    "        d_k = tf.cast(K.shape[-1], tf.float32)\n",
    "        QK = tf.matmul(Q, K, transpose_b=True)\n",
    "\n",
    "        scaled_qk = QK / tf.math.sqrt(d_k)\n",
    "\n",
    "        if mask is not None: scaled_qk += (mask * -1e9)  \n",
    "\n",
    "        attentions = tf.nn.softmax(scaled_qk, axis=-1)\n",
    "        out = tf.matmul(attentions, V)\n",
    "\n",
    "        return out, attentions\n",
    "        \n",
    "\n",
    "    def split_heads(self, x):\n",
    "        bsz = x.shape[0]\n",
    "        split_x = tf.reshape(x, (bsz, -1, self.num_heads, self.depth))\n",
    "        split_x = tf.transpose(split_x, perm=[0, 2, 1, 3])\n",
    "\n",
    "        return split_x\n",
    "\n",
    "    def combine_heads(self, x):\n",
    "        bsz = x.shape[0]\n",
    "        combined_x = tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "        combined_x = tf.reshape(combined_x, (bsz, -1, self.d_model))\n",
    "\n",
    "        return combined_x\n",
    "\n",
    "    \n",
    "    def call(self, Q, K, V, mask):\n",
    "        WQ = self.W_q(Q)\n",
    "        WK = self.W_k(K)\n",
    "        WV = self.W_v(V)\n",
    "        \n",
    "        WQ_splits = self.split_heads(WQ)\n",
    "        WK_splits = self.split_heads(WK)\n",
    "        WV_splits = self.split_heads(WV)\n",
    "        \n",
    "        out, attention_weights = self.scaled_dot_product_attention(\n",
    "            WQ_splits, WK_splits, WV_splits, mask)\n",
    "                        \n",
    "        out = self.combine_heads(out)\n",
    "        out = self.linear(out)\n",
    "            \n",
    "        return out, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "67b3d02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PoswiseFeedForwardNet(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, d_ff):\n",
    "        super(PoswiseFeedForwardNet, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.d_ff = d_ff\n",
    "\n",
    "        self.fc1 = tf.keras.layers.Dense(d_ff, activation='relu')\n",
    "        self.fc2 = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "    def call(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.fc2(out)\n",
    "            \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "884ef9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, n_heads, d_ff, dropout):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "\n",
    "        self.enc_self_attn = MultiHeadAttention(d_model, n_heads)\n",
    "        self.ffn = PoswiseFeedForwardNet(d_model, d_ff)\n",
    "\n",
    "        self.norm_1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.norm_2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.do = tf.keras.layers.Dropout(dropout)\n",
    "        \n",
    "    def call(self, x, mask):\n",
    "        '''\n",
    "        Multi-Head Attention\n",
    "        '''\n",
    "        residual = x\n",
    "        out = self.norm_1(x)\n",
    "        out, enc_attn = self.enc_self_attn(out, out, out, mask)\n",
    "        out = self.do(out)\n",
    "        out += residual\n",
    "        \n",
    "        '''\n",
    "        Position-Wise Feed Forward Network\n",
    "        '''\n",
    "        residual = out\n",
    "        out = self.norm_2(out)\n",
    "        out = self.ffn(out)\n",
    "        out = self.do(out)\n",
    "        out += residual\n",
    "        \n",
    "        return out, enc_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "919474cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "\n",
    "        self.dec_self_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.enc_dec_attn = MultiHeadAttention(d_model, num_heads)\n",
    "\n",
    "        self.ffn = PoswiseFeedForwardNet(d_model, d_ff)\n",
    "\n",
    "        self.norm_1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.norm_2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.norm_3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.do = tf.keras.layers.Dropout(dropout)\n",
    "    \n",
    "    def call(self, x, enc_out, dec_enc_mask, padding_mask):\n",
    "        '''\n",
    "        Masked Multi-Head Attention\n",
    "        '''\n",
    "        residual = x\n",
    "        out = self.norm_1(x)\n",
    "        out, dec_attn = self.dec_self_attn(out, out, out, padding_mask)\n",
    "        out = self.do(out)\n",
    "        out += residual\n",
    "\n",
    "        '''\n",
    "        Multi-Head Attention\n",
    "        '''\n",
    "        residual = out\n",
    "        out = self.norm_2(out)\n",
    "        # Q, K, V 순서에 주의하세요!\n",
    "        out, dec_enc_attn = self.enc_dec_attn(Q=out, K=enc_out, V=enc_out, mask=dec_enc_mask)\n",
    "        out = self.do(out)\n",
    "        out += residual\n",
    "        \n",
    "        '''\n",
    "        Position-Wise Feed Forward Network\n",
    "        '''\n",
    "        residual = out\n",
    "        out = self.norm_3(out)\n",
    "        out = self.ffn(out)\n",
    "        out = self.do(out)\n",
    "        out += residual\n",
    "\n",
    "        return out, dec_attn, dec_enc_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "982cdc9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self,\n",
    "                    n_layers,\n",
    "                    d_model,\n",
    "                    n_heads,\n",
    "                    d_ff,\n",
    "                    dropout):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.enc_layers = [EncoderLayer(d_model, n_heads, d_ff, dropout) \n",
    "                        for _ in range(n_layers)]\n",
    "    \n",
    "        self.do = tf.keras.layers.Dropout(dropout)\n",
    "        \n",
    "    def call(self, x, mask):\n",
    "        out = x\n",
    "    \n",
    "        enc_attns = list()\n",
    "        for i in range(self.n_layers):\n",
    "            out, enc_attn = self.enc_layers[i](out, mask)\n",
    "            enc_attns.append(enc_attn)\n",
    "        \n",
    "        return out, enc_attns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "49c938e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self,\n",
    "                    n_layers,\n",
    "                    d_model,\n",
    "                    n_heads,\n",
    "                    d_ff,\n",
    "                    dropout):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.dec_layers = [DecoderLayer(d_model, n_heads, d_ff, dropout) \n",
    "                            for _ in range(n_layers)]\n",
    "                            \n",
    "    def call(self, x, enc_out, dec_enc_mask, padding_mask):\n",
    "        out = x\n",
    "    \n",
    "        dec_attns = list()\n",
    "        dec_enc_attns = list()\n",
    "        for i in range(self.n_layers):\n",
    "            out, dec_attn, dec_enc_attn = \\\n",
    "            self.dec_layers[i](out, enc_out, dec_enc_mask, padding_mask)\n",
    "\n",
    "            dec_attns.append(dec_attn)\n",
    "            dec_enc_attns.append(dec_enc_attn)\n",
    "\n",
    "        return out, dec_attns, dec_enc_attns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f5dd8b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "    def __init__(self,\n",
    "                    n_layers,\n",
    "                    d_model,\n",
    "                    n_heads,\n",
    "                    d_ff,\n",
    "                    src_vocab_size,\n",
    "                    tgt_vocab_size,\n",
    "                    pos_len,\n",
    "                    dropout=0.2,\n",
    "                    shared_fc=True,\n",
    "                    shared_emb=False):\n",
    "        super(Transformer, self).__init__()\n",
    "        \n",
    "        self.d_model = tf.cast(d_model, tf.float32)\n",
    "\n",
    "        if shared_emb:\n",
    "            self.enc_emb = self.dec_emb = \\\n",
    "            tf.keras.layers.Embedding(src_vocab_size, d_model)\n",
    "        else:\n",
    "            self.enc_emb = tf.keras.layers.Embedding(src_vocab_size, d_model)\n",
    "            self.dec_emb = tf.keras.layers.Embedding(tgt_vocab_size, d_model)\n",
    "\n",
    "        self.pos_encoding = positional_encoding(pos_len, d_model)\n",
    "        self.do = tf.keras.layers.Dropout(dropout)\n",
    "\n",
    "        self.encoder = Encoder(n_layers, d_model, n_heads, d_ff, dropout)\n",
    "        self.decoder = Decoder(n_layers, d_model, n_heads, d_ff, dropout)\n",
    "\n",
    "        self.fc = tf.keras.layers.Dense(tgt_vocab_size)\n",
    "\n",
    "        self.shared_fc = shared_fc\n",
    "\n",
    "        if shared_fc:\n",
    "            self.fc.set_weights(tf.transpose(self.dec_emb.weights))\n",
    "\n",
    "    def embedding(self, emb, x):\n",
    "        seq_len = x.shape[1]\n",
    "\n",
    "        out = emb(x)\n",
    "\n",
    "        if self.shared_fc: out *= tf.math.sqrt(self.d_model)\n",
    "\n",
    "        out += self.pos_encoding[np.newaxis, ...][:, :seq_len, :]\n",
    "        out = self.do(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "        \n",
    "    def call(self, enc_in, dec_in, enc_mask, dec_enc_mask, dec_mask):\n",
    "        enc_in = self.embedding(self.enc_emb, enc_in)\n",
    "        dec_in = self.embedding(self.dec_emb, dec_in)\n",
    "\n",
    "        enc_out, enc_attns = self.encoder(enc_in, enc_mask)\n",
    "        \n",
    "        dec_out, dec_attns, dec_enc_attns = \\\n",
    "        self.decoder(dec_in, enc_out, dec_enc_mask, dec_mask)\n",
    "        \n",
    "        logits = self.fc(dec_out)\n",
    "        \n",
    "        return logits, enc_attns, dec_attns, dec_enc_attns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2c9ff8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model = 512\n",
    "\n",
    "transformer = Transformer(\n",
    "    n_layers=2,\n",
    "    d_model=d_model,\n",
    "    n_heads=8,\n",
    "    d_ff=2048,\n",
    "    src_vocab_size=vocab_size,\n",
    "    tgt_vocab_size=vocab_size,\n",
    "    pos_len=200,\n",
    "    dropout=0.2,\n",
    "    shared_fc=True,\n",
    "    shared_emb=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d6451d",
   "metadata": {},
   "source": [
    "## LearningRateScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3dd550aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LearningRateScheduler(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(LearningRateScheduler, self).__init__()\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.warmup_steps = warmup_steps\n",
    "    \n",
    "    def __call__(self, step):\n",
    "        arg1 = step ** -0.5\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "        \n",
    "        return (self.d_model ** -0.5) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4fab8e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = LearningRateScheduler(d_model)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate,\n",
    "                                        beta_1=0.9,\n",
    "                                        beta_2=0.98, \n",
    "                                        epsilon=1e-9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4df9f72",
   "metadata": {},
   "source": [
    "## Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0894e1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_sum(loss_)/tf.reduce_sum(mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cde8b3d",
   "metadata": {},
   "source": [
    "## Train Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "89037650",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function()\n",
    "def train_step(src, tgt, model, optimizer):\n",
    "    tgt_in = tgt[:, :-1]  # Decoder의 input\n",
    "    gold = tgt[:, 1:]     # Decoder의 output과 비교하기 위해 right shift를 통해 생성한 최종 타겟\n",
    "\n",
    "    enc_mask, dec_enc_mask, dec_mask = generate_masks(src, tgt_in)\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions, enc_attns, dec_attns, dec_enc_attns = \\\n",
    "        model(src, tgt_in, enc_mask, dec_enc_mask, dec_mask)\n",
    "        loss = loss_function(gold, predictions)\n",
    "\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)    \n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    return loss, enc_attns, dec_attns, dec_enc_attns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd421ae5",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6de25790",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "05be316b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed09451ba5de4e0a81f15fea9ce41c7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/548 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss 2916.4919\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3f89e8494464da9b3179cbd71e8dfd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/548 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Loss 901.4663\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2218f3fcfd25455dacfd42f7db3f9226",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/548 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Loss 381.6400\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 3\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    total_loss = 0\n",
    "    \n",
    "    dataset_count = tf.data.experimental.cardinality(train_dataset).numpy()\n",
    "    tqdm_bar = tqdm(total=dataset_count)\n",
    "    \n",
    "    for (src, tgt) in train_dataset:\n",
    "        loss, enc_attns, dec_attns, dec_enc_attns = train_step(src, tgt, transformer, optimizer)\n",
    "        total_loss += loss\n",
    "        tqdm_bar.set_description(f'Epoch {epoch + 1} Loss {total_loss.numpy():.4f}')\n",
    "        tqdm_bar.update()\n",
    "    tqdm_bar.close()\n",
    "    losses.append(total_loss.numpy())\n",
    "    print(f'Epoch {epoch + 1} Loss {total_loss.numpy():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "31d0e5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"t6\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "8b4a95f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer.save_weights(prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "e4b4c2ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[787.20886, 168.26482, 55.12243, 25.144192, 22.477667, 19.482353, 16.018162, 14.431708, 11.617785, 11.186228, 9.353998, 8.853584, 8.795164, 7.742421, 6.0034046, 7.1208277, 5.947632, 7.072251, 5.509118, 5.9569187]\n"
     ]
    }
   ],
   "source": [
    "print(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "7079cdde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fc7ce5f21c0>]"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "6fd196fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "histories = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "cbac3a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "histories[prefix] = losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "d15190fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_var(histories, \"histories\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "7cd6e5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "histories = load_var(\"histories\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "a544c500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'t0': [3832.5205, 2699.2415, 2176.4763], 't2': [3019.052, 2088.4956, 1682.1465, 1293.043, 1016.2196, 890.7383, 821.02826, 798.14386, 676.56366, 530.8138, 422.03873, 345.6523, 292.3675, 251.544, 222.10175, 192.92442, 169.73122, 149.50732, 134.93729, 118.146194], 't3': [1196.5056, 770.89154, 515.7512, 332.12772, 218.50471, 153.27972, 111.07922, 87.32306, 69.94883, 60.657585, 51.169834, 46.357754, 41.018753, 36.591194, 34.529594, 31.869173, 30.55571, 27.797064, 26.021723, 24.426159], 't4': [829.39075, 553.6872, 388.4518, 256.35968, 163.90486, 106.86399, 73.23022, 55.18291, 42.760113, 34.53064, 28.88408, 25.128407, 21.6047, 19.305098, 16.911804, 15.340065, 14.466317, 13.576882, 12.711096, 12.083197], 't5': [458.72556, 305.93698, 223.22914, 154.14638, 105.16861, 69.60865, 47.335815, 34.450607, 25.698656, 20.670425, 16.077423, 13.947396, 12.800986, 10.957445, 9.842569, 10.093627, 9.131347, 8.277581, 7.504043, 7.450125], 't6': [787.20886, 168.26482, 55.12243, 25.144192, 22.477667, 19.482353, 16.018162, 14.431708, 11.617785, 11.186228, 9.353998, 8.853584, 8.795164, 7.742421, 6.0034046, 7.1208277, 5.947632, 7.072251, 5.509118, 5.9569187]}\n"
     ]
    }
   ],
   "source": [
    "print(histories)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ddcad12",
   "metadata": {},
   "source": [
    "- t0: base. 3 epochs\n",
    "- t1: 20 epochs\n",
    "- t2: data aug. x4 --> x3\n",
    "- t3: batch size. 64 --> 128\n",
    "- t4: data aug. x3 --> x2\n",
    "- t5: fix. dataframe --> list\n",
    "- t6: data aug. x1 --> x3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8207a28",
   "metadata": {},
   "source": [
    "# Step 7. 성능 측정하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648dd337",
   "metadata": {},
   "source": [
    "주어진 질문에 적절한 답변을 하는지 확인하고, BLEU Score를 계산하는 calculate_bleu() 함수도 적용해 보세요."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923374de",
   "metadata": {},
   "source": [
    "```\n",
    "# 예문\n",
    "1. 지루하다, 놀러가고 싶어.\n",
    "2. 오늘 일찍 일어났더니 피곤하다.\n",
    "3. 간만에 여자친구랑 데이트 하기로 했어.\n",
    "4. 집에 있는다는 소리야.\n",
    "\n",
    "---\n",
    "\n",
    "# 제출\n",
    "\n",
    "Translations\n",
    "> 1. 잠깐 쉬 어도 돼요 . <end>\n",
    "> 2. 맛난 거 드세요 . <end>\n",
    "> 3. 떨리 겠 죠 . <end>\n",
    "> 4. 좋 아 하 면 그럴 수 있 어요 . <end>\n",
    "\n",
    "Hyperparameters\n",
    "> n_layers: 1\n",
    "> d_model: 368\n",
    "> n_heads: 8\n",
    "> d_ff: 1024\n",
    "> dropout: 0.2\n",
    "\n",
    "Training Parameters\n",
    "> Warmup Steps: 1000\n",
    "> Batch Size: 64\n",
    "> Epoch At: 10\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "56f7a6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(text_tokens, model, tokenizer):\n",
    "    print(f\"- {text_tokens}\")\n",
    "    seq_tokens = tokenizer.texts_to_sequences(text_tokens)\n",
    "    padded_tokens = pad_sequences(seq_tokens, padding=\"post\")\n",
    "    \n",
    "    ids = []\n",
    "    output = tf.expand_dims([tokenizer.word_index['<start>']], 0)   \n",
    "    for i in range(vocab_size):\n",
    "        enc_padding_mask, combined_mask, dec_padding_mask = generate_masks(padded_tokens, output)\n",
    "\n",
    "        try:\n",
    "            predictions, _, _, _ = model(padded_tokens,\n",
    "                                         output,\n",
    "                                         enc_padding_mask,\n",
    "                                         combined_mask,\n",
    "                                         dec_padding_mask)\n",
    "\n",
    "            predicted_id = tf.argmax(\n",
    "                tf.math.softmax(predictions, axis=-1)[0, -1]).numpy().item()\n",
    "\n",
    "            if tokenizer.word_index['<end>'] == predicted_id:\n",
    "                result = ' '.join(tokenizer.sequences_to_texts([ids]))\n",
    "                return result\n",
    "\n",
    "            ids.append(predicted_id)\n",
    "            output = tf.concat([output, tf.expand_dims([predicted_id], 0)], axis=-1)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(\"Caught an exception:\", e)\n",
    "            break\n",
    "\n",
    "    result = ' '.join(tokenizer.sequences_to_texts([ids]))\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "7044cbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_bleu_single(model, src_sentence, tgt_sentence, tokenizer, verbose=True):\n",
    "    \n",
    "#     print(f\"src: {src_sentence}\")\n",
    "#     print(f\"tgt: {tgt_sentence}\")\n",
    "\n",
    "    reference = tgt_sentence\n",
    "    candidate = translate(src_sentence, model, tokenizer).split()\n",
    "\n",
    "    score = sentence_bleu([reference], candidate,\n",
    "                          smoothing_function=SmoothingFunction().method1)\n",
    "\n",
    "    if verbose:\n",
    "        # print(\"Source Sentence: \", src_sentence)\n",
    "        print(\"Model Prediction: \", \" \".join(candidate))\n",
    "        print(\"Real: \", \" \".join(reference))\n",
    "        print(\"Score: %lf\\n\" % score)\n",
    "        \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "56b4c620",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_bleu(model, src_sentences, tgt_sentences, tokenizer, verbose=True):\n",
    "    total_score = 0.0\n",
    "    sample_size = len(src_sentences)\n",
    "    \n",
    "    for idx in tqdm(range(sample_size)):\n",
    "        src = \" \".join(src_sentences[idx])\n",
    "        tgt = tgt_sentences[idx]\n",
    "        score = eval_bleu_single(model, src, tgt, tokenizer, verbose)\n",
    "        if not score: continue\n",
    "        \n",
    "        total_score += score\n",
    "    \n",
    "    print(\"Num of Sample:\", sample_size)\n",
    "    print(\"Total Score:\", total_score / sample_size)\n",
    "    \n",
    "    return total_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1cb009dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_questions = [\"지루하다, 놀러가고 싶어.\",\n",
    "                  \"오늘 일찍 일어났더니 피곤하다.\",\n",
    "                  \"간만에 여자친구랑 데이트 하기로 했어.\",\n",
    "                  \"집에 있는다는 소리야.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b448f1e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['지루', '하', '다', '놀', '러', '가', '고', '싶', '어'],\n",
       " ['오늘', '일찍', '일어났', '더니', '피곤', '하', '다'],\n",
       " ['간만에', '여자', '친구', '랑', '데이트', '하', '기', '로', '했', '어'],\n",
       " ['집', '에', '있', '는다는', '소리야']]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_questions = cleaner.clean_corpus(test_questions)\n",
    "test_questions = get_tokenized_corpus(test_questions, mecab)\n",
    "test_questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b1b8a5b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[36721, 29576, 41665, 34028, 29759, 29952, 4288, 8121, 21349, 42258]\n"
     ]
    }
   ],
   "source": [
    "random_indices = random.sample(range(0, df_corpus.shape[0] + 1), 10)\n",
    "print(random_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "643b3f97",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 헤어지 고 난 뒤 애인\n",
      "Source Sentence:  헤어지 고 난 뒤 애인\n",
      "Model Prediction:  ['만나', '길', '바라', '요']\n",
      "Real:  ['<start>', '친구', '가', '되', '기', '쉽', '지', '않', '을', '거', '예요', '<end>']\n",
      "Score: 0.000000\n",
      "\n",
      "- 소개팅 하 고 애프터 까지 왔 지만 설렘 이 있 어\n",
      "Source Sentence:  소개팅 하 고 애프터 까지 왔 지만 설렘 이 있 어\n",
      "Model Prediction:  ['썸', '은', '사이', '가', '는', '사이', '가', '좋', '은', '일', '이', '에요']\n",
      "Real:  ['<start>', '조금', '더', '만나', '보', '고', '결정', '하', '는', '건', '어떨까', '요', '<end>']\n",
      "Score: 0.015671\n",
      "\n",
      "- 은 남자 맘 이 뭔지\n",
      "Source Sentence:  은 남자 맘 이 뭔지\n",
      "Model Prediction:  ['운명', '입니다']\n",
      "Real:  ['<start>', '사람', '맘', '은', '알', '길', '이', '없', '어요', '<end>']\n",
      "Score: 0.000000\n",
      "\n",
      "- 나가 이 멍청 한 거 지\n",
      "Source Sentence:  나가 이 멍청 한 거 지\n",
      "Model Prediction:  ['운명', '은', '사람', '은', '모두', '사람', '은', '모두', '모두', '모두', '모두', '말', '은', '거', '예요']\n",
      "Real:  ['<start>', '실수', '했', '나요', '<end>']\n",
      "Score: 0.000000\n",
      "\n",
      "- 년 동거 후 이별 개월 차\n",
      "Source Sentence:  년 동거 후 이별 개월 차\n",
      "Model Prediction:  ['많', '은', '시기', '네요']\n",
      "Real:  ['<start>', '생각', '을', '오래', '하', '면', '더욱', '지칠', '수', '있', '어요', '<end>']\n",
      "Score: 0.000000\n",
      "\n",
      "- 나 자체 을 사랑 해 줄 사람 이 있 습니까\n",
      "Source Sentence:  나 자체 을 사랑 해 줄 사람 이 있 습니까\n",
      "Model Prediction:  ['운명', '은', '사람', '은', '모두', '사람', '은', '모두', '모두', '모두', '모두', '말', '은', '거', '예요']\n",
      "Real:  ['<start>', '잘', '찾아보', '세요', '<end>']\n",
      "Score: 0.000000\n",
      "\n",
      "- 대체 불가 한 사람 이 되 고 싶 어\n",
      "Source Sentence:  대체 불가 한 사람 이 되 고 싶 어\n",
      "Model Prediction:  ['궁금', '하', '네요']\n",
      "Real:  ['<start>', '지금', '도', '그래요', '<end>']\n",
      "Score: 0.000000\n",
      "\n",
      "- 삶 살만 해서\n",
      "Source Sentence:  삶 살만 해서\n",
      "Model Prediction:  ['당신', '이', '답', '을', '수', '있', '어요']\n",
      "Real:  ['<start>', '누구', '나', '한', '번', '쯤', '시도', '해', '볼', '만', '하', '죠', '<end>']\n",
      "Score: 0.000000\n",
      "\n",
      "- 여자 친구 이 너무 챙 김 받 고 싶 어 해서\n",
      "Source Sentence:  여자 친구 이 너무 챙 김 받 고 싶 어 해서\n",
      "Model Prediction:  ['이성', '으로', '어필', '을', '어필', '해', '보', '세요']\n",
      "Real:  ['<start>', '사랑', '을', '더', '받', '고', '싶', '은', '가', '봐요', '<end>']\n",
      "Score: 0.019090\n",
      "\n",
      "- 양배추 찹쌀 최악\n",
      "Source Sentence:  양배추 찹쌀 최악\n",
      "Model Prediction:  ['제일', '방법', '이', '에요']\n",
      "Real:  ['<start>', '먹', '으면서', '다이어트', '하', '는', '분', '들', '진짜', '엄청', '대단', '한', '분', '들', '이', '에요', '<end>']\n",
      "Score: 0.006588\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for index in random_indices:\n",
    "    score = eval_bleu_single(transformer, \n",
    "                             \" \".join(df_corpus[\"questions\"].iloc[index]), \n",
    "                             df_corpus[\"target_tokens\"].iloc[index], \n",
    "                             tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "41437ecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19887, 25117, 4751, 11536, 32518, 12289, 16228, 30753, 3071, 19636, 15279, 17286, 23372, 31889, 16128, 16251, 21496, 4810, 10209, 19640, 30521, 30755, 28950, 5745, 16428, 33118, 19186, 22832, 25003, 23917, 29354, 12166, 18510, 21926, 21459, 25451, 32723, 13335, 33961, 31754, 14060, 11450, 31338, 5407, 26082, 19355, 33939, 4867, 18802, 15227, 1054, 28991, 8533, 18598, 30611, 20774, 31750, 16288, 31268, 25220, 23542, 10263, 26795, 10794, 20061, 14970, 24938, 11862, 21991, 13521, 31883, 11387, 13652, 7556, 13665, 6502, 6366, 27152, 18332, 31448, 8207, 14931, 7575, 11242, 416, 23118, 21411, 7583, 1578, 21383, 2508, 9024, 11699, 24074, 15056, 25251, 12799, 8536, 540, 11955]\n"
     ]
    }
   ],
   "source": [
    "indices_bleu = random.sample(range(0, df_corpus.shape[0] + 1), 100)\n",
    "print(indices_bleu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "4fb3be70",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_sentences = list(df_corpus[\"questions\"].iloc[indices_bleu])\n",
    "tgt_sentences = list(df_corpus[\"answers\"].iloc[indices_bleu])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "5a639c55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['아', '벌', '받', '고', '있', '는', '건가', '네'], ['달', '게', '받', '으세요'])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_sentences[0], tgt_sentences[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3384a1cf",
   "metadata": {},
   "source": [
    "### t0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80389c83",
   "metadata": {},
   "source": [
    "- n_layers: 2\n",
    "- d_model: 512\n",
    "- n_heads: 8\n",
    "- d_ff: 2048\n",
    "- dropout: 0.3\n",
    "- batch_size: 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "488560e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 지루 하 다 놀 러 가 고 싶 어\n",
      "> 고백 하 게 고백 하 세요\n",
      "\n",
      "- 오늘 일찍 일어났 더니 피곤 하 다\n",
      "> 썸 이 에요\n",
      "\n",
      "- 간만에 여자 친구 랑 데이트 하 기 로 했 어\n",
      "> 다시 시작 이 되 겠 어요\n",
      "\n",
      "- 집 에 있 는다는 소리야\n",
      "> 축하 드려요\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for question in test_questions:\n",
    "    result = translate(\" \".join(question), transformer, tokenizer)\n",
    "    print(f\"> {result}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "b2fff4e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 오후 돌이\n",
      "Source Sentence:  오후 돌이\n",
      "Model Prediction:  ['썸', '이', '에요']\n",
      "Real:  ['하루', '가', '또', '가', '네요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 오후 순이\n",
      "Source Sentence:  오후 순이\n",
      "Model Prediction:  ['썸', '이', '에요']\n",
      "Real:  ['하루', '가', '또', '가', '네요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 오전 돌이\n",
      "Source Sentence:  오전 돌이\n",
      "Model Prediction:  ['썸', '이', '에요']\n",
      "Real:  ['하루', '가', '또', '가', '네요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 캐스터 여학교 떨어졌 어서\n",
      "Source Sentence:  캐스터 여학교 떨어졌 어서\n",
      "Model Prediction:  ['사랑', '은', '언제', '든', '시작', '이', '었', '으니까요']\n",
      "Real:  ['위로', '해', '드립니다']\n",
      "Score: 0.000000\n",
      "\n",
      "- 캐스터 여학교 떨어졌 어\n",
      "Source Sentence:  캐스터 여학교 떨어졌 어\n",
      "Model Prediction:  ['사랑', '은', '언제', '든', '시작', '이', '었', '으니까요']\n",
      "Real:  ['위로', '해', '드립니다']\n",
      "Score: 0.000000\n",
      "\n",
      "- 캐스터 소학교 떨어졌 어서\n",
      "Source Sentence:  캐스터 소학교 떨어졌 어서\n",
      "Model Prediction:  ['사랑', '은', '언제', '든', '시작', '이', '었', '으니까요']\n",
      "Real:  ['위로', '해', '드립니다']\n",
      "Score: 0.000000\n",
      "\n",
      "- 캐스터 여학교 올라갔 어서\n",
      "Source Sentence:  캐스터 여학교 올라갔 어서\n",
      "Model Prediction:  ['사랑', '은', '언제', '든', '시작', '이', '었', '으니까요']\n",
      "Real:  ['위로', '해', '드립니다']\n",
      "Score: 0.000000\n",
      "\n",
      "- 윤 월 놀 러 이 는데 싶 는데\n",
      "Source Sentence:  윤 월 놀 러 이 는데 싶 는데\n",
      "Model Prediction:  ['호감', '을', '표현', '하', '고', '있', '어요']\n",
      "Real:  ['여행', '은', '언제나', '좋', '죠']\n",
      "Score: 0.000000\n",
      "\n",
      "- 윤 월 놀 니 이 는데 싶 는데\n",
      "Source Sentence:  윤 월 놀 니 이 는데 싶 는데\n",
      "Model Prediction:  ['호감', '을', '표현', '하', '고', '있', '어요']\n",
      "Real:  ['여행', '은', '언제나', '좋', '죠']\n",
      "Score: 0.000000\n",
      "\n",
      "- 윤 월 놀 러 이 는데 싫 는데\n",
      "Source Sentence:  윤 월 놀 러 이 는데 싫 는데\n",
      "Model Prediction:  ['호감', '을', '표현', '하', '고', '있', '어요']\n",
      "Real:  ['여행', '은', '언제나', '좋', '죠']\n",
      "Score: 0.000000\n",
      "\n",
      "- 윤 월 놀 러 은 는데 싶 는데\n",
      "Source Sentence:  윤 월 놀 러 은 는데 싶 는데\n",
      "Model Prediction:  ['호감', '을', '표현', '하', '고', '있', '어요']\n",
      "Real:  ['여행', '은', '언제나', '좋', '죠']\n",
      "Score: 0.000000\n",
      "\n",
      "- 김 월 만큼 놀 거든 이 지만 싶 지만\n",
      "Source Sentence:  김 월 만큼 놀 거든 이 지만 싶 지만\n",
      "Model Prediction:  ['바라', '요']\n",
      "Real:  ['여행', '은', '언제나', '좋', '죠']\n",
      "Score: 0.000000\n",
      "\n",
      "- 김 월 만큼 놀 거든 은 지만 싶 지만\n",
      "Source Sentence:  김 월 만큼 놀 거든 은 지만 싶 지만\n",
      "Model Prediction:  ['바라', '요']\n",
      "Real:  ['여행', '은', '언제나', '좋', '죠']\n",
      "Score: 0.000000\n",
      "\n",
      "- 김 월 만큼 울 거든 이 지만 싶 지만\n",
      "Source Sentence:  김 월 만큼 울 거든 이 지만 싶 지만\n",
      "Model Prediction:  ['바라', '요']\n",
      "Real:  ['여행', '은', '언제나', '좋', '죠']\n",
      "Score: 0.000000\n",
      "\n",
      "- 윤 월 만큼 놀 거든 이 지만 싶 지만\n",
      "Source Sentence:  윤 월 만큼 놀 거든 이 지만 싶 지만\n",
      "Model Prediction:  ['호감', '을', '표현', '하', '고', '있', '어요']\n",
      "Real:  ['여행', '은', '언제나', '좋', '죠']\n",
      "Score: 0.000000\n",
      "\n",
      "- ppl 약하 다섯\n",
      "Source Sentence:  ppl 약하 다섯\n",
      "Model Prediction:  ['만나', '길', '바라', '요']\n",
      "Real:  ['눈살', '이', '찌푸려', '지', '죠']\n",
      "Score: 0.000000\n",
      "\n",
      "- ppl 강하 다섯\n",
      "Source Sentence:  ppl 강하 다섯\n",
      "Model Prediction:  ['만나', '길', '바라', '요']\n",
      "Real:  ['눈살', '이', '찌푸려', '지', '죠']\n",
      "Score: 0.000000\n",
      "\n",
      "- ppl 약하 여섯\n",
      "Source Sentence:  ppl 약하 여섯\n",
      "Model Prediction:  ['만나', '길', '바라', '요']\n",
      "Real:  ['눈살', '이', '찌푸려', '지', '죠']\n",
      "Score: 0.000000\n",
      "\n",
      "- cp 단말 아름다웠 어\n",
      "Source Sentence:  cp 단말 아름다웠 어\n",
      "Model Prediction:  ['슬픈', '이야기', '네요']\n",
      "Real:  ['다시', '새로', '사', '는', '게', '마음', '편해요']\n",
      "Score: 0.000000\n",
      "\n",
      "- perl 단말 아름다웠 어\n",
      "Source Sentence:  perl 단말 아름다웠 어\n",
      "Model Prediction:  ['만나', '길', '바라', '요']\n",
      "Real:  ['다시', '새로', '사', '는', '게', '마음', '편해요']\n",
      "Score: 0.000000\n",
      "\n",
      "- cp 단말 기뻐했 어\n",
      "Source Sentence:  cp 단말 기뻐했 어\n",
      "Model Prediction:  ['슬픈', '이야기', '네요']\n",
      "Real:  ['다시', '새로', '사', '는', '게', '마음', '편해요']\n",
      "Score: 0.000000\n",
      "\n",
      "- cp 모뎀 아름다웠 어\n",
      "Source Sentence:  cp 모뎀 아름다웠 어\n",
      "Model Prediction:  ['슬픈', '이야기', '네요']\n",
      "Real:  ['다시', '새로', '사', '는', '게', '마음', '편해요']\n",
      "Score: 0.000000\n",
      "\n",
      "- perl 모뎀 앞 됐으며\n",
      "Source Sentence:  perl 모뎀 앞 됐으며\n",
      "Model Prediction:  ['만나', '길', '바라', '요']\n",
      "Real:  ['다시', '새로', '사', '는', '게', '마음', '편해요']\n",
      "Score: 0.000000\n",
      "\n",
      "- perl 모뎀 앞 됐으나\n",
      "Source Sentence:  perl 모뎀 앞 됐으나\n",
      "Model Prediction:  ['만나', '길', '바라', '요']\n",
      "Real:  ['다시', '새로', '사', '는', '게', '마음', '편해요']\n",
      "Score: 0.000000\n",
      "\n",
      "- perl 모뎀 옆 됐으며\n",
      "Source Sentence:  perl 모뎀 옆 됐으며\n",
      "Model Prediction:  ['만나', '길', '바라', '요']\n",
      "Real:  ['다시', '새로', '사', '는', '게', '마음', '편해요']\n",
      "Score: 0.000000\n",
      "\n",
      "- cp 모뎀 앞 됐으며\n",
      "Source Sentence:  cp 모뎀 앞 됐으며\n",
      "Model Prediction:  ['슬픈', '이야기', '네요']\n",
      "Real:  ['다시', '새로', '사', '는', '게', '마음', '편해요']\n",
      "Score: 0.000000\n",
      "\n",
      "- casework 주저앉 팔 정말로 옆 하 당치\n",
      "Source Sentence:  casework 주저앉 팔 정말로 옆 하 당치\n",
      "Model Prediction:  ['슬픈', '이야기', '네요']\n",
      "Real:  ['잘', '모르', '고', '있', '을', '수', '도', '있', '어요']\n",
      "Score: 0.000000\n",
      "\n",
      "- casework 주저앉 빨 정말로 옆 하 당치\n",
      "Source Sentence:  casework 주저앉 빨 정말로 옆 하 당치\n",
      "Model Prediction:  ['슬픈', '이야기', '네요']\n",
      "Real:  ['잘', '모르', '고', '있', '을', '수', '도', '있', '어요']\n",
      "Score: 0.000000\n",
      "\n",
      "- casework 주저앉 팔 정말로 옆 시키 당치\n",
      "Source Sentence:  casework 주저앉 팔 정말로 옆 시키 당치\n",
      "Model Prediction:  ['슬픈', '이야기', '네요']\n",
      "Real:  ['잘', '모르', '고', '있', '을', '수', '도', '있', '어요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 케이스워크 주저앉 팔 정말로 옆 하 당치\n",
      "Source Sentence:  케이스워크 주저앉 팔 정말로 옆 하 당치\n",
      "Model Prediction:  ['다음', '부터', '는', '만큼', '더', '좋', '은', '선택', '이', '었', '길', '바라', '요']\n",
      "Real:  ['잘', '모르', '고', '있', '을', '수', '도', '있', '어요']\n",
      "Score: 0.000000\n",
      "\n",
      "- sns 분 절약 , 거 아 는데 아침 꾀하 은 중\n",
      "Source Sentence:  sns 분 절약 , 거 아 는데 아침 꾀하 은 중\n",
      "Model Prediction:  ['만나', '길', '바라', '요']\n",
      "Real:  ['시간', '을', '정하', '고', '해', '보', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- sns 분 절약 , 거 아 지만 아침 꾀하 은 중\n",
      "Source Sentence:  sns 분 절약 , 거 아 지만 아침 꾀하 은 중\n",
      "Model Prediction:  ['만나', '길', '바라', '요']\n",
      "Real:  ['시간', '을', '정하', '고', '해', '보', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- sns 초간 절약 , 거 아 는데 아침 꾀하 은 중\n",
      "Source Sentence:  sns 초간 절약 , 거 아 는데 아침 꾀하 은 중\n",
      "Model Prediction:  ['만나', '길', '바라', '요']\n",
      "Real:  ['시간', '을', '정하', '고', '해', '보', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- sns 분 절약 , 거 아 는데 아침 시키 은 중\n",
      "Source Sentence:  sns 분 절약 , 거 아 는데 아침 시키 은 중\n",
      "Model Prediction:  ['만나', '길', '바라', '요']\n",
      "Real:  ['시간', '을', '정하', '고', '해', '보', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 케이스워크 시간 조달 라면 혹시 알아채 게끔 이루어짐\n",
      "Source Sentence:  케이스워크 시간 조달 라면 혹시 알아채 게끔 이루어짐\n",
      "Model Prediction:  ['다음', '부터', '는', '만큼', '더', '좋', '은', '선택', '이', '었', '길', '바라', '요']\n",
      "Real:  ['시간', '을', '정하', '고', '해', '보', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 케이스워크 시간 조달 라면 누가 알아채 게끔 이루어짐\n",
      "Source Sentence:  케이스워크 시간 조달 라면 누가 알아채 게끔 이루어짐\n",
      "Model Prediction:  ['다음', '부터', '는', '만큼', '더', '좋', '은', '선택', '이', '었', '길', '바라', '요']\n",
      "Real:  ['시간', '을', '정하', '고', '해', '보', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 케이스워크 시간 조달 라면 혹시 알아채 게끔 들어옴\n",
      "Source Sentence:  케이스워크 시간 조달 라면 혹시 알아채 게끔 들어옴\n",
      "Model Prediction:  ['다음', '부터', '는', '만큼', '더', '좋', '은', '선택', '이', '었', '길', '바라', '요']\n",
      "Real:  ['시간', '을', '정하', '고', '해', '보', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 케이스워크 분 조달 라면 혹시 알아채 게끔 이루어짐\n",
      "Source Sentence:  케이스워크 분 조달 라면 혹시 알아채 게끔 이루어짐\n",
      "Model Prediction:  ['다음', '부터', '는', '만큼', '더', '좋', '은', '선택', '이', '었', '길', '바라', '요']\n",
      "Real:  ['시간', '을', '정하', '고', '해', '보', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 케이스워크 보 면 나 만 때리 는데 다 행복 해 보여\n",
      "Source Sentence:  케이스워크 보 면 나 만 때리 는데 다 행복 해 보여\n",
      "Model Prediction:  ['다음', '부터', '는', '만큼', '더', '좋', '은', '선택', '이', '었', '길', '바라', '요']\n",
      "Real:  ['자랑', '하', '는', '자리', '니까요']\n",
      "Score: 0.015537\n",
      "\n",
      "- 케이스워크 보 면 나 만 걷어차 는데 다 행복 해 보여\n",
      "Source Sentence:  케이스워크 보 면 나 만 걷어차 는데 다 행복 해 보여\n",
      "Model Prediction:  ['다음', '부터', '는', '만큼', '더', '좋', '은', '선택', '이', '었', '길', '바라', '요']\n",
      "Real:  ['자랑', '하', '는', '자리', '니까요']\n",
      "Score: 0.015537\n",
      "\n",
      "- 케이스워크 보 면 나 만 때리 는데 다 행복 해서 보여\n",
      "Source Sentence:  케이스워크 보 면 나 만 때리 는데 다 행복 해서 보여\n",
      "Model Prediction:  ['다음', '부터', '는', '만큼', '더', '좋', '은', '선택', '이', '었', '길', '바라', '요']\n",
      "Real:  ['자랑', '하', '는', '자리', '니까요']\n",
      "Score: 0.015537\n",
      "\n",
      "- 케이스워크 보 면 나 만 때리 는데 는데 행복 해 보여\n",
      "Source Sentence:  케이스워크 보 면 나 만 때리 는데 는데 행복 해 보여\n",
      "Model Prediction:  ['다음', '부터', '는', '만큼', '더', '좋', '은', '선택', '이', '었', '길', '바라', '요']\n",
      "Real:  ['자랑', '하', '는', '자리', '니까요']\n",
      "Score: 0.015537\n",
      "\n",
      "- 가끔 의아 해\n",
      "Source Sentence:  가끔 의아 해\n",
      "Model Prediction:  ['나', '를', '더', '나', '봐요']\n",
      "Real:  ['그', '사람', '도', '그럴', '거', '예요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 이따금 의아 해\n",
      "Source Sentence:  이따금 의아 해\n",
      "Model Prediction:  ['참', '은', '참', '기', '힘들', '게', '없', '어요']\n",
      "Real:  ['그', '사람', '도', '그럴', '거', '예요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가끔 흡족 해\n",
      "Source Sentence:  가끔 흡족 해\n",
      "Model Prediction:  ['나', '를', '더', '나', '봐요']\n",
      "Real:  ['그', '사람', '도', '그럴', '거', '예요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가끔 의아 해서\n",
      "Source Sentence:  가끔 의아 해서\n",
      "Model Prediction:  ['나', '를', '더', '나', '봐요']\n",
      "Real:  ['그', '사람', '도', '그럴', '거', '예요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가끔 뭐 꾀하 는지 의아 해\n",
      "Source Sentence:  가끔 뭐 꾀하 는지 의아 해\n",
      "Model Prediction:  ['나', '를', '더', '나', '봐요']\n",
      "Real:  ['그', '사람', '도', '그럴', '거', '예요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가끔 어쩌 꾀하 는지 의아 해\n",
      "Source Sentence:  가끔 어쩌 꾀하 는지 의아 해\n",
      "Model Prediction:  ['나', '를', '더', '나', '봐요']\n",
      "Real:  ['그', '사람', '도', '그럴', '거', '예요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가끔 뭐 시키 는지 의아 해\n",
      "Source Sentence:  가끔 뭐 시키 는지 의아 해\n",
      "Model Prediction:  ['나', '를', '더', '나', '봐요']\n",
      "Real:  ['그', '사람', '도', '그럴', '거', '예요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가끔 뭐 꾀하 는가 의아 해\n",
      "Source Sentence:  가끔 뭐 꾀하 는가 의아 해\n",
      "Model Prediction:  ['나', '를', '더', '나', '봐요']\n",
      "Real:  ['그', '사람', '도', '그럴', '거', '예요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가끔 은 혼자 의 게 좋 다\n",
      "Source Sentence:  가끔 은 혼자 의 게 좋 다\n",
      "Model Prediction:  ['나', '를', '더', '나', '봐요']\n",
      "Real:  ['혼자', '를', '즐기', '세요']\n",
      "Score: 0.053728\n",
      "\n",
      "- 가끔 은 혼자 의 도록 좋 다\n",
      "Source Sentence:  가끔 은 혼자 의 도록 좋 다\n",
      "Model Prediction:  ['나', '를', '더', '나', '봐요']\n",
      "Real:  ['혼자', '를', '즐기', '세요']\n",
      "Score: 0.053728\n",
      "\n",
      "- 가끔 은 거기 의 게 좋 다\n",
      "Source Sentence:  가끔 은 거기 의 게 좋 다\n",
      "Model Prediction:  ['나', '를', '더', '나', '봐요']\n",
      "Real:  ['혼자', '를', '즐기', '세요']\n",
      "Score: 0.053728\n",
      "\n",
      "- 가끔 은 혼자 의 게 좋 는데\n",
      "Source Sentence:  가끔 은 혼자 의 게 좋 는데\n",
      "Model Prediction:  ['나', '를', '더', '나', '봐요']\n",
      "Real:  ['혼자', '를', '즐기', '세요']\n",
      "Score: 0.053728\n",
      "\n",
      "- 가난 한 자 의 슬픔\n",
      "Source Sentence:  가난 한 자 의 슬픔\n",
      "Model Prediction:  ['나', '를', '더', '나', '봐요']\n",
      "Real:  ['돈', '은', '다시', '들어올', '거', '예요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가난 한 면서 의 슬픔\n",
      "Source Sentence:  가난 한 면서 의 슬픔\n",
      "Model Prediction:  ['나', '를', '더', '나', '봐요']\n",
      "Real:  ['돈', '은', '다시', '들어올', '거', '예요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 부유 한 자 의 슬픔\n",
      "Source Sentence:  부유 한 자 의 슬픔\n",
      "Model Prediction:  ['추억', '이', '되', '겠', '네요']\n",
      "Real:  ['돈', '은', '다시', '들어올', '거', '예요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가난 한 자 , 슬픔\n",
      "Source Sentence:  가난 한 자 , 슬픔\n",
      "Model Prediction:  ['나', '를', '더', '나', '봐요']\n",
      "Real:  ['돈', '은', '다시', '들어올', '거', '예요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가만 없 어도 땀 난다\n",
      "Source Sentence:  가만 없 어도 땀 난다\n",
      "Model Prediction:  ['나', '를', '더', '나', '봐요']\n",
      "Real:  ['땀', '을', '식혀', '주', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가국 없 어도 땀 난다\n",
      "Source Sentence:  가국 없 어도 땀 난다\n",
      "Model Prediction:  ['나', '를', '더', '나', '봐요']\n",
      "Real:  ['땀', '을', '식혀', '주', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가만 있 어도 땀 난다\n",
      "Source Sentence:  가만 있 어도 땀 난다\n",
      "Model Prediction:  ['나', '를', '더', '나', '봐요']\n",
      "Real:  ['땀', '을', '식혀', '주', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가만 없 어도 땀 생긴다\n",
      "Source Sentence:  가만 없 어도 땀 생긴다\n",
      "Model Prediction:  ['나', '를', '더', '나', '봐요']\n",
      "Real:  ['땀', '을', '식혀', '주', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가상현실 화폐 서요 망함\n",
      "Source Sentence:  가상현실 화폐 서요 망함\n",
      "Model Prediction:  ['나', '를', '더', '나', '봐요']\n",
      "Real:  ['어서', '잊', '고', '새', '출발', '하', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가상현실 화폐 대리국 망함\n",
      "Source Sentence:  가상현실 화폐 대리국 망함\n",
      "Model Prediction:  ['나', '를', '더', '나', '봐요']\n",
      "Real:  ['어서', '잊', '고', '새', '출발', '하', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가상현실 화폐 서요 들려줌\n",
      "Source Sentence:  가상현실 화폐 서요 들려줌\n",
      "Model Prediction:  ['나', '를', '더', '나', '봐요']\n",
      "Real:  ['어서', '잊', '고', '새', '출발', '하', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가상현실 통화 서요 망함\n",
      "Source Sentence:  가상현실 통화 서요 망함\n",
      "Model Prediction:  ['나', '를', '더', '나', '봐요']\n",
      "Real:  ['어서', '잊', '고', '새', '출발', '하', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 냉각재 불 켜 고 갔 어\n",
      "Source Sentence:  냉각재 불 켜 고 갔 어\n",
      "Model Prediction:  ['만나', '길', '바라', '요']\n",
      "Real:  ['빨리', '집', '에', '돌아가', '서', '끄', '고', '나오', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 냉각재 불 켜 고 나갔 어\n",
      "Source Sentence:  냉각재 불 켜 고 나갔 어\n",
      "Model Prediction:  ['만나', '길', '바라', '요']\n",
      "Real:  ['빨리', '집', '에', '돌아가', '서', '끄', '고', '나오', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 냉각재 불 당겨 고 갔 어\n",
      "Source Sentence:  냉각재 불 당겨 고 갔 어\n",
      "Model Prediction:  ['만나', '길', '바라', '요']\n",
      "Real:  ['빨리', '집', '에', '돌아가', '서', '끄', '고', '나오', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 냉각수 불 켜 고 갔 어\n",
      "Source Sentence:  냉각수 불 켜 고 갔 어\n",
      "Model Prediction:  ['만나', '길', '바라', '요']\n",
      "Real:  ['빨리', '집', '에', '돌아가', '서', '끄', '고', '나오', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가스 성 켜 놓 는데 나온 건가 같 아\n",
      "Source Sentence:  가스 성 켜 놓 는데 나온 건가 같 아\n",
      "Model Prediction:  ['나', '를', '더', '나', '봐요']\n",
      "Real:  ['빨리', '집', '에', '돌아가', '서', '끄', '고', '나오', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가스 성 켜 놓 는데 나타난 건가 같 아\n",
      "Source Sentence:  가스 성 켜 놓 는데 나타난 건가 같 아\n",
      "Model Prediction:  ['나', '를', '더', '나', '봐요']\n",
      "Real:  ['빨리', '집', '에', '돌아가', '서', '끄', '고', '나오', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가스 성 당겨 놓 는데 나온 건가 같 아\n",
      "Source Sentence:  가스 성 당겨 놓 는데 나온 건가 같 아\n",
      "Model Prediction:  ['나', '를', '더', '나', '봐요']\n",
      "Real:  ['빨리', '집', '에', '돌아가', '서', '끄', '고', '나오', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가스 성 켜 늘어놓 는데 나온 건가 같 아\n",
      "Source Sentence:  가스 성 켜 늘어놓 는데 나온 건가 같 아\n",
      "Model Prediction:  ['나', '를', '더', '나', '봐요']\n",
      "Real:  ['빨리', '집', '에', '돌아가', '서', '끄', '고', '나오', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 냉각수 비 너무 많이 올라왔 는데\n",
      "Source Sentence:  냉각수 비 너무 많이 올라왔 는데\n",
      "Model Prediction:  ['만나', '길', '바라', '요']\n",
      "Real:  ['다음', '달', '에', '는', '더', '절약', '해봐요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 냉각수 비 너무 많이 나왔 는데\n",
      "Source Sentence:  냉각수 비 너무 많이 나왔 는데\n",
      "Model Prediction:  ['만나', '길', '바라', '요']\n",
      "Real:  ['다음', '달', '에', '는', '더', '절약', '해봐요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 냉각수 비 너무 많이 올라왔 지만\n",
      "Source Sentence:  냉각수 비 너무 많이 올라왔 지만\n",
      "Model Prediction:  ['만나', '길', '바라', '요']\n",
      "Real:  ['다음', '달', '에', '는', '더', '절약', '해봐요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 냉각수 비 너무 잘 올라왔 는데\n",
      "Source Sentence:  냉각수 비 너무 잘 올라왔 는데\n",
      "Model Prediction:  ['만나', '길', '바라', '요']\n",
      "Real:  ['다음', '달', '에', '는', '더', '절약', '해봐요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 냉각수 침습 비싼데 감기 걸렸 겠 어\n",
      "Source Sentence:  냉각수 침습 비싼데 감기 걸렸 겠 어\n",
      "Model Prediction:  ['만나', '길', '바라', '요']\n",
      "Real:  ['따뜻', '하', '게', '사세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 냉각수 비가역 비싼데 감기 걸렸 겠 어\n",
      "Source Sentence:  냉각수 비가역 비싼데 감기 걸렸 겠 어\n",
      "Model Prediction:  ['만나', '길', '바라', '요']\n",
      "Real:  ['따뜻', '하', '게', '사세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 냉각수 침습 비싼데 감기 걸렸 겠 어서\n",
      "Source Sentence:  냉각수 침습 비싼데 감기 걸렸 겠 어서\n",
      "Model Prediction:  ['만나', '길', '바라', '요']\n",
      "Real:  ['따뜻', '하', '게', '사세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 냉각수 침습 비싼데 감기 걸렸 셨 어\n",
      "Source Sentence:  냉각수 침습 비싼데 감기 걸렸 셨 어\n",
      "Model Prediction:  ['만나', '길', '바라', '요']\n",
      "Real:  ['따뜻', '하', '게', '사세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 냉각수 침습 장난 임\n",
      "Source Sentence:  냉각수 침습 장난 임\n",
      "Model Prediction:  ['만나', '길', '바라', '요']\n",
      "Real:  ['다음', '달', '에', '는', '더', '절약', '해봐요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 냉각재 침습 장난 임\n",
      "Source Sentence:  냉각재 침습 장난 임\n",
      "Model Prediction:  ['만나', '길', '바라', '요']\n",
      "Real:  ['다음', '달', '에', '는', '더', '절약', '해봐요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 냉각수 침습 장난 아님\n",
      "Source Sentence:  냉각수 침습 장난 아님\n",
      "Model Prediction:  ['만나', '길', '바라', '요']\n",
      "Real:  ['다음', '달', '에', '는', '더', '절약', '해봐요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 냉각수 침습 농담 임\n",
      "Source Sentence:  냉각수 침습 농담 임\n",
      "Model Prediction:  ['만나', '길', '바라', '요']\n",
      "Real:  ['다음', '달', '에', '는', '더', '절약', '해봐요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가족 여행 은 기 로서 했 어\n",
      "Source Sentence:  가족 여행 은 기 로서 했 어\n",
      "Model Prediction:  ['나', '를', '더', '나', '봐요']\n",
      "Real:  ['온', '가족', '이', '모두', '마음', '에', '드', '는', '곳', '으로', '가보세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가족 항해 은 기 로서 했 어\n",
      "Source Sentence:  가족 항해 은 기 로서 했 어\n",
      "Model Prediction:  ['나', '를', '더', '나', '봐요']\n",
      "Real:  ['온', '가족', '이', '모두', '마음', '에', '드', '는', '곳', '으로', '가보세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가족 여행 은 고자 로서 했 어\n",
      "Source Sentence:  가족 여행 은 고자 로서 했 어\n",
      "Model Prediction:  ['나', '를', '더', '나', '봐요']\n",
      "Real:  ['온', '가족', '이', '모두', '마음', '에', '드', '는', '곳', '으로', '가보세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가족 여행 은 기 로서 했 어서\n",
      "Source Sentence:  가족 여행 은 기 로서 했 어서\n",
      "Model Prediction:  ['나', '를', '더', '나', '봐요']\n",
      "Real:  ['온', '가족', '이', '모두', '마음', '에', '드', '는', '곳', '으로', '가보세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 친지 여행 고고\n",
      "Source Sentence:  친지 여행 고고\n",
      "Model Prediction:  ['썸', '사이', '사이', '에서', '말', '고', '싶', '은', '거', '같', '아요']\n",
      "Real:  ['온', '가족', '이', '모두', '마음', '에', '드', '는', '곳', '으로', '가보세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 친지 항해 고고\n",
      "Source Sentence:  친지 항해 고고\n",
      "Model Prediction:  ['썸', '사이', '사이', '에서', '말', '고', '싶', '은', '거', '같', '아요']\n",
      "Real:  ['온', '가족', '이', '모두', '마음', '에', '드', '는', '곳', '으로', '가보세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 친지 여행 다용\n",
      "Source Sentence:  친지 여행 다용\n",
      "Model Prediction:  ['썸', '사이', '사이', '에서', '말', '고', '싶', '은', '거', '같', '아요']\n",
      "Real:  ['온', '가족', '이', '모두', '마음', '에', '드', '는', '곳', '으로', '가보세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 주변인 여행 고고\n",
      "Source Sentence:  주변인 여행 고고\n",
      "Model Prediction:  ['그', '사람', '을', '생각', '해', '보', '세요']\n",
      "Real:  ['온', '가족', '이', '모두', '마음', '에', '드', '는', '곳', '으로', '가보세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 친지 여행 어디 로서 갖\n",
      "Source Sentence:  친지 여행 어디 로서 갖\n",
      "Model Prediction:  ['썸', '사이', '사이', '에서', '말', '고', '싶', '은', '거', '같', '아요']\n",
      "Real:  ['온', '가족', '이', '모두', '마음', '에', '드', '는', '곳', '으로', '가보세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 친지 여행 언제 로서 갖\n",
      "Source Sentence:  친지 여행 언제 로서 갖\n",
      "Model Prediction:  ['썸', '사이', '사이', '에서', '말', '고', '싶', '은', '거', '같', '아요']\n",
      "Real:  ['온', '가족', '이', '모두', '마음', '에', '드', '는', '곳', '으로', '가보세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 주변인 여행 어디 로서 갖\n",
      "Source Sentence:  주변인 여행 어디 로서 갖\n",
      "Model Prediction:  ['그', '사람', '을', '생각', '해', '보', '세요']\n",
      "Real:  ['온', '가족', '이', '모두', '마음', '에', '드', '는', '곳', '으로', '가보세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 친지 항해 어디 로서 갖\n",
      "Source Sentence:  친지 항해 어디 로서 갖\n",
      "Model Prediction:  ['썸', '사이', '사이', '에서', '말', '고', '싶', '은', '거', '같', '아요']\n",
      "Real:  ['온', '가족', '이', '모두', '마음', '에', '드', '는', '곳', '으로', '가보세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 친지 끼리 여행 간다\n",
      "Source Sentence:  친지 끼리 여행 간다\n",
      "Model Prediction:  ['썸', '사이', '사이', '에서', '말', '고', '싶', '은', '거', '같', '아요']\n",
      "Real:  ['더', '가까워질', '기회', '가', '되', '겠', '네요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 친지 서로 여행 간다\n",
      "Source Sentence:  친지 서로 여행 간다\n",
      "Model Prediction:  ['썸', '사이', '사이', '에서', '말', '고', '싶', '은', '거', '같', '아요']\n",
      "Real:  ['더', '가까워질', '기회', '가', '되', '겠', '네요']\n",
      "Score: 0.000000\n",
      "\n",
      "Num of Sample: 100\n",
      "Total Score: 0.0027706248913574975\n"
     ]
    }
   ],
   "source": [
    "score = eval_bleu(transformer, src_sentences, tgt_sentences, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f236dc0",
   "metadata": {},
   "source": [
    "### t1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8a5abe",
   "metadata": {},
   "source": [
    "- n_layers: 2\n",
    "- d_model: 512\n",
    "- n_heads: 8\n",
    "- d_ff: 2048\n",
    "- dropout: 0.3\n",
    "- batch_size: 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "3c4fe4c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 지루 하 다 놀 러 가 고 싶 어\n",
      "> 시기 가 다를 뿐 이 에요\n",
      "\n",
      "- 오늘 일찍 일어났 더니 피곤 하 다\n",
      "> 그 분 이 네요\n",
      "\n",
      "- 간만에 여자 친구 랑 데이트 하 기 로 했 어\n",
      "> 생각나 적 으로 도 적 되 는 게 도 적 는지 이상 할 적 이 에요\n",
      "\n",
      "- 집 에 있 는다는 소리야\n",
      "> 내 집 마련 축하 드려요\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for question in test_questions:\n",
    "    result = translate(\" \".join(question), transformer, tokenizer)\n",
    "    print(f\"> {result}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "d2214297",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f70cb28bc02747aca7835de993635deb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 오후 돌이\n",
      "Source Sentence:  오후 돌이\n",
      "Model Prediction:  ['그', '분', '이', '네요']\n",
      "Real:  ['하루', '가', '또', '가', '네요']\n",
      "Score: 0.062571\n",
      "\n",
      "- 오후 순이\n",
      "Source Sentence:  오후 순이\n",
      "Model Prediction:  ['그', '분', '이', '네요']\n",
      "Real:  ['하루', '가', '또', '가', '네요']\n",
      "Score: 0.062571\n",
      "\n",
      "- 오전 돌이\n",
      "Source Sentence:  오전 돌이\n",
      "Model Prediction:  ['그', '분', '이', '네요']\n",
      "Real:  ['하루', '가', '또', '가', '네요']\n",
      "Score: 0.062571\n",
      "\n",
      "- 캐스터 여학교 떨어졌 어서\n",
      "Source Sentence:  캐스터 여학교 떨어졌 어서\n",
      "Model Prediction:  ['근처', '산', '에', '가보세요']\n",
      "Real:  ['위로', '해', '드립니다']\n",
      "Score: 0.000000\n",
      "\n",
      "- 캐스터 여학교 떨어졌 어\n",
      "Source Sentence:  캐스터 여학교 떨어졌 어\n",
      "Model Prediction:  ['근처', '산', '에', '가보세요']\n",
      "Real:  ['위로', '해', '드립니다']\n",
      "Score: 0.000000\n",
      "\n",
      "- 캐스터 소학교 떨어졌 어서\n",
      "Source Sentence:  캐스터 소학교 떨어졌 어서\n",
      "Model Prediction:  ['근처', '산', '에', '가보세요']\n",
      "Real:  ['위로', '해', '드립니다']\n",
      "Score: 0.000000\n",
      "\n",
      "- 캐스터 여학교 올라갔 어서\n",
      "Source Sentence:  캐스터 여학교 올라갔 어서\n",
      "Model Prediction:  ['근처', '산', '에', '가보세요']\n",
      "Real:  ['위로', '해', '드립니다']\n",
      "Score: 0.000000\n",
      "\n",
      "- 윤 월 놀 러 이 는데 싶 는데\n",
      "Source Sentence:  윤 월 놀 러 이 는데 싶 는데\n",
      "Model Prediction:  ['은', '은', '은', '은', '은', '은', '은', '은', '알', '수', '없', '어요']\n",
      "Real:  ['여행', '은', '언제나', '좋', '죠']\n",
      "Score: 0.017033\n",
      "\n",
      "- 윤 월 놀 니 이 는데 싶 는데\n",
      "Source Sentence:  윤 월 놀 니 이 는데 싶 는데\n",
      "Model Prediction:  ['은', '은', '은', '은', '은', '은', '은', '은', '알', '수', '없', '어요']\n",
      "Real:  ['여행', '은', '언제나', '좋', '죠']\n",
      "Score: 0.017033\n",
      "\n",
      "- 윤 월 놀 러 이 는데 싫 는데\n",
      "Source Sentence:  윤 월 놀 러 이 는데 싫 는데\n",
      "Model Prediction:  ['은', '은', '은', '은', '은', '은', '은', '은', '알', '수', '없', '어요']\n",
      "Real:  ['여행', '은', '언제나', '좋', '죠']\n",
      "Score: 0.017033\n",
      "\n",
      "- 윤 월 놀 러 은 는데 싶 는데\n",
      "Source Sentence:  윤 월 놀 러 은 는데 싶 는데\n",
      "Model Prediction:  ['은', '은', '은', '은', '은', '은', '은', '은', '알', '수', '없', '어요']\n",
      "Real:  ['여행', '은', '언제나', '좋', '죠']\n",
      "Score: 0.017033\n",
      "\n",
      "- 김 월 만큼 놀 거든 이 지만 싶 지만\n",
      "Source Sentence:  김 월 만큼 놀 거든 이 지만 싶 지만\n",
      "Model Prediction:  ['이제', '더', '다면', '신뢰', '을', '가', '있', '을', '거', '예요']\n",
      "Real:  ['여행', '은', '언제나', '좋', '죠']\n",
      "Score: 0.000000\n",
      "\n",
      "- 김 월 만큼 놀 거든 은 지만 싶 지만\n",
      "Source Sentence:  김 월 만큼 놀 거든 은 지만 싶 지만\n",
      "Model Prediction:  ['이제', '더', '다면', '신뢰', '을', '가', '있', '을', '거', '예요']\n",
      "Real:  ['여행', '은', '언제나', '좋', '죠']\n",
      "Score: 0.000000\n",
      "\n",
      "- 김 월 만큼 울 거든 이 지만 싶 지만\n",
      "Source Sentence:  김 월 만큼 울 거든 이 지만 싶 지만\n",
      "Model Prediction:  ['이제', '더', '다면', '신뢰', '을', '가', '있', '을', '거', '예요']\n",
      "Real:  ['여행', '은', '언제나', '좋', '죠']\n",
      "Score: 0.000000\n",
      "\n",
      "- 윤 월 만큼 놀 거든 이 지만 싶 지만\n",
      "Source Sentence:  윤 월 만큼 놀 거든 이 지만 싶 지만\n",
      "Model Prediction:  ['은', '은', '은', '은', '은', '은', '은', '은', '알', '수', '없', '어요']\n",
      "Real:  ['여행', '은', '언제나', '좋', '죠']\n",
      "Score: 0.017033\n",
      "\n",
      "- ppl 약하 다섯\n",
      "Source Sentence:  ppl 약하 다섯\n",
      "Model Prediction:  ['잘', '모르', '겠', '지요']\n",
      "Real:  ['눈살', '이', '찌푸려', '지', '죠']\n",
      "Score: 0.000000\n",
      "\n",
      "- ppl 강하 다섯\n",
      "Source Sentence:  ppl 강하 다섯\n",
      "Model Prediction:  ['잘', '모르', '겠', '지요']\n",
      "Real:  ['눈살', '이', '찌푸려', '지', '죠']\n",
      "Score: 0.000000\n",
      "\n",
      "- ppl 약하 여섯\n",
      "Source Sentence:  ppl 약하 여섯\n",
      "Model Prediction:  ['잘', '모르', '겠', '지요']\n",
      "Real:  ['눈살', '이', '찌푸려', '지', '죠']\n",
      "Score: 0.000000\n",
      "\n",
      "- cp 단말 아름다웠 어\n",
      "Source Sentence:  cp 단말 아름다웠 어\n",
      "Model Prediction:  ['자신', '만', '의', '자신']\n",
      "Real:  ['다시', '새로', '사', '는', '게', '마음', '편해요']\n",
      "Score: 0.000000\n",
      "\n",
      "- perl 단말 아름다웠 어\n",
      "Source Sentence:  perl 단말 아름다웠 어\n",
      "Model Prediction:  ['잘', '모르', '겠', '지요']\n",
      "Real:  ['다시', '새로', '사', '는', '게', '마음', '편해요']\n",
      "Score: 0.000000\n",
      "\n",
      "- cp 단말 기뻐했 어\n",
      "Source Sentence:  cp 단말 기뻐했 어\n",
      "Model Prediction:  ['자신', '만', '의', '자신']\n",
      "Real:  ['다시', '새로', '사', '는', '게', '마음', '편해요']\n",
      "Score: 0.000000\n",
      "\n",
      "- cp 모뎀 아름다웠 어\n",
      "Source Sentence:  cp 모뎀 아름다웠 어\n",
      "Model Prediction:  ['자신', '만', '의', '자신']\n",
      "Real:  ['다시', '새로', '사', '는', '게', '마음', '편해요']\n",
      "Score: 0.000000\n",
      "\n",
      "- perl 모뎀 앞 됐으며\n",
      "Source Sentence:  perl 모뎀 앞 됐으며\n",
      "Model Prediction:  ['잘', '모르', '겠', '지요']\n",
      "Real:  ['다시', '새로', '사', '는', '게', '마음', '편해요']\n",
      "Score: 0.000000\n",
      "\n",
      "- perl 모뎀 앞 됐으나\n",
      "Source Sentence:  perl 모뎀 앞 됐으나\n",
      "Model Prediction:  ['잘', '모르', '겠', '지요']\n",
      "Real:  ['다시', '새로', '사', '는', '게', '마음', '편해요']\n",
      "Score: 0.000000\n",
      "\n",
      "- perl 모뎀 옆 됐으며\n",
      "Source Sentence:  perl 모뎀 옆 됐으며\n",
      "Model Prediction:  ['잘', '모르', '겠', '지요']\n",
      "Real:  ['다시', '새로', '사', '는', '게', '마음', '편해요']\n",
      "Score: 0.000000\n",
      "\n",
      "- cp 모뎀 앞 됐으며\n",
      "Source Sentence:  cp 모뎀 앞 됐으며\n",
      "Model Prediction:  ['자신', '만', '의', '자신']\n",
      "Real:  ['다시', '새로', '사', '는', '게', '마음', '편해요']\n",
      "Score: 0.000000\n",
      "\n",
      "- casework 주저앉 팔 정말로 옆 하 당치\n",
      "Source Sentence:  casework 주저앉 팔 정말로 옆 하 당치\n",
      "Model Prediction:  ['자신', '만', '의', '자신']\n",
      "Real:  ['잘', '모르', '고', '있', '을', '수', '도', '있', '어요']\n",
      "Score: 0.000000\n",
      "\n",
      "- casework 주저앉 빨 정말로 옆 하 당치\n",
      "Source Sentence:  casework 주저앉 빨 정말로 옆 하 당치\n",
      "Model Prediction:  ['자신', '만', '의', '자신']\n",
      "Real:  ['잘', '모르', '고', '있', '을', '수', '도', '있', '어요']\n",
      "Score: 0.000000\n",
      "\n",
      "- casework 주저앉 팔 정말로 옆 시키 당치\n",
      "Source Sentence:  casework 주저앉 팔 정말로 옆 시키 당치\n",
      "Model Prediction:  ['자신', '만', '의', '자신']\n",
      "Real:  ['잘', '모르', '고', '있', '을', '수', '도', '있', '어요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 케이스워크 주저앉 팔 정말로 옆 하 당치\n",
      "Source Sentence:  케이스워크 주저앉 팔 정말로 옆 하 당치\n",
      "Model Prediction:  ['충분히', '충분히', '충분히', '충분히', '충분히', '충분히', '충분히', '아름다워요']\n",
      "Real:  ['잘', '모르', '고', '있', '을', '수', '도', '있', '어요']\n",
      "Score: 0.000000\n",
      "\n",
      "- sns 분 절약 , 거 아 는데 아침 꾀하 은 중\n",
      "Source Sentence:  sns 분 절약 , 거 아 는데 아침 꾀하 은 중\n",
      "Model Prediction:  ['잘', '모르', '겠', '지요']\n",
      "Real:  ['시간', '을', '정하', '고', '해', '보', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- sns 분 절약 , 거 아 지만 아침 꾀하 은 중\n",
      "Source Sentence:  sns 분 절약 , 거 아 지만 아침 꾀하 은 중\n",
      "Model Prediction:  ['잘', '모르', '겠', '지요']\n",
      "Real:  ['시간', '을', '정하', '고', '해', '보', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- sns 초간 절약 , 거 아 는데 아침 꾀하 은 중\n",
      "Source Sentence:  sns 초간 절약 , 거 아 는데 아침 꾀하 은 중\n",
      "Model Prediction:  ['잘', '모르', '겠', '지요']\n",
      "Real:  ['시간', '을', '정하', '고', '해', '보', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- sns 분 절약 , 거 아 는데 아침 시키 은 중\n",
      "Source Sentence:  sns 분 절약 , 거 아 는데 아침 시키 은 중\n",
      "Model Prediction:  ['잘', '모르', '겠', '지요']\n",
      "Real:  ['시간', '을', '정하', '고', '해', '보', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 케이스워크 시간 조달 라면 혹시 알아채 게끔 이루어짐\n",
      "Source Sentence:  케이스워크 시간 조달 라면 혹시 알아채 게끔 이루어짐\n",
      "Model Prediction:  ['충분히', '충분히', '충분히', '충분히', '충분히', '충분히', '충분히', '아름다워요']\n",
      "Real:  ['시간', '을', '정하', '고', '해', '보', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 케이스워크 시간 조달 라면 누가 알아채 게끔 이루어짐\n",
      "Source Sentence:  케이스워크 시간 조달 라면 누가 알아채 게끔 이루어짐\n",
      "Model Prediction:  ['충분히', '충분히', '충분히', '충분히', '충분히', '충분히', '충분히', '아름다워요']\n",
      "Real:  ['시간', '을', '정하', '고', '해', '보', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 케이스워크 시간 조달 라면 혹시 알아채 게끔 들어옴\n",
      "Source Sentence:  케이스워크 시간 조달 라면 혹시 알아채 게끔 들어옴\n",
      "Model Prediction:  ['충분히', '충분히', '충분히', '충분히', '충분히', '충분히', '충분히', '아름다워요']\n",
      "Real:  ['시간', '을', '정하', '고', '해', '보', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 케이스워크 분 조달 라면 혹시 알아채 게끔 이루어짐\n",
      "Source Sentence:  케이스워크 분 조달 라면 혹시 알아채 게끔 이루어짐\n",
      "Model Prediction:  ['충분히', '충분히', '충분히', '충분히', '충분히', '충분히', '충분히', '아름다워요']\n",
      "Real:  ['시간', '을', '정하', '고', '해', '보', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 케이스워크 보 면 나 만 때리 는데 다 행복 해 보여\n",
      "Source Sentence:  케이스워크 보 면 나 만 때리 는데 다 행복 해 보여\n",
      "Model Prediction:  ['충분히', '충분히', '충분히', '충분히', '충분히', '충분히', '충분히', '아름다워요']\n",
      "Real:  ['자랑', '하', '는', '자리', '니까요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 케이스워크 보 면 나 만 걷어차 는데 다 행복 해 보여\n",
      "Source Sentence:  케이스워크 보 면 나 만 걷어차 는데 다 행복 해 보여\n",
      "Model Prediction:  ['충분히', '충분히', '충분히', '충분히', '충분히', '충분히', '충분히', '아름다워요']\n",
      "Real:  ['자랑', '하', '는', '자리', '니까요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 케이스워크 보 면 나 만 때리 는데 다 행복 해서 보여\n",
      "Source Sentence:  케이스워크 보 면 나 만 때리 는데 다 행복 해서 보여\n",
      "Model Prediction:  ['충분히', '충분히', '충분히', '충분히', '충분히', '충분히', '충분히', '아름다워요']\n",
      "Real:  ['자랑', '하', '는', '자리', '니까요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 케이스워크 보 면 나 만 때리 는데 는데 행복 해 보여\n",
      "Source Sentence:  케이스워크 보 면 나 만 때리 는데 는데 행복 해 보여\n",
      "Model Prediction:  ['충분히', '충분히', '충분히', '충분히', '충분히', '충분히', '충분히', '아름다워요']\n",
      "Real:  ['자랑', '하', '는', '자리', '니까요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가끔 의아 해\n",
      "Source Sentence:  가끔 의아 해\n",
      "Model Prediction:  ['저', '요']\n",
      "Real:  ['그', '사람', '도', '그럴', '거', '예요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 이따금 의아 해\n",
      "Source Sentence:  이따금 의아 해\n",
      "Model Prediction:  ['알', '수', '없', '는', '게', '사랑', '이', '에요']\n",
      "Real:  ['그', '사람', '도', '그럴', '거', '예요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가끔 흡족 해\n",
      "Source Sentence:  가끔 흡족 해\n",
      "Model Prediction:  ['저', '요']\n",
      "Real:  ['그', '사람', '도', '그럴', '거', '예요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가끔 의아 해서\n",
      "Source Sentence:  가끔 의아 해서\n",
      "Model Prediction:  ['저', '요']\n",
      "Real:  ['그', '사람', '도', '그럴', '거', '예요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가끔 뭐 꾀하 는지 의아 해\n",
      "Source Sentence:  가끔 뭐 꾀하 는지 의아 해\n",
      "Model Prediction:  ['저', '요']\n",
      "Real:  ['그', '사람', '도', '그럴', '거', '예요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가끔 어쩌 꾀하 는지 의아 해\n",
      "Source Sentence:  가끔 어쩌 꾀하 는지 의아 해\n",
      "Model Prediction:  ['저', '요']\n",
      "Real:  ['그', '사람', '도', '그럴', '거', '예요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가끔 뭐 시키 는지 의아 해\n",
      "Source Sentence:  가끔 뭐 시키 는지 의아 해\n",
      "Model Prediction:  ['저', '요']\n",
      "Real:  ['그', '사람', '도', '그럴', '거', '예요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가끔 뭐 꾀하 는가 의아 해\n",
      "Source Sentence:  가끔 뭐 꾀하 는가 의아 해\n",
      "Model Prediction:  ['저', '요']\n",
      "Real:  ['그', '사람', '도', '그럴', '거', '예요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가끔 은 혼자 의 게 좋 다\n",
      "Source Sentence:  가끔 은 혼자 의 게 좋 다\n",
      "Model Prediction:  ['저', '요']\n",
      "Real:  ['혼자', '를', '즐기', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가끔 은 혼자 의 도록 좋 다\n",
      "Source Sentence:  가끔 은 혼자 의 도록 좋 다\n",
      "Model Prediction:  ['저', '요']\n",
      "Real:  ['혼자', '를', '즐기', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가끔 은 거기 의 게 좋 다\n",
      "Source Sentence:  가끔 은 거기 의 게 좋 다\n",
      "Model Prediction:  ['저', '요']\n",
      "Real:  ['혼자', '를', '즐기', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가끔 은 혼자 의 게 좋 는데\n",
      "Source Sentence:  가끔 은 혼자 의 게 좋 는데\n",
      "Model Prediction:  ['저', '요']\n",
      "Real:  ['혼자', '를', '즐기', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가난 한 자 의 슬픔\n",
      "Source Sentence:  가난 한 자 의 슬픔\n",
      "Model Prediction:  ['저', '요']\n",
      "Real:  ['돈', '은', '다시', '들어올', '거', '예요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가난 한 면서 의 슬픔\n",
      "Source Sentence:  가난 한 면서 의 슬픔\n",
      "Model Prediction:  ['저', '요']\n",
      "Real:  ['돈', '은', '다시', '들어올', '거', '예요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 부유 한 자 의 슬픔\n",
      "Source Sentence:  부유 한 자 의 슬픔\n",
      "Model Prediction:  ['이제', '최선', '의', '선택', '일거', '예요']\n",
      "Real:  ['돈', '은', '다시', '들어올', '거', '예요']\n",
      "Score: 0.040825\n",
      "\n",
      "- 가난 한 자 , 슬픔\n",
      "Source Sentence:  가난 한 자 , 슬픔\n",
      "Model Prediction:  ['저', '요']\n",
      "Real:  ['돈', '은', '다시', '들어올', '거', '예요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가만 없 어도 땀 난다\n",
      "Source Sentence:  가만 없 어도 땀 난다\n",
      "Model Prediction:  ['저', '요']\n",
      "Real:  ['땀', '을', '식혀', '주', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가국 없 어도 땀 난다\n",
      "Source Sentence:  가국 없 어도 땀 난다\n",
      "Model Prediction:  ['저', '요']\n",
      "Real:  ['땀', '을', '식혀', '주', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가만 있 어도 땀 난다\n",
      "Source Sentence:  가만 있 어도 땀 난다\n",
      "Model Prediction:  ['저', '요']\n",
      "Real:  ['땀', '을', '식혀', '주', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가만 없 어도 땀 생긴다\n",
      "Source Sentence:  가만 없 어도 땀 생긴다\n",
      "Model Prediction:  ['저', '요']\n",
      "Real:  ['땀', '을', '식혀', '주', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가상현실 화폐 서요 망함\n",
      "Source Sentence:  가상현실 화폐 서요 망함\n",
      "Model Prediction:  ['저', '요']\n",
      "Real:  ['어서', '잊', '고', '새', '출발', '하', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가상현실 화폐 대리국 망함\n",
      "Source Sentence:  가상현실 화폐 대리국 망함\n",
      "Model Prediction:  ['저', '요']\n",
      "Real:  ['어서', '잊', '고', '새', '출발', '하', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가상현실 화폐 서요 들려줌\n",
      "Source Sentence:  가상현실 화폐 서요 들려줌\n",
      "Model Prediction:  ['저', '요']\n",
      "Real:  ['어서', '잊', '고', '새', '출발', '하', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가상현실 통화 서요 망함\n",
      "Source Sentence:  가상현실 통화 서요 망함\n",
      "Model Prediction:  ['저', '요']\n",
      "Real:  ['어서', '잊', '고', '새', '출발', '하', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 냉각재 불 켜 고 갔 어\n",
      "Source Sentence:  냉각재 불 켜 고 갔 어\n",
      "Model Prediction:  ['잘', '모르', '겠', '지요']\n",
      "Real:  ['빨리', '집', '에', '돌아가', '서', '끄', '고', '나오', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 냉각재 불 켜 고 나갔 어\n",
      "Source Sentence:  냉각재 불 켜 고 나갔 어\n",
      "Model Prediction:  ['잘', '모르', '겠', '지요']\n",
      "Real:  ['빨리', '집', '에', '돌아가', '서', '끄', '고', '나오', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 냉각재 불 당겨 고 갔 어\n",
      "Source Sentence:  냉각재 불 당겨 고 갔 어\n",
      "Model Prediction:  ['잘', '모르', '겠', '지요']\n",
      "Real:  ['빨리', '집', '에', '돌아가', '서', '끄', '고', '나오', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 냉각수 불 켜 고 갔 어\n",
      "Source Sentence:  냉각수 불 켜 고 갔 어\n",
      "Model Prediction:  ['잘', '모르', '겠', '지요']\n",
      "Real:  ['빨리', '집', '에', '돌아가', '서', '끄', '고', '나오', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가스 성 켜 놓 는데 나온 건가 같 아\n",
      "Source Sentence:  가스 성 켜 놓 는데 나온 건가 같 아\n",
      "Model Prediction:  ['저', '요']\n",
      "Real:  ['빨리', '집', '에', '돌아가', '서', '끄', '고', '나오', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가스 성 켜 놓 는데 나타난 건가 같 아\n",
      "Source Sentence:  가스 성 켜 놓 는데 나타난 건가 같 아\n",
      "Model Prediction:  ['저', '요']\n",
      "Real:  ['빨리', '집', '에', '돌아가', '서', '끄', '고', '나오', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가스 성 당겨 놓 는데 나온 건가 같 아\n",
      "Source Sentence:  가스 성 당겨 놓 는데 나온 건가 같 아\n",
      "Model Prediction:  ['저', '요']\n",
      "Real:  ['빨리', '집', '에', '돌아가', '서', '끄', '고', '나오', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가스 성 켜 늘어놓 는데 나온 건가 같 아\n",
      "Source Sentence:  가스 성 켜 늘어놓 는데 나온 건가 같 아\n",
      "Model Prediction:  ['저', '요']\n",
      "Real:  ['빨리', '집', '에', '돌아가', '서', '끄', '고', '나오', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 냉각수 비 너무 많이 올라왔 는데\n",
      "Source Sentence:  냉각수 비 너무 많이 올라왔 는데\n",
      "Model Prediction:  ['잘', '모르', '겠', '지요']\n",
      "Real:  ['다음', '달', '에', '는', '더', '절약', '해봐요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 냉각수 비 너무 많이 나왔 는데\n",
      "Source Sentence:  냉각수 비 너무 많이 나왔 는데\n",
      "Model Prediction:  ['잘', '모르', '겠', '지요']\n",
      "Real:  ['다음', '달', '에', '는', '더', '절약', '해봐요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 냉각수 비 너무 많이 올라왔 지만\n",
      "Source Sentence:  냉각수 비 너무 많이 올라왔 지만\n",
      "Model Prediction:  ['잘', '모르', '겠', '지요']\n",
      "Real:  ['다음', '달', '에', '는', '더', '절약', '해봐요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 냉각수 비 너무 잘 올라왔 는데\n",
      "Source Sentence:  냉각수 비 너무 잘 올라왔 는데\n",
      "Model Prediction:  ['잘', '모르', '겠', '지요']\n",
      "Real:  ['다음', '달', '에', '는', '더', '절약', '해봐요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 냉각수 침습 비싼데 감기 걸렸 겠 어\n",
      "Source Sentence:  냉각수 침습 비싼데 감기 걸렸 겠 어\n",
      "Model Prediction:  ['잘', '모르', '겠', '지요']\n",
      "Real:  ['따뜻', '하', '게', '사세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 냉각수 비가역 비싼데 감기 걸렸 겠 어\n",
      "Source Sentence:  냉각수 비가역 비싼데 감기 걸렸 겠 어\n",
      "Model Prediction:  ['잘', '모르', '겠', '지요']\n",
      "Real:  ['따뜻', '하', '게', '사세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 냉각수 침습 비싼데 감기 걸렸 겠 어서\n",
      "Source Sentence:  냉각수 침습 비싼데 감기 걸렸 겠 어서\n",
      "Model Prediction:  ['잘', '모르', '겠', '지요']\n",
      "Real:  ['따뜻', '하', '게', '사세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 냉각수 침습 비싼데 감기 걸렸 셨 어\n",
      "Source Sentence:  냉각수 침습 비싼데 감기 걸렸 셨 어\n",
      "Model Prediction:  ['잘', '모르', '겠', '지요']\n",
      "Real:  ['따뜻', '하', '게', '사세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 냉각수 침습 장난 임\n",
      "Source Sentence:  냉각수 침습 장난 임\n",
      "Model Prediction:  ['잘', '모르', '겠', '지요']\n",
      "Real:  ['다음', '달', '에', '는', '더', '절약', '해봐요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 냉각재 침습 장난 임\n",
      "Source Sentence:  냉각재 침습 장난 임\n",
      "Model Prediction:  ['잘', '모르', '겠', '지요']\n",
      "Real:  ['다음', '달', '에', '는', '더', '절약', '해봐요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 냉각수 침습 장난 아님\n",
      "Source Sentence:  냉각수 침습 장난 아님\n",
      "Model Prediction:  ['잘', '모르', '겠', '지요']\n",
      "Real:  ['다음', '달', '에', '는', '더', '절약', '해봐요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 냉각수 침습 농담 임\n",
      "Source Sentence:  냉각수 침습 농담 임\n",
      "Model Prediction:  ['잘', '모르', '겠', '지요']\n",
      "Real:  ['다음', '달', '에', '는', '더', '절약', '해봐요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가족 여행 은 기 로서 했 어\n",
      "Source Sentence:  가족 여행 은 기 로서 했 어\n",
      "Model Prediction:  ['저', '요']\n",
      "Real:  ['온', '가족', '이', '모두', '마음', '에', '드', '는', '곳', '으로', '가보세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가족 항해 은 기 로서 했 어\n",
      "Source Sentence:  가족 항해 은 기 로서 했 어\n",
      "Model Prediction:  ['저', '요']\n",
      "Real:  ['온', '가족', '이', '모두', '마음', '에', '드', '는', '곳', '으로', '가보세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가족 여행 은 고자 로서 했 어\n",
      "Source Sentence:  가족 여행 은 고자 로서 했 어\n",
      "Model Prediction:  ['저', '요']\n",
      "Real:  ['온', '가족', '이', '모두', '마음', '에', '드', '는', '곳', '으로', '가보세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가족 여행 은 기 로서 했 어서\n",
      "Source Sentence:  가족 여행 은 기 로서 했 어서\n",
      "Model Prediction:  ['저', '요']\n",
      "Real:  ['온', '가족', '이', '모두', '마음', '에', '드', '는', '곳', '으로', '가보세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 친지 여행 고고\n",
      "Source Sentence:  친지 여행 고고\n",
      "Model Prediction:  ['보', '세요']\n",
      "Real:  ['온', '가족', '이', '모두', '마음', '에', '드', '는', '곳', '으로', '가보세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 친지 항해 고고\n",
      "Source Sentence:  친지 항해 고고\n",
      "Model Prediction:  ['보', '세요']\n",
      "Real:  ['온', '가족', '이', '모두', '마음', '에', '드', '는', '곳', '으로', '가보세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 친지 여행 다용\n",
      "Source Sentence:  친지 여행 다용\n",
      "Model Prediction:  ['보', '세요']\n",
      "Real:  ['온', '가족', '이', '모두', '마음', '에', '드', '는', '곳', '으로', '가보세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 주변인 여행 고고\n",
      "Source Sentence:  주변인 여행 고고\n",
      "Model Prediction:  ['소주', '한', '잔']\n",
      "Real:  ['온', '가족', '이', '모두', '마음', '에', '드', '는', '곳', '으로', '가보세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 친지 여행 어디 로서 갖\n",
      "Source Sentence:  친지 여행 어디 로서 갖\n",
      "Model Prediction:  ['보', '세요']\n",
      "Real:  ['온', '가족', '이', '모두', '마음', '에', '드', '는', '곳', '으로', '가보세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 친지 여행 언제 로서 갖\n",
      "Source Sentence:  친지 여행 언제 로서 갖\n",
      "Model Prediction:  ['보', '세요']\n",
      "Real:  ['온', '가족', '이', '모두', '마음', '에', '드', '는', '곳', '으로', '가보세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 주변인 여행 어디 로서 갖\n",
      "Source Sentence:  주변인 여행 어디 로서 갖\n",
      "Model Prediction:  ['소주', '한', '잔']\n",
      "Real:  ['온', '가족', '이', '모두', '마음', '에', '드', '는', '곳', '으로', '가보세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 친지 항해 어디 로서 갖\n",
      "Source Sentence:  친지 항해 어디 로서 갖\n",
      "Model Prediction:  ['보', '세요']\n",
      "Real:  ['온', '가족', '이', '모두', '마음', '에', '드', '는', '곳', '으로', '가보세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 친지 끼리 여행 간다\n",
      "Source Sentence:  친지 끼리 여행 간다\n",
      "Model Prediction:  ['보', '세요']\n",
      "Real:  ['더', '가까워질', '기회', '가', '되', '겠', '네요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 친지 서로 여행 간다\n",
      "Source Sentence:  친지 서로 여행 간다\n",
      "Model Prediction:  ['보', '세요']\n",
      "Real:  ['더', '가까워질', '기회', '가', '되', '겠', '네요']\n",
      "Score: 0.000000\n",
      "\n",
      "Num of Sample: 100\n",
      "Total Score: 0.0031370396377935735\n"
     ]
    }
   ],
   "source": [
    "score = eval_bleu(transformer, src_sentences, tgt_sentences, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c3a254",
   "metadata": {},
   "source": [
    "### t2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7792fb8b",
   "metadata": {},
   "source": [
    "- n_layers: 2\n",
    "- d_model: 512\n",
    "- n_heads: 8\n",
    "- d_ff: 2048\n",
    "- dropout: 0.3\n",
    "- batch_size: 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "ad2b538e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 지루 하 다 놀 러 가 고 싶 어\n",
      "> 죠\n",
      "\n",
      "- 오늘 일찍 일어났 더니 피곤 하 다\n",
      "> 따뜻 할 시기 네요\n",
      "\n",
      "- 간만에 여자 친구 랑 데이트 하 기 로 했 어\n",
      "> 헤어짐 은 헤어짐 은 헤어짐 을 좋아하 헤어짐 도 으로 습니다\n",
      "\n",
      "- 집 에 있 는다는 소리야\n",
      "> 조심히 오 세요\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for question in test_questions:\n",
    "    result = translate(\" \".join(question), transformer, tokenizer)\n",
    "    print(f\"> {result}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "8e617c53",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 아 벌 받 고 있 는 건가 네\n",
      "Model Prediction:  수십 번 어야 하나 봅니다\n",
      "Real:  달 게 받 으세요\n",
      "Score: 0.000000\n",
      "\n",
      "- 헤어진지 열흘 됐 는데 연락 하 고 싶 다섯\n",
      "Model Prediction:  서로 에게 부담 없 는 선물 이 좋 아요\n",
      "Real:  후회 하 지 않 는다면 연락 해 보 세요\n",
      "Score: 0.000000\n",
      "\n",
      "- 머리카락 이 정말 빠져\n",
      "Model Prediction:  저 도 그러 그러 그러 그러 그러 그러 그러 는 게 좋 겠 어요\n",
      "Real:  스트레스 받 지 마세요\n",
      "Score: 0.000000\n",
      "\n",
      "- 자율 주행 승용차 나오 겠 지\n",
      "Model Prediction:  기다리 고 말 이 기다리 고 말 고 기다리 고 기다리 고 기다리 세요\n",
      "Real:  가까운 미래 에 나올 거 같 아요\n",
      "Score: 0.000000\n",
      "\n",
      "- 죽 고 못 사 는 관계\n",
      "Model Prediction:  나쁜 생각 멈추 나쁜 나쁜 나쁜 생각 멈추 세요\n",
      "Real:  연애 할 때 가능 하 죠\n",
      "Score: 0.000000\n",
      "\n",
      "- 졸업식 에 가 도 된 나\n",
      "Model Prediction:  잠 을 깨 요 기운 내요\n",
      "Real:  졸업식 에 가 서 축하 해 주 세요\n",
      "Score: 0.000000\n",
      "\n",
      "- 공허 하 네\n",
      "Model Prediction:  죠\n",
      "Real:  제 가 채워줄 게요\n",
      "Score: 0.000000\n",
      "\n",
      "- 여지 를 준 짝 녀 버려야 겠죠\n",
      "Model Prediction:  잘 견뎌 내 상대방 이 에요\n",
      "Real:  오해 가 아니 라면 정리 하 는 게 덜 상처 일 것 같 아요\n",
      "Score: 0.000000\n",
      "\n",
      "- 농사 짓 고 다른가\n",
      "Model Prediction:  서로 에게 부담 없 는 선물 이 좋 아요\n",
      "Real:  생각 하 기 는 쉬운데 실천 하 기 는 어려운 것 같 아요\n",
      "Score: 0.018285\n",
      "\n",
      "- 술 을 마시 러 나갈까 어디 론가 떠나 볼까\n",
      "Model Prediction:  연락 이 후 에 연락 하 는 잔 하 기 좋 죠\n",
      "Real:  어디 든 좋 죠\n",
      "Score: 0.036021\n",
      "\n",
      "- 강우 땜 에 눈 아파\n",
      "Model Prediction:  잊 고 새 출발 하 고 사랑 을 생각 해 보 세요\n",
      "Real:  이쁜 마스크 사 드리 고 싶 네요\n",
      "Score: 0.017033\n",
      "\n",
      "- 너무 가슴 이 조르 네\n",
      "Model Prediction:  죠\n",
      "Real:  무슨 마음 인지 알 겠 어서 더 마음 이 아프 네요\n",
      "Score: 0.000000\n",
      "\n",
      "- 정말 예쁘 고 죽 고 싶 어\n",
      "Model Prediction:  사랑 의 일부 로 이유 를 가 쉬운 일 이 었 을 것 같 아요\n",
      "Real:  당신 은 누구 보다 소중 한 사람 이 에요\n",
      "Score: 0.013218\n",
      "\n",
      "- 좋 아 하 는 사람 도 에 공부 를 못 하 겠 어\n",
      "Model Prediction:  마음 의 정리 가 안 좋 겠 어요\n",
      "Real:  충분히 그럴 수 있 어요\n",
      "Score: 0.027776\n",
      "\n",
      "- 결국 약혼 했 어\n",
      "Model Prediction:  서로 에게 부담 없 는 선물 이 좋 아요\n",
      "Real:  마음 이 더 복잡 하 겠 어요\n",
      "Score: 0.023980\n",
      "\n",
      "- 정말로 돌아올까\n",
      "Model Prediction:  사랑 의 일부 로 이유 를 가 쉬운 일 이 었 을 것 같 아요\n",
      "Real:  돌아오 길 바란다면 연락 해 보 세요\n",
      "Score: 0.000000\n",
      "\n",
      "- 이렇게 가짜 끝 인 걸까\n",
      "Model Prediction:  사랑 이 모두 정답 이 될 거 예요\n",
      "Real:  인연 이 거기 까지 인 가 봐요\n",
      "Score: 0.027776\n",
      "\n",
      "- 먹통 이 야 침울 하 다\n",
      "Model Prediction:  드세요\n",
      "Real:  대화 의 눈높이 가 맞 는 사람 만나 세요\n",
      "Score: 0.000000\n",
      "\n",
      "- 요즘 제정신 이 오로지 야\n",
      "Model Prediction:  좋 죠\n",
      "Real:  그럴 때 가 있 죠\n",
      "Score: 0.033366\n",
      "\n",
      "- 술 이 주꾸미 도 아니 고\n",
      "Model Prediction:  연락 이 후 에 연락 하 는 잔 하 기 좋 죠\n",
      "Real:  술 은 끊 는 게 좋 죠\n",
      "Score: 0.039864\n",
      "\n",
      "- 여자 친구 가 말 를 듣 기 좋 게 해\n",
      "Model Prediction:  잘 견뎌 내 상대방 이 에요\n",
      "Real:  말 도 예쁘 게 하 는 사람 이 네요\n",
      "Score: 0.024762\n",
      "\n",
      "- 여지 를 준 짝 녀 봐야 겠죠\n",
      "Model Prediction:  잘 견뎌 내 상대방 이 에요\n",
      "Real:  오해 가 아니 라면 정리 하 는 게 덜 상처 일 것 같 아요\n",
      "Score: 0.000000\n",
      "\n",
      "- 상사병 극복 하 고 싶 어\n",
      "Model Prediction:  축하 합니다\n",
      "Real:  시간 이 해결 해 줄 거 예요\n",
      "Score: 0.000000\n",
      "\n",
      "- 밥 너무 많이 함\n",
      "Model Prediction:  죠\n",
      "Real:  소분 해서 냉동실 에 보관 해 보 세요\n",
      "Score: 0.000000\n",
      "\n",
      "- 그냥 차단 과 하 지\n",
      "Model Prediction:  좋 아 했 봅니다\n",
      "Real:  스스로 에게 하 는 말 인가요\n",
      "Score: 0.000000\n",
      "\n",
      "- 짝 녀 가 어떻게 하 면 내 확신 을 하 게 할까\n",
      "Model Prediction:  나쁜 생각 멈추 세요\n",
      "Real:  우선 꾸준히 연락 하 고 잘 해 줘 보 세요\n",
      "Score: 0.017927\n",
      "\n",
      "- 사람 이 변하 든\n",
      "Model Prediction:  살 면서 들 이 좋 아 하 앞 으로 살 면서 살 아서 더 좋 겠 네요\n",
      "Real:  사랑 은 변하 고 사람 은 안 변해요\n",
      "Score: 0.000000\n",
      "\n",
      "- 충동 감 이 떨어져 있 는 지금\n",
      "Model Prediction:  말 해 보 세요 생각 해 볼게요\n",
      "Real:  저 도 진짜 힘들 었 는데 지금 은 좋 은 사람 만나 행복 해요\n",
      "Score: 0.000000\n",
      "\n",
      "- 헤어진지 달 반 정도 됬 네\n",
      "Model Prediction:  서로 에게 부담 없 는 선물 이 좋 아요\n",
      "Real:  금방 지나갈 거 예요\n",
      "Score: 0.000000\n",
      "\n",
      "- 집착 같 아서\n",
      "Model Prediction:  조심히 오 세요\n",
      "Real:  차분히 생각 해 보 세요 사랑 은 소유 가 아니 에요\n",
      "Score: 0.007895\n",
      "\n",
      "- 썸 타 는 건가 티 내 고 싶 진 않 아\n",
      "Model Prediction:  짧 으면 짧 을 수록 좋 겠 지요\n",
      "Real:  누구 에게 요\n",
      "Score: 0.000000\n",
      "\n",
      "- 제 외국어 뭐 선택 합니까\n",
      "Model Prediction:  서로 사랑 으로 잊 는 거 같 네요\n",
      "Real:  요즘 은 잘 안 배우 는 언어 도 좋 은 거 같 아요\n",
      "Score: 0.034795\n",
      "\n",
      "- 못하 된 사람\n",
      "Model Prediction:  당신\n",
      "Real:  못 된 사람 은 이제 잊 어 버려요\n",
      "Score: 0.000000\n",
      "\n",
      "- 이별 의 시간\n",
      "Model Prediction:  사랑 이 모두 정답 이 될 거 예요\n",
      "Real:  길 지 않 길 바랄 게요\n",
      "Score: 0.000000\n",
      "\n",
      "- 이런 게 동거 니\n",
      "Model Prediction:  사랑 이 모두 정답 이 될 거 예요\n",
      "Real:  알 다가 도 모르 는 게 연애 같 아요\n",
      "Score: 0.000000\n",
      "\n",
      "- 휴 반년 이 라는 시간 잊 었 다 생각 했 지만 또 다시\n",
      "Model Prediction:  아이구\n",
      "Real:  후폭풍 이 무섭 죠\n",
      "Score: 0.000000\n",
      "\n",
      "- 짝 남 에게 밤 에 자주 산책 하 려고 해도 될까\n",
      "Model Prediction:  나쁜 생각 멈추 세요\n",
      "Real:  밤 데이트 신청 멋지 네요\n",
      "Score: 0.000000\n",
      "\n",
      "- 취업 못 시키 는 기간 이 길 어 진다\n",
      "Model Prediction:  긴 시간 이 겠 어요\n",
      "Real:  다음 공채 때 는 될 거 예요\n",
      "Score: 0.000000\n",
      "\n",
      "- 혼자 썸 타 는 기분 은 야\n",
      "Model Prediction:  조금 만 더 견뎌 받 지 세요\n",
      "Real:  직접 적 이 든 간접 적 이 든 의사 를 확실히 밝혀 보 세요\n",
      "Score: 0.012152\n",
      "\n",
      "- 좋 아 하 은 감정 이 나 를 슬프 게 도 해\n",
      "Model Prediction:  마음 의 정리 가 안 좋 겠 어요\n",
      "Real:  사랑 과 슬픔 은 동전 의 양면 과 같 죠\n",
      "Score: 0.021632\n",
      "\n",
      "- 태 핑 할까\n",
      "Model Prediction:  항상 못 해 본 는 일 이 있 는 것 같 아요\n",
      "Real:  구릿빛 피부 좋 죠\n",
      "Score: 0.000000\n",
      "\n",
      "- 자꾸 뭘 사 게 돼\n",
      "Model Prediction:  기다리 고 말 이 기다리 고 말 고 기다리 고 기다리 고 기다리 세요\n",
      "Real:  마음 이 헛헛 한가 봐요\n",
      "Score: 0.014284\n",
      "\n",
      "- 음식 많이 가리 는 남자 를 사 겨 도 괜찮 습니까\n",
      "Model Prediction:  음\n",
      "Real:  다 먹 으면 좋 겠 지만 큰 문제 는 되 지 않 을 거 예요\n",
      "Score: 0.000000\n",
      "\n",
      "- 뭔 비밀 이 그렇게 높 은지\n",
      "Model Prediction:  긴 시간 이 었 을 수 있 을 거 예요\n",
      "Real:  하나 씩 비밀 을 공유 해 보 세요\n",
      "Score: 0.021105\n",
      "\n",
      "- 구 썸남 보 고 싶 어서\n",
      "Model Prediction:  조급 하 게 생각 하 지 마세요\n",
      "Real:  썸 으로 끝날 사이 가 아니 었 네요\n",
      "Score: 0.000000\n",
      "\n",
      "- 상처 받 고자 싫 다\n",
      "Model Prediction:  축하 합니다\n",
      "Real:  무덤덤 해질 수 있 거예요\n",
      "Score: 0.000000\n",
      "\n",
      "- 현실 적 문제 로 연애 포기 해야 할 듯\n",
      "Model Prediction:  힘들 때 가 있 죠\n",
      "Real:  잠시 쉬 어도 괜찮 아요\n",
      "Score: 0.000000\n",
      "\n",
      "- 메모리 카드 어디 는데 두 었 을까\n",
      "Model Prediction:  한 번 만 더 궁금 한 번 만 더 해요\n",
      "Real:  발 이 달렸 나 봐요\n",
      "Score: 0.000000\n",
      "\n",
      "- 밤 이상 되 면\n",
      "Model Prediction:  내일 은 나 은 하루 이 가 또 데이트 가 나 봐요\n",
      "Real:  생각날 거 예요\n",
      "Score: 0.000000\n",
      "\n",
      "- 화장 이 안 받 다섯\n",
      "Model Prediction:  것 을 아니 라고 하 면서 상처 받 을 것 같 습니다\n",
      "Real:  각질 제거 먼저 하 세요\n",
      "Score: 0.017033\n",
      "\n",
      "- 기력 은 없 어\n",
      "Model Prediction:  잘 견뎌 내 고 있 는 게 아니 었 나 봐요\n",
      "Real:  자신 의 감정 을 주변 사람 들 에게 터놓 고 이야기 해 보 세요\n",
      "Score: 0.014351\n",
      "\n",
      "- 서로 싫어하 는 줄 알 았 는데 짝사랑 이 었 네요\n",
      "Model Prediction:  지금 연락 해 보 세요\n",
      "Real:  안타깝 게 생각 해요\n",
      "Score: 0.000000\n",
      "\n",
      "- 아침 안 잡아먹 는데 자꾸 먹 으라고 그래\n",
      "Model Prediction:  수십 번 어야 하나 봅니다\n",
      "Real:  챙겨 주 고 싶 나 봐요\n",
      "Score: 0.000000\n",
      "\n",
      "- 문자 왔 다는 데 읽 다가 점액 터졌 어\n",
      "Model Prediction:  소원 을 비세 요\n",
      "Real:  마음껏 우세요\n",
      "Score: 0.000000\n",
      "\n",
      "- 여자 친구 가 잠 이 너무 많 아\n",
      "Model Prediction:  잘 견뎌 내 상대방 이 에요\n",
      "Real:  미인 은 잠꾸러기 라던데요\n",
      "Score: 0.000000\n",
      "\n",
      "- 오늘 연락 왔었 어\n",
      "Model Prediction:  따뜻 할 시기 네요\n",
      "Real:  기다리 던 연락 이 었 길 바랍니다\n",
      "Score: 0.000000\n",
      "\n",
      "- 좋 아 하 는 감정 를 혼자 서 정리 할 수 있 을까요\n",
      "Model Prediction:  마음 의 정리 가 안 좋 겠 어요\n",
      "Real:  본인 이 하 기 나름 일 거 예요\n",
      "Score: 0.000000\n",
      "\n",
      "- 괜찮 았었 지만\n",
      "Model Prediction:  서로 에게 부담 없 는 선물 이 좋 아요\n",
      "Real:  울 어도 괜찮 아요\n",
      "Score: 0.023980\n",
      "\n",
      "- 우린 운명 이 었 어\n",
      "Model Prediction:  어떨까 요\n",
      "Real:  운명 이 아니 였 다면 사랑 도 할 수 없 었 겠 지요\n",
      "Score: 0.000000\n",
      "\n",
      "- 헤어짐 이 인생 이 었 으면 좋 겠 어\n",
      "Model Prediction:  서로 에게 부담 없 는 선물 이 좋 아요\n",
      "Real:  현실 을 직시 할 필요 도 있 어요\n",
      "Score: 0.000000\n",
      "\n",
      "- 제 가 집착 하 는 중 은 에요\n",
      "Model Prediction:  서로 사랑 으로 잊 는 거 같 네요\n",
      "Real:  사랑 은 소유 하 는 것 이 아니 랍니다\n",
      "Score: 0.029150\n",
      "\n",
      "- 우리 계속 엇갈림\n",
      "Model Prediction:  어떨까 요\n",
      "Real:  타이밍 이 안 맞 았 나 봐요\n",
      "Score: 0.000000\n",
      "\n",
      "- 남자 들 은 좋 아 하 면 무조건 답장 이 빠른 가요\n",
      "Model Prediction:  잘 견뎌 내 었 나 봐요\n",
      "Real:  답 할 수 있 는 상황 이 면 빠르 죠\n",
      "Score: 0.000000\n",
      "\n",
      "- 이렇게 못 알 아 듣 니\n",
      "Model Prediction:  사랑 이 모두 정답 이 될 거 예요\n",
      "Real:  노력 하 겠 습니다\n",
      "Score: 0.000000\n",
      "\n",
      "- 아프 니까 너무 생각나 고 힘드 네\n",
      "Model Prediction:  수십 번 어야 하나 봅니다\n",
      "Real:  아플 땐 더 약해 지나 봐요\n",
      "Score: 0.000000\n",
      "\n",
      "- 헤어진 여자 친구 가 준 편지 못 버리 겠 어\n",
      "Model Prediction:  서로 에게 부담 없 는 선물 이 좋 아요\n",
      "Real:  마음 에 버리 세요\n",
      "Score: 0.000000\n",
      "\n",
      "- 헤어진 지 주 가 흘렀 네\n",
      "Model Prediction:  서로 에게 부담 없 는 선물 이 좋 아요\n",
      "Real:  어느덧 주 가 흘렀 나 봐요\n",
      "Score: 0.000000\n",
      "\n",
      "- 부드러운 좀 하 지\n",
      "Model Prediction:  습니다 습니다\n",
      "Real:  사람 들 이 중간 을 몰라요\n",
      "Score: 0.000000\n",
      "\n",
      "- 이별 준비 시키 려고\n",
      "Model Prediction:  사랑 이 모두 정답 이 될 거 예요\n",
      "Real:  쉽 지 않 은 결정 이 었 을 텐데 마음 고생 많 았 어요\n",
      "Score: 0.013121\n",
      "\n",
      "- 연인 가 엄청 소심 해\n",
      "Model Prediction:  마음 의 정리 를 하 겠 어요\n",
      "Real:  더 신경 써 주 세요\n",
      "Score: 0.000000\n",
      "\n",
      "- 좋 아 하 는 마음 이 앞 생길 것 같 다고 떠난 여자\n",
      "Model Prediction:  마음 의 정리 가 안 좋 겠 어요\n",
      "Real:  이제 그녀 를 놓아주 세요\n",
      "Score: 0.000000\n",
      "\n",
      "- 자 고 일어나 때문 피곤 해\n",
      "Model Prediction:  기다리 고 말 이 기다리 고 말 고 기다리 고 기다리 고 기다리 세요\n",
      "Real:  요즘 바쁜가 봐요\n",
      "Score: 0.000000\n",
      "\n",
      "- 친구 랑 비교 하 면 내 가 작아져\n",
      "Model Prediction:  잘못 안 좋 은 분 이 만나 세요\n",
      "Real:  당신 은 생각 보다 큰 사람 이 에요\n",
      "Score: 0.033032\n",
      "\n",
      "- 수도 이 얼 었 나 봐\n",
      "Model Prediction:  더 잘 할 수 있 을 거 예요\n",
      "Real:  잘 녹여 보 세요\n",
      "Score: 0.027776\n",
      "\n",
      "- 친구 랑 없 으면 내 가 작아져\n",
      "Model Prediction:  잘못 안 좋 은 분 이 만나 세요\n",
      "Real:  당신 은 생각 보다 큰 사람 이 에요\n",
      "Score: 0.033032\n",
      "\n",
      "- 비오 은 날 뭐 할까\n",
      "Model Prediction:  봅니다\n",
      "Real:  실내 데이트 요\n",
      "Score: 0.000000\n",
      "\n",
      "- 불 그날 뻔 했 어\n",
      "Model Prediction:  그럴 수 있 어요\n",
      "Real:  조심 하 세요\n",
      "Score: 0.000000\n",
      "\n",
      "- 남자 친구 , 틀리 는 맞춤법 이 거슬려\n",
      "Model Prediction:  잘 견뎌 내 었 나 봐요\n",
      "Real:  지적 하 지 말 고 맞 는 걸로 계속 이야기 해 주 세요\n",
      "Score: 0.000000\n",
      "\n",
      "- 매일 매일 눈물 로 보내\n",
      "Model Prediction:  조금 더 라도 더 잘 해 주 세요\n",
      "Real:  울 고 싶 을 때 한껏 울 어 버려요\n",
      "Score: 0.000000\n",
      "\n",
      "- 이 사람 이랑 결혼 이 옳 은 걸까\n",
      "Model Prediction:  사랑 이 모두 정답 이 될 거 예요\n",
      "Real:  결혼 에 는 옳 고 그름 이 없 어요\n",
      "Score: 0.024512\n",
      "\n",
      "- 심심 한데 뭐 시키 면 좋 을까\n",
      "Model Prediction:  모든 날 들 이 있 어요\n",
      "Real:  저 랑 이야기 해요\n",
      "Score: 0.000000\n",
      "\n",
      "- 허전 하 는데\n",
      "Model Prediction:  당신 이 아픈 가요\n",
      "Real:  제 가 채워 드릴게요\n",
      "Score: 0.000000\n",
      "\n",
      "- 수분 크림 바르 고 자 면 나아질 거 니라\n",
      "Model Prediction:  더 잘 할 수 있 을 거 예요\n",
      "Real:  예뻐질 거 예요\n",
      "Score: 0.058739\n",
      "\n",
      "- 월 이 익숙 해 지 지 않 네\n",
      "Model Prediction:  딱 좋 을 때 네요\n",
      "Real:  조금 만 더 힘내 세요\n",
      "Score: 0.000000\n",
      "\n",
      "- 재혼 했 어\n",
      "Model Prediction:  지만 에 대한 지켜보 는 건 취업 에 성공 할 거 예요\n",
      "Real:  좋 겠 어요\n",
      "Score: 0.000000\n",
      "\n",
      "- 전 여자 친구 부친상 다녀왔 어\n",
      "Model Prediction:  잊 고 새 잊 으세요\n",
      "Real:  인간 적 예 를 다 하 셨 네요\n",
      "Score: 0.000000\n",
      "\n",
      "- 어떠 고 있 는 게 잘 하 고 있 는 건지\n",
      "Model Prediction:  조금 더 잘 해 주 는 것 도 좋 을 것 같 아요\n",
      "Real:  충분히 잘 하 고 있 을 거 라 생각 해요\n",
      "Score: 0.018477\n",
      "\n",
      "- 수염 기르 고 싶 다\n",
      "Model Prediction:  더 잘 할 수 있 을 거 예요\n",
      "Real:  지저분 해요\n",
      "Score: 0.000000\n",
      "\n",
      "- 나 잘 살 경우 있 겠 지\n",
      "Model Prediction:  괜찮 아 질 거 예요\n",
      "Real:  지금 보다 더 잘 살 거 예요\n",
      "Score: 0.076163\n",
      "\n",
      "- 이것 또한 받아들이 는 것 이 겠 죠\n",
      "Model Prediction:  사랑 이 모두 정답 이 될 거 예요\n",
      "Real:  받아들여야 할 부분 도 있 을 거 예요\n",
      "Score: 0.058739\n",
      "\n",
      "- 내 가 원 하 는 사람 이 되 기 어려워\n",
      "Model Prediction:  자신 있 다면 만나 세요\n",
      "Real:  다른 사람 들 이 원 하 는 내 가 되 는 건 어려워요\n",
      "Score: 0.000000\n",
      "\n",
      "- 얼 어 죽 는 주\n",
      "Model Prediction:  남 의 눈 을 의식 하 는 사람 은 남 을 거 예요\n",
      "Real:  감기 조심 하 세요\n",
      "Score: 0.015537\n",
      "\n",
      "- 잡담 할 시간 있 어서\n",
      "Model Prediction:  잡 잡 용기 가 잡 잡 잡 잡 아 보 세요\n",
      "Real:  물론 이 죠 무엇 이 든 말씀 하 세요\n",
      "Score: 0.018850\n",
      "\n",
      "- 희생 힘드 네\n",
      "Model Prediction:  서로 에게 부담 없 는 선물 이 좋 아요\n",
      "Real:  힘 들 만 해요\n",
      "Score: 0.000000\n",
      "\n",
      "- 혼영 해야지\n",
      "Model Prediction:  조금 만 더 견뎌 받 지 세요\n",
      "Real:  편하 고 좋 죠\n",
      "Score: 0.000000\n",
      "\n",
      "- 누가 딴 여자 를 만나 고 싶 다는 생각 이 든다면\n",
      "Model Prediction:  저 는 기 는 힘들 어요\n",
      "Real:  정신 차리 세요\n",
      "Score: 0.000000\n",
      "\n",
      "- 집안일 해도 해도 끝 은 없 어\n",
      "Model Prediction:  조심히 오 세요\n",
      "Real:  매일 조금 씩 해 보 세요\n",
      "Score: 0.041799\n",
      "\n",
      "- 아침 일찍 일어나 산책 하 고 있 어\n",
      "Model Prediction:  수십 번 어야 하나 봅니다\n",
      "Real:  건강 에 좋 은 습관 이 네요\n",
      "Score: 0.000000\n",
      "\n",
      "- 고민 좀 들 어 줄래\n",
      "Model Prediction:  많 은 시간 이 흘렀 네요\n",
      "Real:  네 말씀 하 세요\n",
      "Score: 0.000000\n",
      "\n",
      "- 전학 원망 된다\n",
      "Model Prediction:  잊 고 새 잊 으세요\n",
      "Real:  걱정 하 지 마세요 잘 할 거 예요\n",
      "Score: 0.000000\n",
      "\n",
      "Num of Sample: 100\n",
      "Total Score: 0.008961625084588757\n"
     ]
    }
   ],
   "source": [
    "score = eval_bleu(transformer, src_sentences, tgt_sentences, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa22ffc5",
   "metadata": {},
   "source": [
    "### t3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5590223",
   "metadata": {},
   "source": [
    "- n_layers: 2\n",
    "- d_model: 512\n",
    "- n_heads: 8\n",
    "- d_ff: 2048\n",
    "- dropout: 0.3\n",
    "- batch_size: 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "4751ef25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 지루 하 다 놀 러 가 고 싶 어\n",
      "> 누구 에게 요\n",
      "\n",
      "- 오늘 일찍 일어났 더니 피곤 하 다\n",
      "> 기다리 고 있 나 봐요\n",
      "\n",
      "- 간만에 여자 친구 랑 데이트 하 기 로 했 어\n",
      "> 직접 적 이 든 간접 적 이 든 의사 를 확실히 밝혀 보 세요\n",
      "\n",
      "- 집 에 있 는다는 소리야\n",
      "> 그냥 신경 쓰 지 마세요\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for question in test_questions:\n",
    "    result = translate(\" \".join(question), transformer, tokenizer)\n",
    "    print(f\"> {result}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "3ae4253a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 아 벌 받 고 있 는 건가 네\n",
      "Model Prediction:  수십 번 생각 이 수십 수십 번 마주쳐 보 세요\n",
      "Real:  달 게 받 으세요\n",
      "Score: 0.000000\n",
      "\n",
      "- 헤어진지 열흘 됐 는데 연락 하 고 싶 다섯\n",
      "Model Prediction:  시간 이 지나 면 좋 겠 네요\n",
      "Real:  후회 하 지 않 는다면 연락 해 보 세요\n",
      "Score: 0.000000\n",
      "\n",
      "- 머리카락 이 정말 빠져\n",
      "Model Prediction:  네 말씀 해 주 세요\n",
      "Real:  스트레스 받 지 마세요\n",
      "Score: 0.000000\n",
      "\n",
      "- 자율 주행 승용차 나오 겠 지\n",
      "Model Prediction:  기다리 고 있 었 어요\n",
      "Real:  가까운 미래 에 나올 거 같 아요\n",
      "Score: 0.000000\n",
      "\n",
      "- 죽 고 못 사 는 관계\n",
      "Model Prediction:  너무 무리 하 지 마세요\n",
      "Real:  연애 할 때 가능 하 죠\n",
      "Score: 0.043989\n",
      "\n",
      "- 졸업식 에 가 도 된 나\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "required broadcastable shapes [Op:AddV2]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_39/2789742676.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_bleu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_sentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_sentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_39/861136348.py\u001b[0m in \u001b[0;36meval_bleu\u001b[0;34m(model, src_sentences, tgt_sentences, tokenizer, verbose)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_sentences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mtgt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtgt_sentences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_bleu_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_39/1746119813.py\u001b[0m in \u001b[0;36meval_bleu_single\u001b[0;34m(model, src_sentence, tgt_sentence, tokenizer, verbose)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mreference\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtgt_sentence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mcandidate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtranslate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_sentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     score = sentence_bleu([reference], candidate,\n",
      "\u001b[0;32m/tmp/ipykernel_39/2829387780.py\u001b[0m in \u001b[0;36mtranslate\u001b[0;34m(text_tokens, model, tokenizer)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0menc_padding_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcombined_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_padding_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_masks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadded_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         predictions, _, _, _ = model(padded_tokens,\n\u001b[0m\u001b[1;32m     12\u001b[0m                                      \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m                                      \u001b[0menc_padding_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1036\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1037\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_39/316502540.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, enc_in, dec_in, enc_mask, dec_enc_mask, dec_mask)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_enc_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0menc_in\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menc_emb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0mdec_in\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdec_emb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0menc_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_attns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menc_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_39/316502540.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(self, emb, x)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshared_fc\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mout\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0md_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_encoding\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mseq_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mbinary_op_wrapper\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m   1365\u001b[0m         \u001b[0;31m#   r_binary_op_wrapper use different force_same_dtype values.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaybe_promote_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_same_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1368\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m         \u001b[0;31m# Even if dispatching the op failed, the RHS may be a tensor aware\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36m_add_dispatch\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   1698\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1699\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1700\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1702\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36madd_v2\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m    453\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 455\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    456\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6939\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6940\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6941\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6942\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6943\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: required broadcastable shapes [Op:AddV2]"
     ]
    }
   ],
   "source": [
    "score = eval_bleu(transformer, src_sentences, tgt_sentences, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7632b527",
   "metadata": {},
   "source": [
    "### t4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c42eaf1",
   "metadata": {},
   "source": [
    "- n_layers: 2\n",
    "- d_model: 512\n",
    "- n_heads: 8\n",
    "- d_ff: 2048\n",
    "- dropout: 0.2\n",
    "- batch_size: 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "23d0c321",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 지루 하 다 놀 러 가 고 싶 어\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'<start>'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_39/3165525781.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mquestion\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_questions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtranslate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"> {result}\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_39/2829387780.py\u001b[0m in \u001b[0;36mtranslate\u001b[0;34m(text_tokens, model, tokenizer)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'<start>'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0menc_padding_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcombined_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_padding_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_masks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadded_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: '<start>'"
     ]
    }
   ],
   "source": [
    "for question in test_questions:\n",
    "    result = translate(\" \".join(question), transformer, tokenizer)\n",
    "    print(f\"> {result}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "c6eb5a0f",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 아 벌 받 고 있 는 건가 네\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'<start>'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_39/2789742676.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_bleu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_sentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_sentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_39/861136348.py\u001b[0m in \u001b[0;36meval_bleu\u001b[0;34m(model, src_sentences, tgt_sentences, tokenizer, verbose)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_sentences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mtgt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtgt_sentences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_bleu_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_39/1746119813.py\u001b[0m in \u001b[0;36meval_bleu_single\u001b[0;34m(model, src_sentence, tgt_sentence, tokenizer, verbose)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mreference\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtgt_sentence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mcandidate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtranslate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_sentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     score = sentence_bleu([reference], candidate,\n",
      "\u001b[0;32m/tmp/ipykernel_39/2829387780.py\u001b[0m in \u001b[0;36mtranslate\u001b[0;34m(text_tokens, model, tokenizer)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'<start>'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0menc_padding_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcombined_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_padding_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_masks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadded_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: '<start>'"
     ]
    }
   ],
   "source": [
    "score = eval_bleu(transformer, src_sentences, tgt_sentences, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff4b447",
   "metadata": {},
   "source": [
    "### t5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330e2916",
   "metadata": {},
   "source": [
    "- n_layers: 2\n",
    "- d_model: 512\n",
    "- n_heads: 8\n",
    "- d_ff: 2048\n",
    "- dropout: 0.2\n",
    "- batch_size: 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "019e01a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 지루 하 다 놀 러 가 고 싶 어\n",
      "> 말씀 해 보 세요\n",
      "\n",
      "- 오늘 일찍 일어났 더니 피곤 하 다\n",
      "> 즐거운 시간 보내 고 있 나 봐요\n",
      "\n",
      "- 간만에 여자 친구 랑 데이트 하 기 로 했 어\n",
      "> 상대방 을 탓 하 지 마세요\n",
      "\n",
      "- 집 에 있 는다는 소리야\n",
      "> 조심히 오 세요\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for question in test_questions:\n",
    "    result = translate(\" \".join(question), transformer, tokenizer)\n",
    "    print(f\"> {result}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "2f6ffafd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 아 벌 받 고 있 는 건가 네\n",
      "Model Prediction:  수십 번 번 수십 번 도 잊 으세요\n",
      "Real:  달 게 받 으세요\n",
      "Score: 0.027776\n",
      "\n",
      "- 헤어진지 열흘 됐 는데 연락 하 고 싶 다섯\n",
      "Model Prediction:  지금 도 늦 지 않 게 먹 는 게 좋 을 것 같 아요\n",
      "Real:  후회 하 지 않 는다면 연락 해 보 세요\n",
      "Score: 0.030206\n",
      "\n",
      "- 머리카락 이 정말 빠져\n",
      "Model Prediction:  그러 지 말 아요\n",
      "Real:  스트레스 받 지 마세요\n",
      "Score: 0.080343\n",
      "\n",
      "- 자율 주행 승용차 나오 겠 지\n",
      "Model Prediction:  기다리 고 있 었 어요\n",
      "Real:  가까운 미래 에 나올 거 같 아요\n",
      "Score: 0.000000\n",
      "\n",
      "- 죽 고 못 사 는 관계\n",
      "Model Prediction:  그런 생각 보다 많 은 죽 지 않 아요\n",
      "Real:  연애 할 때 가능 하 죠\n",
      "Score: 0.000000\n",
      "\n",
      "- 졸업식 에 가 도 된 나\n",
      "Model Prediction:  잠 을 깨 요\n",
      "Real:  졸업식 에 가 서 축하 해 주 세요\n",
      "Score: 0.000000\n",
      "\n",
      "- 공허 하 네\n",
      "Model Prediction:  좋 은 결과 가 순간 이 죠\n",
      "Real:  제 가 채워줄 게요\n",
      "Score: 0.033032\n",
      "\n",
      "- 여지 를 준 짝 녀 버려야 겠죠\n",
      "Model Prediction:  잘 견뎌 내 고 있 어요\n",
      "Real:  오해 가 아니 라면 정리 하 는 게 덜 상처 일 것 같 아요\n",
      "Score: 0.000000\n",
      "\n",
      "- 농사 짓 고 다른가\n",
      "Model Prediction:  지금 도 늦 지 않 게 먹 는 게 좋 을 것 같 아요\n",
      "Real:  생각 하 기 는 쉬운데 실천 하 기 는 어려운 것 같 아요\n",
      "Score: 0.075965\n",
      "\n",
      "- 술 을 마시 러 나갈까 어디 론가 떠나 볼까\n",
      "Model Prediction:  술 많이 드 시 면 연락 안\n",
      "Real:  어디 든 좋 죠\n",
      "Score: 0.000000\n",
      "\n",
      "- 강우 땜 에 눈 아파\n",
      "Model Prediction:  지금 은 분 인가 봐요\n",
      "Real:  이쁜 마스크 사 드리 고 싶 네요\n",
      "Score: 0.000000\n",
      "\n",
      "- 너무 가슴 이 조르 네\n",
      "Model Prediction:  저 도 썸\n",
      "Real:  무슨 마음 인지 알 겠 어서 더 마음 이 아프 네요\n",
      "Score: 0.000000\n",
      "\n",
      "- 정말 예쁘 고 죽 고 싶 어\n",
      "Model Prediction:  사람 마다 다르 지 않 기 도 해요\n",
      "Real:  당신 은 누구 보다 소중 한 사람 이 에요\n",
      "Score: 0.024512\n",
      "\n",
      "- 좋 아 하 는 사람 도 에 공부 를 못 하 겠 어\n",
      "Model Prediction:  좋 은 취미 네요\n",
      "Real:  충분히 그럴 수 있 어요\n",
      "Score: 0.000000\n",
      "\n",
      "- 결국 약혼 했 어\n",
      "Model Prediction:  지금 도 늦 지 않 게 먹 는 게 좋 을 것 같 아요\n",
      "Real:  마음 이 더 복잡 하 겠 어요\n",
      "Score: 0.000000\n",
      "\n",
      "- 정말로 돌아올까\n",
      "Model Prediction:  사람 마다 다르 지 않 기 도 해요\n",
      "Real:  돌아오 길 바란다면 연락 해 보 세요\n",
      "Score: 0.000000\n",
      "\n",
      "- 이렇게 가짜 끝 인 걸까\n",
      "Model Prediction:  저 기 전 기 전 기 더 힘들 기\n",
      "Real:  인연 이 거기 까지 인 가 봐요\n",
      "Score: 0.000000\n",
      "\n",
      "- 먹통 이 야 침울 하 다\n",
      "Model Prediction:  색다른 시 겠 네요\n",
      "Real:  대화 의 눈높이 가 맞 는 사람 만나 세요\n",
      "Score: 0.000000\n",
      "\n",
      "- 요즘 제정신 이 오로지 야\n",
      "Model Prediction:  많이 힘들 지 않 길 바랄 게요\n",
      "Real:  그럴 때 가 있 죠\n",
      "Score: 0.000000\n",
      "\n",
      "- 술 이 주꾸미 도 아니 고\n",
      "Model Prediction:  술 많이 드 시 면 연락 안\n",
      "Real:  술 은 끊 는 게 좋 죠\n",
      "Score: 0.033032\n",
      "\n",
      "- 여자 친구 가 말 를 듣 기 좋 게 해\n",
      "Model Prediction:  잘 견뎌 내 고 있 어요\n",
      "Real:  말 도 예쁘 게 하 는 사람 이 네요\n",
      "Score: 0.000000\n",
      "\n",
      "- 여지 를 준 짝 녀 봐야 겠죠\n",
      "Model Prediction:  잘 견뎌 내 고 있 어요\n",
      "Real:  오해 가 아니 라면 정리 하 는 게 덜 상처 일 것 같 아요\n",
      "Score: 0.000000\n",
      "\n",
      "- 상사병 극복 하 고 싶 어\n",
      "Model Prediction:  아무래도 뿌듯 할 거 예요\n",
      "Real:  시간 이 해결 해 줄 거 예요\n",
      "Score: 0.076163\n",
      "\n",
      "- 밥 너무 많이 함\n",
      "Model Prediction:  시간 이 밥 사 는 시간 이 온전히 느낄 수 있 죠\n",
      "Real:  소분 해서 냉동실 에 보관 해 보 세요\n",
      "Score: 0.000000\n",
      "\n",
      "- 그냥 차단 과 하 지\n",
      "Model Prediction:  산책 을 내 는 게 좋 죠\n",
      "Real:  스스로 에게 하 는 말 인가요\n",
      "Score: 0.033032\n",
      "\n",
      "- 짝 녀 가 어떻게 하 면 내 확신 을 하 게 할까\n",
      "Model Prediction:  많이 힘들 죠\n",
      "Real:  우선 꾸준히 연락 하 고 잘 해 줘 보 세요\n",
      "Score: 0.000000\n",
      "\n",
      "- 사람 이 변하 든\n",
      "Model Prediction:  원 하 는 대로 사 줄 사 적 사 는 것 이 많 지 않 아요\n",
      "Real:  사랑 은 변하 고 사람 은 안 변해요\n",
      "Score: 0.000000\n",
      "\n",
      "- 충동 감 이 떨어져 있 는 지금\n",
      "Model Prediction:  좋 은 말 만 해요\n",
      "Real:  저 도 진짜 힘들 었 는데 지금 은 좋 은 사람 만나 행복 해요\n",
      "Score: 0.020785\n",
      "\n",
      "- 헤어진지 달 반 정도 됬 네\n",
      "Model Prediction:  지금 도 늦 지 않 게 먹 는 게 좋 을 것 같 아요\n",
      "Real:  금방 지나갈 거 예요\n",
      "Score: 0.000000\n",
      "\n",
      "- 집착 같 아서\n",
      "Model Prediction:  조심히 오 세요\n",
      "Real:  차분히 생각 해 보 세요 사랑 은 소유 가 아니 에요\n",
      "Score: 0.007895\n",
      "\n",
      "- 썸 타 는 건가 티 내 고 싶 진 않 아\n",
      "Caught an exception: required broadcastable shapes [Op:AddV2]\n",
      "Model Prediction:  관계 의 관계 길 관계 길 관계 관계 도 썸 관계 관계 길 관계 관계 관계 도 썸 관계 관계 관계 의 관계 관계 관계 의 관계 의 관계 관계 관계 관계 길 관계 길 관계 길 관계 길 관계 길 관계 길 관계 관계 길 관계 길 관계 길 관계 길 관계 길 관계 길 관계 길 관계 길 관계 길 관계 길 관계 길 관계 길 관계 길 관계 길 관계 길 관계 관계 관계 관계 길 관계 길 관계 길 관계 길 관계 길 관계 길 관계 길 관계 길 관계 길 관계 길 관계 길 관계 길 관계 길 관계 길 관계 길 관계 길 관계 길 관계 관계 관계 길 관계 길 관계 길 관계 길 관계 길 관계 길 관계 길 관계 길 관계 길 관계 길 관계 길 관계 길 관계 길 관계 길 관계 길 관계 길 관계 길 관계 길 관계 길 관계 길 관계 길 관계 길 관계 길 관계 길 관계 길 관계 길 관계 길 관계 길 관계 길 관계 길 관계 길 관계 길 관계 길 관계 길 관계 길 관계 길 관계 길 관계 길 관계 길 관계 길 관계 길 관계 길 관계 길 관계\n",
      "Real:  누구 에게 요\n",
      "Score: 0.000000\n",
      "\n",
      "- 제 외국어 뭐 선택 합니까\n",
      "Model Prediction:  저 도 모르 는 습관 이 에요\n",
      "Real:  요즘 은 잘 안 배우 는 언어 도 좋 은 거 같 아요\n",
      "Score: 0.016670\n",
      "\n",
      "- 못하 된 사람\n",
      "Model Prediction:  안 가 기 전 은 안 될 수 도 있 어요\n",
      "Real:  못 된 사람 은 이제 잊 어 버려요\n",
      "Score: 0.018850\n",
      "\n",
      "- 이별 의 시간\n",
      "Model Prediction:  저 기 전 기 전 기 더 힘들 기\n",
      "Real:  길 지 않 길 바랄 게요\n",
      "Score: 0.000000\n",
      "\n",
      "- 이런 게 동거 니\n",
      "Model Prediction:  저 기 전 기 전 기 더 힘들 기\n",
      "Real:  알 다가 도 모르 는 게 연애 같 아요\n",
      "Score: 0.000000\n",
      "\n",
      "- 휴 반년 이 라는 시간 잊 었 다 생각 했 지만 또 다시\n",
      "Model Prediction:  아이구\n",
      "Real:  후폭풍 이 무섭 죠\n",
      "Score: 0.000000\n",
      "\n",
      "- 짝 남 에게 밤 에 자주 산책 하 려고 해도 될까\n",
      "Model Prediction:  많이 힘들 죠\n",
      "Real:  밤 데이트 신청 멋지 네요\n",
      "Score: 0.000000\n",
      "\n",
      "- 취업 못 시키 는 기간 이 길 어 진다\n",
      "Model Prediction:  아무래도 사생활 이 지켜 지 않 지만 힘내 세요\n",
      "Real:  다음 공채 때 는 될 거 예요\n",
      "Score: 0.000000\n",
      "\n",
      "- 혼자 썸 타 는 기분 은 야\n",
      "Model Prediction:  맛있 는 거 드세요\n",
      "Real:  직접 적 이 든 간접 적 이 든 의사 를 확실히 밝혀 보 세요\n",
      "Score: 0.000000\n",
      "\n",
      "- 좋 아 하 은 감정 이 나 를 슬프 게 도 해\n",
      "Model Prediction:  좋 은 취미 네요\n",
      "Real:  사랑 과 슬픔 은 동전 의 양면 과 같 죠\n",
      "Score: 0.017927\n",
      "\n",
      "- 태 핑 할까\n",
      "Model Prediction:  누구 나 만났 나 봐요\n",
      "Real:  구릿빛 피부 좋 죠\n",
      "Score: 0.000000\n",
      "\n",
      "- 자꾸 뭘 사 게 돼\n",
      "Model Prediction:  기다리 고 있 었 어요\n",
      "Real:  마음 이 헛헛 한가 봐요\n",
      "Score: 0.000000\n",
      "\n",
      "- 음식 많이 가리 는 남자 를 사 겨 도 괜찮 습니까\n",
      "Model Prediction:  음\n",
      "Real:  다 먹 으면 좋 겠 지만 큰 문제 는 되 지 않 을 거 예요\n",
      "Score: 0.000000\n",
      "\n",
      "- 뭔 비밀 이 그렇게 높 은지\n",
      "Model Prediction:  지금 은 힘들 지요\n",
      "Real:  하나 씩 비밀 을 공유 해 보 세요\n",
      "Score: 0.000000\n",
      "\n",
      "- 구 썸남 보 고 싶 어서\n",
      "Model Prediction:  안타깝 네요\n",
      "Real:  썸 으로 끝날 사이 가 아니 었 네요\n",
      "Score: 0.007445\n",
      "\n",
      "- 상처 받 고자 싫 다\n",
      "Model Prediction:  아무래도 뿌듯 할 거 예요\n",
      "Real:  무덤덤 해질 수 있 거예요\n",
      "Score: 0.000000\n",
      "\n",
      "- 현실 적 문제 로 연애 포기 해야 할 듯\n",
      "Model Prediction:  한동안 은 힘들 지 도 몰라요\n",
      "Real:  잠시 쉬 어도 괜찮 아요\n",
      "Score: 0.000000\n",
      "\n",
      "- 메모리 카드 어디 는데 두 었 을까\n",
      "Model Prediction:  와 항상 가슴 아픈 사람 으로 대하 는 게 좋 을 거 같 아요\n",
      "Real:  발 이 달렸 나 봐요\n",
      "Score: 0.000000\n",
      "\n",
      "- 밤 이상 되 면\n",
      "Caught an exception: required broadcastable shapes [Op:AddV2]\n",
      "Model Prediction:  하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루\n",
      "Real:  생각날 거 예요\n",
      "Score: 0.000000\n",
      "\n",
      "- 화장 이 안 받 다섯\n",
      "Model Prediction:  화 내 면서 크 지 않 도록\n",
      "Real:  각질 제거 먼저 하 세요\n",
      "Score: 0.000000\n",
      "\n",
      "- 기력 은 없 어\n",
      "Model Prediction:  건강 에 는 안 좋 은 건강 습관 이 에요\n",
      "Real:  자신 의 감정 을 주변 사람 들 에게 터놓 고 이야기 해 보 세요\n",
      "Score: 0.000000\n",
      "\n",
      "- 서로 싫어하 는 줄 알 았 는데 짝사랑 이 었 네요\n",
      "Model Prediction:  아무래도 만 인 것 같 네요\n",
      "Real:  안타깝 게 생각 해요\n",
      "Score: 0.000000\n",
      "\n",
      "- 아침 안 잡아먹 는데 자꾸 먹 으라고 그래\n",
      "Model Prediction:  수십 번 번 수십 번 도 잊 으세요\n",
      "Real:  챙겨 주 고 싶 나 봐요\n",
      "Score: 0.000000\n",
      "\n",
      "- 문자 왔 다는 데 읽 다가 점액 터졌 어\n",
      "Model Prediction:  소원 을 비세 요\n",
      "Real:  마음껏 우세요\n",
      "Score: 0.000000\n",
      "\n",
      "- 여자 친구 가 잠 이 너무 많 아\n",
      "Model Prediction:  잘 견뎌 내 고 있 어요\n",
      "Real:  미인 은 잠꾸러기 라던데요\n",
      "Score: 0.000000\n",
      "\n",
      "- 오늘 연락 왔었 어\n",
      "Model Prediction:  즐거운 시간 보내 고 있 나 봐요\n",
      "Real:  기다리 던 연락 이 었 길 바랍니다\n",
      "Score: 0.000000\n",
      "\n",
      "- 좋 아 하 는 감정 를 혼자 서 정리 할 수 있 을까요\n",
      "Model Prediction:  좋 은 취미 네요\n",
      "Real:  본인 이 하 기 나름 일 거 예요\n",
      "Score: 0.000000\n",
      "\n",
      "- 괜찮 았었 지만\n",
      "Model Prediction:  지금 도 늦 지 않 게 먹 는 게 좋 을 것 같 아요\n",
      "Real:  울 어도 괜찮 아요\n",
      "Score: 0.014284\n",
      "\n",
      "- 우린 운명 이 었 어\n",
      "Model Prediction:  함께 충분 해요\n",
      "Real:  운명 이 아니 였 다면 사랑 도 할 수 없 었 겠 지요\n",
      "Score: 0.000000\n",
      "\n",
      "- 헤어짐 이 인생 이 었 으면 좋 겠 어\n",
      "Model Prediction:  지금 도 늦 지 않 게 먹 는 게 좋 을 것 같 아요\n",
      "Real:  현실 을 직시 할 필요 도 있 어요\n",
      "Score: 0.016986\n",
      "\n",
      "- 제 가 집착 하 는 중 은 에요\n",
      "Model Prediction:  저 도 모르 는 습관 이 에요\n",
      "Real:  사랑 은 소유 하 는 것 이 아니 랍니다\n",
      "Score: 0.029519\n",
      "\n",
      "- 우리 계속 엇갈림\n",
      "Model Prediction:  함께 충분 해요\n",
      "Real:  타이밍 이 안 맞 았 나 봐요\n",
      "Score: 0.000000\n",
      "\n",
      "- 남자 들 은 좋 아 하 면 무조건 답장 이 빠른 가요\n",
      "Model Prediction:  지금 행복 스러운 바랄 게요\n",
      "Real:  답 할 수 있 는 상황 이 면 빠르 죠\n",
      "Score: 0.000000\n",
      "\n",
      "- 이렇게 못 알 아 듣 니\n",
      "Model Prediction:  저 기 전 기 전 기 더 힘들 기\n",
      "Real:  노력 하 겠 습니다\n",
      "Score: 0.000000\n",
      "\n",
      "- 아프 니까 너무 생각나 고 힘드 네\n",
      "Model Prediction:  수십 번 번 수십 번 도 잊 으세요\n",
      "Real:  아플 땐 더 약해 지나 봐요\n",
      "Score: 0.000000\n",
      "\n",
      "- 헤어진 여자 친구 가 준 편지 못 버리 겠 어\n",
      "Model Prediction:  지금 도 늦 지 않 게 먹 는 게 좋 을 것 같 아요\n",
      "Real:  마음 에 버리 세요\n",
      "Score: 0.000000\n",
      "\n",
      "- 헤어진 지 주 가 흘렀 네\n",
      "Model Prediction:  지금 도 늦 지 않 게 먹 는 게 좋 을 것 같 아요\n",
      "Real:  어느덧 주 가 흘렀 나 봐요\n",
      "Score: 0.000000\n",
      "\n",
      "- 부드러운 좀 하 지\n",
      "Model Prediction:  저 도 크 시 겠 네요\n",
      "Real:  사람 들 이 중간 을 몰라요\n",
      "Score: 0.000000\n",
      "\n",
      "- 이별 준비 시키 려고\n",
      "Model Prediction:  저 기 전 기 전 기 더 힘들 기\n",
      "Real:  쉽 지 않 은 결정 이 었 을 텐데 마음 고생 많 았 어요\n",
      "Score: 0.000000\n",
      "\n",
      "- 연인 가 엄청 소심 해\n",
      "Model Prediction:  저 는 오래 살 아서 더 힘들 었 을 거 예요\n",
      "Real:  더 신경 써 주 세요\n",
      "Score: 0.018850\n",
      "\n",
      "- 좋 아 하 는 마음 이 앞 생길 것 같 다고 떠난 여자\n",
      "Model Prediction:  좋 은 취미 네요\n",
      "Real:  이제 그녀 를 놓아주 세요\n",
      "Score: 0.000000\n",
      "\n",
      "- 자 고 일어나 때문 피곤 해\n",
      "Model Prediction:  기다리 고 있 었 어요\n",
      "Real:  요즘 바쁜가 봐요\n",
      "Score: 0.000000\n",
      "\n",
      "- 친구 랑 비교 하 면 내 가 작아져\n",
      "Model Prediction:  신경 쓰이 는 일 이 에요\n",
      "Real:  당신 은 생각 보다 큰 사람 이 에요\n",
      "Score: 0.061861\n",
      "\n",
      "- 수도 이 얼 었 나 봐\n",
      "Model Prediction:  서로 의 상황 에서 안 할 수 있 을 거 예요\n",
      "Real:  잘 녹여 보 세요\n",
      "Score: 0.000000\n",
      "\n",
      "- 친구 랑 없 으면 내 가 작아져\n",
      "Model Prediction:  신경 쓰이 는 일 이 에요\n",
      "Real:  당신 은 생각 보다 큰 사람 이 에요\n",
      "Score: 0.061861\n",
      "\n",
      "- 비오 은 날 뭐 할까\n",
      "Model Prediction:  후회 안 남 지 않 길 바랄 게요\n",
      "Real:  실내 데이트 요\n",
      "Score: 0.000000\n",
      "\n",
      "- 불 그날 뻔 했 어\n",
      "Model Prediction:  친구 들 과 함께\n",
      "Real:  조심 하 세요\n",
      "Score: 0.000000\n",
      "\n",
      "- 남자 친구 , 틀리 는 맞춤법 이 거슬려\n",
      "Model Prediction:  지금 행복 스러운 바랄 게요\n",
      "Real:  지적 하 지 말 고 맞 는 걸로 계속 이야기 해 주 세요\n",
      "Score: 0.000000\n",
      "\n",
      "- 매일 매일 눈물 로 보내\n",
      "Model Prediction:  긍정 적 인 문제 가 에요\n",
      "Real:  울 고 싶 을 때 한껏 울 어 버려요\n",
      "Score: 0.000000\n",
      "\n",
      "- 이 사람 이랑 결혼 이 옳 은 걸까\n",
      "Model Prediction:  저 기 전 기 전 기 더 힘들 기\n",
      "Real:  결혼 에 는 옳 고 그름 이 없 어요\n",
      "Score: 0.000000\n",
      "\n",
      "- 심심 한데 뭐 시키 면 좋 을까\n",
      "Model Prediction:  지금 도 힘들 지 않 았 으면 좋 겠 네요\n",
      "Real:  저 랑 이야기 해요\n",
      "Score: 0.000000\n",
      "\n",
      "- 허전 하 는데\n",
      "Model Prediction:  물리 적 시간 가 는 따뜻 할 거 같 아요\n",
      "Real:  제 가 채워 드릴게요\n",
      "Score: 0.021105\n",
      "\n",
      "- 수분 크림 바르 고 자 면 나아질 거 니라\n",
      "Model Prediction:  서로 의 상황 에서 안 할 수 있 을 거 예요\n",
      "Real:  예뻐질 거 예요\n",
      "Score: 0.039864\n",
      "\n",
      "- 월 이 익숙 해 지 지 않 네\n",
      "Model Prediction:  과정 이 탓 인지 월요일 스럽 것 같 아요\n",
      "Real:  조금 만 더 힘내 세요\n",
      "Score: 0.000000\n",
      "\n",
      "- 재혼 했 어\n",
      "Model Prediction:  성공 하 지 않 으면 성공 을 수 있 는 성공 할 거 예요\n",
      "Real:  좋 겠 어요\n",
      "Score: 0.000000\n",
      "\n",
      "- 전 여자 친구 부친상 다녀왔 어\n",
      "Model Prediction:  남 이 라는 걸 잊 지 않 으면 좋 겠 어요\n",
      "Real:  인간 적 예 를 다 하 셨 네요\n",
      "Score: 0.000000\n",
      "\n",
      "- 어떠 고 있 는 게 잘 하 고 있 는 건지\n",
      "Model Prediction:  그냥 지만 조금 씩 변화 를 내 세요\n",
      "Real:  충분히 잘 하 고 있 을 거 라 생각 해요\n",
      "Score: 0.000000\n",
      "\n",
      "- 수염 기르 고 싶 다\n",
      "Model Prediction:  서로 의 상황 에서 안 할 수 있 을 거 예요\n",
      "Real:  지저분 해요\n",
      "Score: 0.000000\n",
      "\n",
      "- 나 잘 살 경우 있 겠 지\n",
      "Model Prediction:  지금 은 괜찮 아요\n",
      "Real:  지금 보다 더 잘 살 거 예요\n",
      "Score: 0.037951\n",
      "\n",
      "- 이것 또한 받아들이 는 것 이 겠 죠\n",
      "Model Prediction:  저 기 전 기 전 기 더 힘들 기\n",
      "Real:  받아들여야 할 부분 도 있 을 거 예요\n",
      "Score: 0.000000\n",
      "\n",
      "- 내 가 원 하 는 사람 이 되 기 어려워\n",
      "Model Prediction:  저 도 궁금 하 네요\n",
      "Real:  다른 사람 들 이 원 하 는 내 가 되 는 건 어려워요\n",
      "Score: 0.010848\n",
      "\n",
      "- 얼 어 죽 는 주\n",
      "Model Prediction:  감기 조심 하 세요\n",
      "Real:  감기 조심 하 세요\n",
      "Score: 1.000000\n",
      "\n",
      "- 잡담 할 시간 있 어서\n",
      "Model Prediction:  잡 잡 잡 잡 잡 잡 잡 잡 아 잡 아 잡 잡 잡 잡 잡 잡 잡 잡 잡 잡\n",
      "Real:  물론 이 죠 무엇 이 든 말씀 하 세요\n",
      "Score: 0.000000\n",
      "\n",
      "- 희생 힘드 네\n",
      "Model Prediction:  지금 도 늦 지 않 게 먹 는 게 좋 을 것 같 아요\n",
      "Real:  힘 들 만 해요\n",
      "Score: 0.000000\n",
      "\n",
      "- 혼영 해야지\n",
      "Model Prediction:  맛있 는 거 드세요\n",
      "Real:  편하 고 좋 죠\n",
      "Score: 0.000000\n",
      "\n",
      "- 누가 딴 여자 를 만나 고 싶 다는 생각 이 든다면\n",
      "Model Prediction:  좋 은 일 이 네요\n",
      "Real:  정신 차리 세요\n",
      "Score: 0.000000\n",
      "\n",
      "- 집안일 해도 해도 끝 은 없 어\n",
      "Model Prediction:  조심히 오 세요\n",
      "Real:  매일 조금 씩 해 보 세요\n",
      "Score: 0.041799\n",
      "\n",
      "- 아침 일찍 일어나 산책 하 고 있 어\n",
      "Model Prediction:  수십 번 번 수십 번 도 잊 으세요\n",
      "Real:  건강 에 좋 은 습관 이 네요\n",
      "Score: 0.000000\n",
      "\n",
      "- 고민 좀 들 어 줄래\n",
      "Model Prediction:  그러 다 보 면 할 것 같 아요\n",
      "Real:  네 말씀 하 세요\n",
      "Score: 0.000000\n",
      "\n",
      "- 전학 원망 된다\n",
      "Model Prediction:  남 이 라는 걸 잊 지 않 으면 좋 겠 어요\n",
      "Real:  걱정 하 지 마세요 잘 할 거 예요\n",
      "Score: 0.018850\n",
      "\n",
      "Num of Sample: 100\n",
      "Total Score: 0.01877410997600004\n"
     ]
    }
   ],
   "source": [
    "score = eval_bleu(transformer, src_sentences, tgt_sentences, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca5c7cc",
   "metadata": {},
   "source": [
    "> loss 값은 많이 줄었는데.. bleu score 값은 여전히 엉망"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8784f433",
   "metadata": {},
   "source": [
    "### t6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185a19ec",
   "metadata": {},
   "source": [
    "- n_layers: 2\n",
    "- d_model: 512\n",
    "- n_heads: 8\n",
    "- d_ff: 2048\n",
    "- dropout: 0.2\n",
    "- batch_size: 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "cf308632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 지루 하 다 놀 러 가 고 싶 어\n",
      "> 지\n",
      "\n",
      "- 오늘 일찍 일어났 더니 피곤 하 다\n",
      "> 오\n",
      "\n",
      "- 간만에 여자 친구 랑 데이트 하 기 로 했 어\n",
      "> 간\n",
      "\n",
      "- 집 에 있 는다는 소리야\n",
      "> 집 집\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for question in test_questions:\n",
    "    result = translate(\" \".join(question), transformer, tokenizer)\n",
    "    print(f\"> {result}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "081a43f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab0050f23da748c380edb6fa8de220e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 아 벌 받 고 있 는 건가 네\n",
      "Model Prediction:  아\n",
      "Real:  달 게 받 으세요\n",
      "Score: 0.000000\n",
      "\n",
      "- 헤어진지 열흘 됐 는데 연락 하 고 싶 다섯\n",
      "Model Prediction:  좋아하\n",
      "Real:  후회 하 지 않 는다면 연락 해 보 세요\n",
      "Score: 0.000000\n",
      "\n",
      "- 머리카락 이 정말 빠져\n",
      "Model Prediction:  머\n",
      "Real:  스트레스 받 지 마세요\n",
      "Score: 0.000000\n",
      "\n",
      "- 자율 주행 승용차 나오 겠 지\n",
      "Model Prediction:  자\n",
      "Real:  가까운 미래 에 나올 거 같 아요\n",
      "Score: 0.000000\n",
      "\n",
      "- 죽 고 못 사 는 관계\n",
      "Model Prediction:  죽 죽\n",
      "Real:  연애 할 때 가능 하 죠\n",
      "Score: 0.000000\n",
      "\n",
      "- 졸업식 에 가 도 된 나\n",
      "Model Prediction:  졸\n",
      "Real:  졸업식 에 가 서 축하 해 주 세요\n",
      "Score: 0.000000\n",
      "\n",
      "- 공허 하 네\n",
      "Model Prediction:  공\n",
      "Real:  제 가 채워줄 게요\n",
      "Score: 0.000000\n",
      "\n",
      "- 여지 를 준 짝 녀 버려야 겠죠\n",
      "Model Prediction:  여\n",
      "Real:  오해 가 아니 라면 정리 하 는 게 덜 상처 일 것 같 아요\n",
      "Score: 0.000000\n",
      "\n",
      "- 농사 짓 고 다른가\n",
      "Model Prediction:  좋아하\n",
      "Real:  생각 하 기 는 쉬운데 실천 하 기 는 어려운 것 같 아요\n",
      "Score: 0.000000\n",
      "\n",
      "- 술 을 마시 러 나갈까 어디 론가 떠나 볼까\n",
      "Model Prediction:  술\n",
      "Real:  어디 든 좋 죠\n",
      "Score: 0.000000\n",
      "\n",
      "- 강우 땜 에 눈 아파\n",
      "Model Prediction:  강\n",
      "Real:  이쁜 마스크 사 드리 고 싶 네요\n",
      "Score: 0.000000\n",
      "\n",
      "- 너무 가슴 이 조르 네\n",
      "Model Prediction:  너 너\n",
      "Real:  무슨 마음 인지 알 겠 어서 더 마음 이 아프 네요\n",
      "Score: 0.000000\n",
      "\n",
      "- 정말 예쁘 고 죽 고 싶 어\n",
      "Model Prediction:  정\n",
      "Real:  당신 은 누구 보다 소중 한 사람 이 에요\n",
      "Score: 0.000000\n",
      "\n",
      "- 좋 아 하 는 사람 도 에 공부 를 못 하 겠 어\n",
      "Model Prediction:  좋 좋\n",
      "Real:  충분히 그럴 수 있 어요\n",
      "Score: 0.000000\n",
      "\n",
      "- 결국 약혼 했 어\n",
      "Model Prediction:  좋아하\n",
      "Real:  마음 이 더 복잡 하 겠 어요\n",
      "Score: 0.000000\n",
      "\n",
      "- 정말로 돌아올까\n",
      "Model Prediction:  정\n",
      "Real:  돌아오 길 바란다면 연락 해 보 세요\n",
      "Score: 0.000000\n",
      "\n",
      "- 이렇게 가짜 끝 인 걸까\n",
      "Model Prediction:  이\n",
      "Real:  인연 이 거기 까지 인 가 봐요\n",
      "Score: 0.000441\n",
      "\n",
      "- 먹통 이 야 침울 하 다\n",
      "Model Prediction:  먹\n",
      "Real:  대화 의 눈높이 가 맞 는 사람 만나 세요\n",
      "Score: 0.000000\n",
      "\n",
      "- 요즘 제정신 이 오로지 야\n",
      "Model Prediction:  요\n",
      "Real:  그럴 때 가 있 죠\n",
      "Score: 0.000000\n",
      "\n",
      "- 술 이 주꾸미 도 아니 고\n",
      "Model Prediction:  술\n",
      "Real:  술 은 끊 는 게 좋 죠\n",
      "Score: 0.000441\n",
      "\n",
      "- 여자 친구 가 말 를 듣 기 좋 게 해\n",
      "Model Prediction:  여\n",
      "Real:  말 도 예쁘 게 하 는 사람 이 네요\n",
      "Score: 0.000000\n",
      "\n",
      "- 여지 를 준 짝 녀 봐야 겠죠\n",
      "Model Prediction:  여\n",
      "Real:  오해 가 아니 라면 정리 하 는 게 덜 상처 일 것 같 아요\n",
      "Score: 0.000000\n",
      "\n",
      "- 상사병 극복 하 고 싶 어\n",
      "Model Prediction:  상\n",
      "Real:  시간 이 해결 해 줄 거 예요\n",
      "Score: 0.000000\n",
      "\n",
      "- 밥 너무 많이 함\n",
      "Model Prediction:  밥\n",
      "Real:  소분 해서 냉동실 에 보관 해 보 세요\n",
      "Score: 0.000000\n",
      "\n",
      "- 그냥 차단 과 하 지\n",
      "Model Prediction:  그\n",
      "Real:  스스로 에게 하 는 말 인가요\n",
      "Score: 0.000000\n",
      "\n",
      "- 짝 녀 가 어떻게 하 면 내 확신 을 하 게 할까\n",
      "Model Prediction:  짝\n",
      "Real:  우선 꾸준히 연락 하 고 잘 해 줘 보 세요\n",
      "Score: 0.000000\n",
      "\n",
      "- 사람 이 변하 든\n",
      "Model Prediction:  사\n",
      "Real:  사랑 은 변하 고 사람 은 안 변해요\n",
      "Score: 0.000000\n",
      "\n",
      "- 충동 감 이 떨어져 있 는 지금\n",
      "Model Prediction:  충\n",
      "Real:  저 도 진짜 힘들 었 는데 지금 은 좋 은 사람 만나 행복 해요\n",
      "Score: 0.000000\n",
      "\n",
      "- 헤어진지 달 반 정도 됬 네\n",
      "Model Prediction:  좋아하\n",
      "Real:  금방 지나갈 거 예요\n",
      "Score: 0.000000\n",
      "\n",
      "- 집착 같 아서\n",
      "Model Prediction:  집 집\n",
      "Real:  차분히 생각 해 보 세요 사랑 은 소유 가 아니 에요\n",
      "Score: 0.000000\n",
      "\n",
      "- 썸 타 는 건가 티 내 고 싶 진 않 아\n",
      "Model Prediction:  썸\n",
      "Real:  누구 에게 요\n",
      "Score: 0.000000\n",
      "\n",
      "- 제 외국어 뭐 선택 합니까\n",
      "Model Prediction:  제\n",
      "Real:  요즘 은 잘 안 배우 는 언어 도 좋 은 거 같 아요\n",
      "Score: 0.000000\n",
      "\n",
      "- 못하 된 사람\n",
      "Model Prediction:  못 못\n",
      "Real:  못 된 사람 은 이제 잊 어 버려요\n",
      "Score: 0.007445\n",
      "\n",
      "- 이별 의 시간\n",
      "Model Prediction:  이\n",
      "Real:  길 지 않 길 바랄 게요\n",
      "Score: 0.000000\n",
      "\n",
      "- 이런 게 동거 니\n",
      "Model Prediction:  이\n",
      "Real:  알 다가 도 모르 는 게 연애 같 아요\n",
      "Score: 0.000000\n",
      "\n",
      "- 휴 반년 이 라는 시간 잊 었 다 생각 했 지만 또 다시\n",
      "Model Prediction:  휴\n",
      "Real:  후폭풍 이 무섭 죠\n",
      "Score: 0.000000\n",
      "\n",
      "- 짝 남 에게 밤 에 자주 산책 하 려고 해도 될까\n",
      "Model Prediction:  짝\n",
      "Real:  밤 데이트 신청 멋지 네요\n",
      "Score: 0.000000\n",
      "\n",
      "- 취업 못 시키 는 기간 이 길 어 진다\n",
      "Model Prediction:  취 취\n",
      "Real:  다음 공채 때 는 될 거 예요\n",
      "Score: 0.000000\n",
      "\n",
      "- 혼자 썸 타 는 기분 은 야\n",
      "Model Prediction:  혼 혼\n",
      "Real:  직접 적 이 든 간접 적 이 든 의사 를 확실히 밝혀 보 세요\n",
      "Score: 0.000000\n",
      "\n",
      "- 좋 아 하 은 감정 이 나 를 슬프 게 도 해\n",
      "Model Prediction:  좋 좋\n",
      "Real:  사랑 과 슬픔 은 동전 의 양면 과 같 죠\n",
      "Score: 0.000000\n",
      "\n",
      "- 태 핑 할까\n",
      "Model Prediction:  태\n",
      "Real:  구릿빛 피부 좋 죠\n",
      "Score: 0.000000\n",
      "\n",
      "- 자꾸 뭘 사 게 돼\n",
      "Model Prediction:  자\n",
      "Real:  마음 이 헛헛 한가 봐요\n",
      "Score: 0.000000\n",
      "\n",
      "- 음식 많이 가리 는 남자 를 사 겨 도 괜찮 습니까\n",
      "Model Prediction:  음\n",
      "Real:  다 먹 으면 좋 겠 지만 큰 문제 는 되 지 않 을 거 예요\n",
      "Score: 0.000000\n",
      "\n",
      "- 뭔 비밀 이 그렇게 높 은지\n",
      "Model Prediction:  뭔\n",
      "Real:  하나 씩 비밀 을 공유 해 보 세요\n",
      "Score: 0.000000\n",
      "\n",
      "- 구 썸남 보 고 싶 어서\n",
      "Model Prediction:  구\n",
      "Real:  썸 으로 끝날 사이 가 아니 었 네요\n",
      "Score: 0.000000\n",
      "\n",
      "- 상처 받 고자 싫 다\n",
      "Model Prediction:  상\n",
      "Real:  무덤덤 해질 수 있 거예요\n",
      "Score: 0.000000\n",
      "\n",
      "- 현실 적 문제 로 연애 포기 해야 할 듯\n",
      "Model Prediction:  현 현\n",
      "Real:  잠시 쉬 어도 괜찮 아요\n",
      "Score: 0.000000\n",
      "\n",
      "- 메모리 카드 어디 는데 두 었 을까\n",
      "Model Prediction:  메\n",
      "Real:  발 이 달렸 나 봐요\n",
      "Score: 0.000000\n",
      "\n",
      "- 밤 이상 되 면\n",
      "Model Prediction:  밤\n",
      "Real:  생각날 거 예요\n",
      "Score: 0.000000\n",
      "\n",
      "- 화장 이 안 받 다섯\n",
      "Model Prediction:  화\n",
      "Real:  각질 제거 먼저 하 세요\n",
      "Score: 0.000000\n",
      "\n",
      "- 기력 은 없 어\n",
      "Model Prediction:  기\n",
      "Real:  자신 의 감정 을 주변 사람 들 에게 터놓 고 이야기 해 보 세요\n",
      "Score: 0.000000\n",
      "\n",
      "- 서로 싫어하 는 줄 알 았 는데 짝사랑 이 었 네요\n",
      "Model Prediction:  서 서\n",
      "Real:  안타깝 게 생각 해요\n",
      "Score: 0.000000\n",
      "\n",
      "- 아침 안 잡아먹 는데 자꾸 먹 으라고 그래\n",
      "Model Prediction:  아\n",
      "Real:  챙겨 주 고 싶 나 봐요\n",
      "Score: 0.000000\n",
      "\n",
      "- 문자 왔 다는 데 읽 다가 점액 터졌 어\n",
      "Model Prediction:  문\n",
      "Real:  마음껏 우세요\n",
      "Score: 0.000000\n",
      "\n",
      "- 여자 친구 가 잠 이 너무 많 아\n",
      "Model Prediction:  여\n",
      "Real:  미인 은 잠꾸러기 라던데요\n",
      "Score: 0.000000\n",
      "\n",
      "- 오늘 연락 왔었 어\n",
      "Model Prediction:  오\n",
      "Real:  기다리 던 연락 이 었 길 바랍니다\n",
      "Score: 0.000000\n",
      "\n",
      "- 좋 아 하 는 감정 를 혼자 서 정리 할 수 있 을까요\n",
      "Model Prediction:  좋 좋\n",
      "Real:  본인 이 하 기 나름 일 거 예요\n",
      "Score: 0.000000\n",
      "\n",
      "- 괜찮 았었 지만\n",
      "Model Prediction:  좋아하\n",
      "Real:  울 어도 괜찮 아요\n",
      "Score: 0.000000\n",
      "\n",
      "- 우린 운명 이 었 어\n",
      "Model Prediction:  우\n",
      "Real:  운명 이 아니 였 다면 사랑 도 할 수 없 었 겠 지요\n",
      "Score: 0.000000\n",
      "\n",
      "- 헤어짐 이 인생 이 었 으면 좋 겠 어\n",
      "Model Prediction:  좋아하\n",
      "Real:  현실 을 직시 할 필요 도 있 어요\n",
      "Score: 0.000000\n",
      "\n",
      "- 제 가 집착 하 는 중 은 에요\n",
      "Model Prediction:  제\n",
      "Real:  사랑 은 소유 하 는 것 이 아니 랍니다\n",
      "Score: 0.000000\n",
      "\n",
      "- 우리 계속 엇갈림\n",
      "Model Prediction:  우\n",
      "Real:  타이밍 이 안 맞 았 나 봐요\n",
      "Score: 0.000000\n",
      "\n",
      "- 남자 들 은 좋 아 하 면 무조건 답장 이 빠른 가요\n",
      "Model Prediction:  남\n",
      "Real:  답 할 수 있 는 상황 이 면 빠르 죠\n",
      "Score: 0.000000\n",
      "\n",
      "- 이렇게 못 알 아 듣 니\n",
      "Model Prediction:  이\n",
      "Real:  노력 하 겠 습니다\n",
      "Score: 0.000000\n",
      "\n",
      "- 아프 니까 너무 생각나 고 힘드 네\n",
      "Model Prediction:  아\n",
      "Real:  아플 땐 더 약해 지나 봐요\n",
      "Score: 0.000000\n",
      "\n",
      "- 헤어진 여자 친구 가 준 편지 못 버리 겠 어\n",
      "Model Prediction:  좋아하\n",
      "Real:  마음 에 버리 세요\n",
      "Score: 0.000000\n",
      "\n",
      "- 헤어진 지 주 가 흘렀 네\n",
      "Model Prediction:  좋아하\n",
      "Real:  어느덧 주 가 흘렀 나 봐요\n",
      "Score: 0.000000\n",
      "\n",
      "- 부드러운 좀 하 지\n",
      "Model Prediction:  부\n",
      "Real:  사람 들 이 중간 을 몰라요\n",
      "Score: 0.000000\n",
      "\n",
      "- 이별 준비 시키 려고\n",
      "Model Prediction:  이\n",
      "Real:  쉽 지 않 은 결정 이 었 을 텐데 마음 고생 많 았 어요\n",
      "Score: 0.000000\n",
      "\n",
      "- 연인 가 엄청 소심 해\n",
      "Model Prediction:  연\n",
      "Real:  더 신경 써 주 세요\n",
      "Score: 0.000000\n",
      "\n",
      "- 좋 아 하 는 마음 이 앞 생길 것 같 다고 떠난 여자\n",
      "Model Prediction:  좋 좋\n",
      "Real:  이제 그녀 를 놓아주 세요\n",
      "Score: 0.000000\n",
      "\n",
      "- 자 고 일어나 때문 피곤 해\n",
      "Model Prediction:  자\n",
      "Real:  요즘 바쁜가 봐요\n",
      "Score: 0.000000\n",
      "\n",
      "- 친구 랑 비교 하 면 내 가 작아져\n",
      "Model Prediction:  친\n",
      "Real:  당신 은 생각 보다 큰 사람 이 에요\n",
      "Score: 0.000000\n",
      "\n",
      "- 수도 이 얼 었 나 봐\n",
      "Model Prediction:  수 수\n",
      "Real:  잘 녹여 보 세요\n",
      "Score: 0.000000\n",
      "\n",
      "- 친구 랑 없 으면 내 가 작아져\n",
      "Model Prediction:  친\n",
      "Real:  당신 은 생각 보다 큰 사람 이 에요\n",
      "Score: 0.000000\n",
      "\n",
      "- 비오 은 날 뭐 할까\n",
      "Model Prediction:  비\n",
      "Real:  실내 데이트 요\n",
      "Score: 0.000000\n",
      "\n",
      "- 불 그날 뻔 했 어\n",
      "Model Prediction:  불\n",
      "Real:  조심 하 세요\n",
      "Score: 0.000000\n",
      "\n",
      "- 남자 친구 , 틀리 는 맞춤법 이 거슬려\n",
      "Model Prediction:  남\n",
      "Real:  지적 하 지 말 고 맞 는 걸로 계속 이야기 해 주 세요\n",
      "Score: 0.000000\n",
      "\n",
      "- 매일 매일 눈물 로 보내\n",
      "Model Prediction:  매\n",
      "Real:  울 고 싶 을 때 한껏 울 어 버려요\n",
      "Score: 0.000000\n",
      "\n",
      "- 이 사람 이랑 결혼 이 옳 은 걸까\n",
      "Model Prediction:  이\n",
      "Real:  결혼 에 는 옳 고 그름 이 없 어요\n",
      "Score: 0.000060\n",
      "\n",
      "- 심심 한데 뭐 시키 면 좋 을까\n",
      "Model Prediction:  심\n",
      "Real:  저 랑 이야기 해요\n",
      "Score: 0.000000\n",
      "\n",
      "- 허전 하 는데\n",
      "Model Prediction:  좋아하\n",
      "Real:  제 가 채워 드릴게요\n",
      "Score: 0.000000\n",
      "\n",
      "- 수분 크림 바르 고 자 면 나아질 거 니라\n",
      "Model Prediction:  수 수\n",
      "Real:  예뻐질 거 예요\n",
      "Score: 0.000000\n",
      "\n",
      "- 월 이 익숙 해 지 지 않 네\n",
      "Model Prediction:  월\n",
      "Real:  조금 만 더 힘내 세요\n",
      "Score: 0.000000\n",
      "\n",
      "- 재혼 했 어\n",
      "Model Prediction:  재\n",
      "Real:  좋 겠 어요\n",
      "Score: 0.000000\n",
      "\n",
      "- 전 여자 친구 부친상 다녀왔 어\n",
      "Model Prediction:  전\n",
      "Real:  인간 적 예 를 다 하 셨 네요\n",
      "Score: 0.000000\n",
      "\n",
      "- 어떠 고 있 는 게 잘 하 고 있 는 건지\n",
      "Model Prediction:  어\n",
      "Real:  충분히 잘 하 고 있 을 거 라 생각 해요\n",
      "Score: 0.000000\n",
      "\n",
      "- 수염 기르 고 싶 다\n",
      "Model Prediction:  수 수\n",
      "Real:  지저분 해요\n",
      "Score: 0.000000\n",
      "\n",
      "- 나 잘 살 경우 있 겠 지\n",
      "Model Prediction:  나\n",
      "Real:  지금 보다 더 잘 살 거 예요\n",
      "Score: 0.000000\n",
      "\n",
      "- 이것 또한 받아들이 는 것 이 겠 죠\n",
      "Model Prediction:  이\n",
      "Real:  받아들여야 할 부분 도 있 을 거 예요\n",
      "Score: 0.000000\n",
      "\n",
      "- 내 가 원 하 는 사람 이 되 기 어려워\n",
      "Model Prediction:  내\n",
      "Real:  다른 사람 들 이 원 하 는 내 가 되 는 건 어려워요\n",
      "Score: 0.000001\n",
      "\n",
      "- 얼 어 죽 는 주\n",
      "Model Prediction:  얼\n",
      "Real:  감기 조심 하 세요\n",
      "Score: 0.000000\n",
      "\n",
      "- 잡담 할 시간 있 어서\n",
      "Model Prediction:  잡 잡\n",
      "Real:  물론 이 죠 무엇 이 든 말씀 하 세요\n",
      "Score: 0.000000\n",
      "\n",
      "- 희생 힘드 네\n",
      "Model Prediction:  좋아하\n",
      "Real:  힘 들 만 해요\n",
      "Score: 0.000000\n",
      "\n",
      "- 혼영 해야지\n",
      "Model Prediction:  혼 혼\n",
      "Real:  편하 고 좋 죠\n",
      "Score: 0.000000\n",
      "\n",
      "- 누가 딴 여자 를 만나 고 싶 다는 생각 이 든다면\n",
      "Model Prediction:  누\n",
      "Real:  정신 차리 세요\n",
      "Score: 0.000000\n",
      "\n",
      "- 집안일 해도 해도 끝 은 없 어\n",
      "Model Prediction:  집 집\n",
      "Real:  매일 조금 씩 해 보 세요\n",
      "Score: 0.000000\n",
      "\n",
      "- 아침 일찍 일어나 산책 하 고 있 어\n",
      "Model Prediction:  아\n",
      "Real:  건강 에 좋 은 습관 이 네요\n",
      "Score: 0.000000\n",
      "\n",
      "- 고민 좀 들 어 줄래\n",
      "Model Prediction:  고\n",
      "Real:  네 말씀 하 세요\n",
      "Score: 0.000000\n",
      "\n",
      "- 전학 원망 된다\n",
      "Model Prediction:  전\n",
      "Real:  걱정 하 지 마세요 잘 할 거 예요\n",
      "Score: 0.000000\n",
      "\n",
      "Num of Sample: 100\n",
      "Total Score: 8.38763518287726e-05\n"
     ]
    }
   ],
   "source": [
    "score = eval_bleu(transformer, src_sentences, tgt_sentences, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69fb3384",
   "metadata": {},
   "source": [
    "> 데이터 증강했더니, 오히려 과적합이된 모양..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1203f5",
   "metadata": {},
   "source": [
    "# 회고"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b356c77a",
   "metadata": {},
   "source": [
    "- 다른 그루분들의 loss 값이 10 미만에서 시작하는데 반해 내가 작성한 최종 모델의 loss 값은 700 ~ 800 에서 시작한다.\n",
    "  - 20 epoch 에서 loss 값이 5 로 낮아지기는 하지만, bleu score 값은 오히려 거의 0에 수렴을 한다.\n",
    "- 무엇이 문제인지 아직 파악이 되지 않는다. 아무래도 전처리에 문제가 있을 것 같다. 전처리는 항상 어렵다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
