{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7aa04ae5",
   "metadata": {},
   "source": [
    "평가문항\t상세기준\n",
    "\n",
    "1. 챗봇 훈련데이터 전처리 과정이 체계적으로 진행되었는가?\t\n",
    "> 챗봇 훈련데이터를 위한 전처리와 augmentation이 적절히 수행되어 3만개 가량의 훈련데이터셋이 구축되었다.\n",
    "\n",
    "2. transformer 모델을 활용한 챗봇 모델이 과적합을 피해 안정적으로 훈련되었는가?\t\n",
    "> 과적합을 피할 수 있는 하이퍼파라미터 셋이 적절히 제시되었다.\n",
    "\n",
    "3. 챗봇이 사용자의 질문에 그럴듯한 형태로 답하는 사례가 있는가?\n",
    "> 주어진 예문을 포함하여 챗봇에 던진 질문에 적절히 답하는 사례가 제출되었다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48a4f8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일 저장 커스텀 모듈\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../custom\")\n",
    "\n",
    "from importlib import reload\n",
    "import custom_utils\n",
    "reload(custom_utils)\n",
    "\n",
    "from custom_utils import save_var, load_var\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6eab4aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import re\n",
    "import os\n",
    "import io\n",
    "import random\n",
    "import logging\n",
    "import math\n",
    "\n",
    "from tqdm import tqdm\n",
    "# from tqdm.notebook import tqdm\n",
    "\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from nltk.translate.bleu_score import SmoothingFunction\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "import sentencepiece as spm\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb587ed3",
   "metadata": {},
   "source": [
    "# Step 1. 데이터 다운로드"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c052b6",
   "metadata": {},
   "source": [
    "읽어 온 데이터의 질문과 답변을 각각 questions, answers 변수에 나눠서 저장하세요!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2af50226",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/ChatbotData.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e31f079c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11823 entries, 0 to 11822\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Q       11823 non-null  object\n",
      " 1   A       11823 non-null  object\n",
      " 2   label   11823 non-null  int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 277.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4f3ed37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = df[\"Q\"]\n",
    "answers = df[\"A\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e0fdd604",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'12시 땡!'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cc252829",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'하루가 또 가네요.'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf120d47",
   "metadata": {},
   "source": [
    "# Step 2. 데이터 정제"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384c23e5",
   "metadata": {},
   "source": [
    "아래 조건을 만족하는 preprocess_sentence() 함수를 구현하세요.\n",
    "\n",
    "- 영문자의 경우, 모두 소문자로 변환합니다.\n",
    "- 영문자와 한글, 숫자, 그리고 주요 특수문자를 제외하곤 정규식을 활용하여 모두 제거합니다.\n",
    "\n",
    "문장부호 양옆에 공백을 추가하는 등 이전과 다르게 생략된 기능들은 우리가 사용할 토크나이저가 지원하기 때문에 굳이 구현하지 않아도 괜찮습니다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ac1bfc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextCleaner:\n",
    "    def __init__(self):\n",
    "        self.punct_space_re = re.compile(r\"([?.!,])\")\n",
    "        self.multiple_spaces_re = re.compile(r'[\" \"]+')\n",
    "        self.allowed_chars_re = re.compile(r\"[^a-zA-Z가-힣?.!,]+\")\n",
    "        self.email_re = re.compile(r'([a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+)')\n",
    "        self.url_re = re.compile(r'(http|ftp|https)://(?:[-\\w.]|(?:%[\\da-fA-F]{2}))+')\n",
    "        self.korean_chars_re = re.compile(r'([ㄱ-ㅎㅏ-ㅣ]+)')\n",
    "        self.html_tag_re = re.compile(r'<[^>]*>')\n",
    "        self.special_chars_re = re.compile(r'[-=+,#/\\?:^$.@*\\\"※~&%ㆍ!』\\\\‘|\\(\\)\\[\\]\\<\\>`\\'…》]')\n",
    "        \n",
    "    def clean_text(self, text):\n",
    "        try:\n",
    "            text = text.strip().lower()\n",
    "            text = self.punct_space_re.sub(r\" \\1 \", text)\n",
    "            text = self.multiple_spaces_re.sub(\" \", text)\n",
    "            text = self.allowed_chars_re.sub(\" \", text)\n",
    "            text = self.email_re.sub(\"\", text)\n",
    "            text = self.url_re.sub(\"\", text)\n",
    "            text = self.korean_chars_re.sub(\"\", text)\n",
    "            text = self.html_tag_re.sub(\"\", text)\n",
    "            text = self.special_chars_re.sub(\"\", text)\n",
    "            text = text.replace('\\n', '.')\n",
    "            return text\n",
    "        except TypeError:\n",
    "            print(\"Warning: Input was not a string or bytes-like object.\")\n",
    "            print(text)\n",
    "            return text\n",
    "\n",
    "    # 데이터 정제\n",
    "    def clean_corpus(self, corpus):\n",
    "        \n",
    "        self.corpus_cleaned = []\n",
    "        \n",
    "        for sentence in corpus:\n",
    "            self.corpus_cleaned.append(self.clean_text(sentence))\n",
    "    \n",
    "        return self.corpus_cleaned\n",
    "\n",
    "    # get unique data for the corpus1 \n",
    "    def get_unique_corpus1(self, corpus1, corpus2):\n",
    "        seen_sentences = set()\n",
    "        unique_corpus1 = []\n",
    "        unique_corpus2 = []\n",
    "        original_length = len(corpus1)\n",
    "        for sent1, sent2 in zip(corpus1, corpus2):\n",
    "            sent1_str = ' '.join(sent1)\n",
    "            if sent1_str not in seen_sentences:\n",
    "                seen_sentences.add(sent1_str)\n",
    "                unique_corpus1.append(sent1)\n",
    "                unique_corpus2.append(sent2)\n",
    "        removed_length = original_length - len(unique_corpus1)\n",
    "        print(f\"removed: {removed_length}\")\n",
    "        return [unique_corpus1, unique_corpus2]\n",
    "\n",
    "\n",
    "    # get unique data for the corpus1,2\n",
    "    def get_unique_corpus_both(self, corpus):\n",
    "\n",
    "        self.unique_corpus = self.get_unique_corpus1(corpus[1], corpus[0])  # for corpus2.\n",
    "        self.unique_corpus = self.get_unique_corpus1(self.unique_corpus[1], self.unique_corpus[0])  # for corpus1.\n",
    "    \n",
    "        return self.unique_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30e69f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaner = TextCleaner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ef91ffb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' 시 땡  ', ' 지망 학교 떨어졌어', ' 박 일 놀러가고 싶다']\n"
     ]
    }
   ],
   "source": [
    "tmp = cleaner.clean_corpus(df[\"Q\"].iloc[:3])\n",
    "print(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "13415aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Q_cleaned\"] = cleaner.clean_corpus(df[\"Q\"])\n",
    "df[\"A_cleaned\"] = cleaner.clean_corpus(df[\"A\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "bcca4082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11823 entries, 0 to 11822\n",
      "Data columns (total 5 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   Q          11823 non-null  object\n",
      " 1   A          11823 non-null  object\n",
      " 2   label      11823 non-null  int64 \n",
      " 3   Q_cleaned  11823 non-null  object\n",
      " 4   A_cleaned  11823 non-null  object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 462.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5c7f515a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "      <th>label</th>\n",
       "      <th>Q_cleaned</th>\n",
       "      <th>A_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12시 땡!</td>\n",
       "      <td>하루가 또 가네요.</td>\n",
       "      <td>0</td>\n",
       "      <td>시 땡</td>\n",
       "      <td>하루가 또 가네요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1지망 학교 떨어졌어</td>\n",
       "      <td>위로해 드립니다.</td>\n",
       "      <td>0</td>\n",
       "      <td>지망 학교 떨어졌어</td>\n",
       "      <td>위로해 드립니다</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3박4일 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "      <td>박 일 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Q            A  label     Q_cleaned     A_cleaned\n",
       "0        12시 땡!   하루가 또 가네요.      0         시 땡     하루가 또 가네요  \n",
       "1   1지망 학교 떨어졌어    위로해 드립니다.      0    지망 학교 떨어졌어    위로해 드립니다  \n",
       "2  3박4일 놀러가고 싶다  여행은 언제나 좋죠.      0   박 일 놀러가고 싶다  여행은 언제나 좋죠  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ef0246",
   "metadata": {},
   "source": [
    "# Step 3. 데이터 토큰화"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba35b16",
   "metadata": {},
   "source": [
    "토큰화에는 KoNLPy의 mecab 클래스를 사용합니다.  \n",
    "아래 조건을 만족하는 build_corpus() 함수를 구현하세요!  \n",
    "\n",
    "1. 소스 문장 데이터와 타겟 문장 데이터를 입력으로 받습니다.\n",
    "2. 데이터를 앞서 정의한 preprocess_sentence() 함수로 정제하고, 토큰화합니다.\n",
    "3. 토큰화는 전달받은 토크나이즈 함수를 사용합니다. 이번엔 mecab.morphs 함수를 전달하시면 됩니다.\n",
    "4. 토큰의 개수가 일정 길이 이상인 문장은 데이터에서 제외합니다.\n",
    "5. 중복되는 문장은 데이터에서 제외합니다. 소스 : 타겟 쌍을 비교하지 않고 소스는 소스대로 타겟은 타겟대로 검사합니다. 중복 쌍이 흐트러지지 않도록 유의하세요!\n",
    "\n",
    "구현한 함수를 활용하여 questions 와 answers 를 각각 que_corpus , ans_corpus 에 토큰화하여 저장합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a96b7c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Mecab\n",
    "\n",
    "mecab = Mecab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4de03a7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['시', '땡']\n"
     ]
    }
   ],
   "source": [
    "res = mecab.morphs(tmp[0])\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "908ac82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokenized_sentence(sentence, tokenizer):\n",
    "    return tokenizer.morphs(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7bb12705",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokenized_corpus(corpus, tokenizer):\n",
    "    corpus_tokenized = []\n",
    "    for sentence in corpus:\n",
    "        corpus_tokenized.append(get_tokenized_sentence(sentence, tokenizer))\n",
    "    return corpus_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "b1cdc653",
   "metadata": {},
   "outputs": [],
   "source": [
    "que_tokens = get_tokenized_corpus(df[\"Q_cleaned\"], mecab)\n",
    "ans_tokens = get_tokenized_corpus(df[\"A_cleaned\"], mecab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "c367345d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['시', '땡'],\n",
       " ['지망', '학교', '떨어졌', '어'],\n",
       " ['박', '일', '놀', '러', '가', '고', '싶', '다'],\n",
       " ['박', '일', '정도', '놀', '러', '가', '고', '싶', '다'],\n",
       " ['ppl', '심하', '네'],\n",
       " ['sd', '카드', '망가졌', '어'],\n",
       " ['sd', '카드', '안', '돼'],\n",
       " ['sns', '맞', '팔', '왜', '안', '하', '지'],\n",
       " ['sns', '시간', '낭비', '인', '거', '아', '는데', '매일', '하', '는', '중'],\n",
       " ['sns', '시간', '낭비', '인데', '자꾸', '보', '게', '됨']]"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "que_tokens[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16b8ce1",
   "metadata": {},
   "source": [
    "### 토큰수 제한"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6a78c055",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:, \"Q_length\"] = df[\"Q_tokenized\"].apply(lambda x: len(x))\n",
    "df.loc[:, \"A_length\"] = df[\"A_tokenized\"].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "7f4d8cbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "      <th>label</th>\n",
       "      <th>Q_cleaned</th>\n",
       "      <th>A_cleaned</th>\n",
       "      <th>Q_tokenized</th>\n",
       "      <th>A_tokenized</th>\n",
       "      <th>Q_length</th>\n",
       "      <th>A_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12시 땡!</td>\n",
       "      <td>하루가 또 가네요.</td>\n",
       "      <td>0</td>\n",
       "      <td>시 땡</td>\n",
       "      <td>하루가 또 가네요</td>\n",
       "      <td>[시, 땡]</td>\n",
       "      <td>[하루, 가, 또, 가, 네요]</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1지망 학교 떨어졌어</td>\n",
       "      <td>위로해 드립니다.</td>\n",
       "      <td>0</td>\n",
       "      <td>지망 학교 떨어졌어</td>\n",
       "      <td>위로해 드립니다</td>\n",
       "      <td>[지망, 학교, 떨어졌, 어]</td>\n",
       "      <td>[위로, 해, 드립니다]</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3박4일 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "      <td>박 일 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠</td>\n",
       "      <td>[박, 일, 놀, 러, 가, 고, 싶, 다]</td>\n",
       "      <td>[여행, 은, 언제나, 좋, 죠]</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Q            A  label     Q_cleaned     A_cleaned  \\\n",
       "0        12시 땡!   하루가 또 가네요.      0         시 땡     하루가 또 가네요     \n",
       "1   1지망 학교 떨어졌어    위로해 드립니다.      0    지망 학교 떨어졌어    위로해 드립니다     \n",
       "2  3박4일 놀러가고 싶다  여행은 언제나 좋죠.      0   박 일 놀러가고 싶다  여행은 언제나 좋죠     \n",
       "\n",
       "                Q_tokenized         A_tokenized  Q_length  A_length  \n",
       "0                    [시, 땡]   [하루, 가, 또, 가, 네요]         2         5  \n",
       "1          [지망, 학교, 떨어졌, 어]       [위로, 해, 드립니다]         4         3  \n",
       "2  [박, 일, 놀, 러, 가, 고, 싶, 다]  [여행, 은, 언제나, 좋, 죠]         8         5  "
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "4ae6884b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[\"label\"].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "096e5936",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAWLElEQVR4nO3dfYxc1X3G8e9TOyGWN8FQ6MixSZdUJhXYqRuPCFUTNFsSMBAViCKKRQGHJEsUkBLFUjFpK2gokpXipE1InZpiAQphgyAEi5cmDsqWINUBmzisDSFZYFG9dddKbOwssdwafv1j7jazw4w9L7vzdp6PNNqZc8/ce36662euz717RxGBmZml4XfaPQAzM2sdh76ZWUIc+mZmCXHom5klxKFvZpaQue0ewLGcdNJJ0d/fP63ttddeY/78+e0Z0AzqlTrAtXSqXqmlV+qA1tSyffv2X0bEyZWWdXzo9/f3s23btmltw8PDFAqF9gxoBvVKHeBaOlWv1NIrdUBrapH0SrVlnt4xM0uIQ9/MLCEOfTOzhDj0zcwS4tA3M0uIQ9/MLCEOfTOzhDj0zcwS4tA3M0tIx/9Fbi/pX/vItNdrlh1h9dpHGFt3YZtGZGap8ZG+mVlCHPpmZglx6JuZJcShb2aWEIe+mVlCHPpmZglx6JuZJcShb2aWEIe+mVlCHPpmZglx6JuZJeSYoS9pk6S9knaWtH1b0o7sMSZpR9beL+lQybJvlLxnhaQRSaOSvipJs1KRmZlVVcsN1+4EbgPunmqIiL+Yei5pPXCgpP+LEbG8wno2AJ8Cfgw8CqwEHqt7xGZm1rBjHulHxBPAvkrLsqP1S4F7j7YOSQuBd0TE1ogIih8gF9c9WjMza4qKGXyMTlI/8HBELC1rPxv4ckTkS/rtAn4OHAT+JiJ+JCkPrIuID2X9PghcHxEfqbK9QWAQIJfLrRgaGpq2fHJykr6+vjrK7Awj4wemvc7Ng4lDsGzR8W0a0czp1n1SiWvpPL1SB7SmloGBge1TuVyu2fvpr2L6Uf4e4F0R8StJK4DvSjqj3pVGxEZgI0A+n49CoTBt+fDwMOVt3WB1hfvprx+Zy9jlhfYMaAZ16z6pxLV0nl6pA9pfS8OhL2ku8FFgxVRbRBwGDmfPt0t6ETgNGAcWl7x9cdZmZmYt1Mwlmx8CfhYRu6caJJ0saU72/N3AEuCliNgDHJR0VnYe4ErgoSa2bWZmDajlks17gf8A3iNpt6RPZIsu480ncM8Gns0u4bwf+HRETJ0E/gzwr8Ao8CK+csfMrOWOOb0TEauqtK+u0PYA8ECV/tuApZWWmZlZa/gvcs3MEuLQNzNLiEPfzCwhDn0zs4Q49M3MEuLQNzNLiEPfzCwhDn0zs4Q49M3MEuLQNzNLiEPfzCwhzd5P32ZRf9n990uNrbuwhSMxs17hI30zs4Q49M3MEuLpnVlwtGkZM7N28pG+mVlCHPpmZglx6JuZJaSW78jdJGmvpJ0lbTdJGpe0I3tcULLsBkmjkl6QdF5J+8qsbVTS2pkvxczMjqWWI/07gZUV2r8SEcuzx6MAkk6n+IXpZ2Tv+WdJcyTNAb4OnA+cDqzK+pqZWQvV8sXoT0jqr3F9FwFDEXEYeFnSKHBmtmw0Il4CkDSU9X2u/iGbmVmjFBHH7lQM/YcjYmn2+iZgNXAQ2AasiYj9km4DtkbEN7N+dwCPZatZGRGfzNqvAN4fEddV2d4gMAiQy+VWDA0NTVs+OTlJX19fXYW20sj4gZr65ebBxCFYtuj4utdT7T3t0un7pB6upfP0Sh3QmloGBga2R0S+0rJGr9PfANwMRPZzPXB1g+t6k4jYCGwEyOfzUSgUpi0fHh6mvK2TrK7xOv01y46wfmQuY5cX6l5Ptfe0S6fvk3q4ls7TK3VA+2tpKPQjYmLquaTbgYezl+PAKSVdF2dtHKXdzMxapKFLNiUtLHl5CTB1Zc9m4DJJx0k6FVgCPAU8DSyRdKqkt1I82bu58WGbmVkjjnmkL+leoACcJGk3cCNQkLSc4vTOGHANQETsknQfxRO0R4BrI+L1bD3XAd8D5gCbImLXTBdjZmZHV8vVO6sqNN9xlP63ALdUaH8UeLSu0ZmZ2YzyX+SamSXEoW9mlhCHvplZQhz6ZmYJceibmSXEoW9mlhCHvplZQhz6ZmYJceibmSXEoW9mlhCHvplZQhz6ZmYJafRLVKxD9Vf54pWxdRe2eCRm1ol8pG9mlhCHvplZQhz6ZmYJceibmSXEoW9mlpBjhr6kTZL2StpZ0vYPkn4m6VlJD0pakLX3SzokaUf2+EbJe1ZIGpE0KumrkjQrFZmZWVW1HOnfCawsa9sCLI2I9wI/B24oWfZiRCzPHp8uad8AfApYkj3K12lmZrPsmKEfEU8A+8ravh8RR7KXW4HFR1uHpIXAOyJia0QEcDdwcUMjNjOzhs3EnP7VwGMlr0+V9BNJ/y7pg1nbImB3SZ/dWZuZmbWQigfex+gk9QMPR8TSsva/BvLARyMiJB0H9EXEryStAL4LnAGcBqyLiA9l7/sgcH1EfKTK9gaBQYBcLrdiaGho2vLJyUn6+vrqqbOlRsYP1NQvNw8mDsGyRcfXvZ5631Ot/0zp9H1SD9fSeXqlDmhNLQMDA9sjIl9pWcO3YZC0GvgIcE42ZUNEHAYOZ8+3S3qRYuCPM30KaHHWVlFEbAQ2AuTz+SgUCtOWDw8PU97WSVZXuRVCuTXLjrB+ZC5jlxfqXk+976nWf6Z0+j6ph2vpPL1SB7S/loamdyStBP4K+POI+E1J+8mS5mTP303xhO1LEbEHOCjprOyqnSuBh5oevZmZ1eWYR/qS7gUKwEmSdgM3Urxa5zhgS3bl5dbsSp2zgS9K+l/gDeDTETF1EvgzFK8EmkfxHEDpeQAzM2uBY4Z+RKyq0HxHlb4PAA9UWbYNWFppmZmZtYb/ItfMLCEOfTOzhDj0zcwS4tA3M0uIQ9/MLCEOfTOzhDj0zcwS4tA3M0uIQ9/MLCEOfTOzhDj0zcwS4tA3M0uIQ9/MLCEOfTOzhDj0zcwS4tA3M0uIQ9/MLCENfzF6Svqrfdn4ugtbPBIzs+Y49BPhDy4zgxqndyRtkrRX0s6SthMlbZH0i+znCVm7JH1V0qikZyW9r+Q9V2X9fyHpqpkvx8zMjqbWOf07gZVlbWuBxyNiCfB49hrgfGBJ9hgENkDxQwK4EXg/cCZw49QHhZmZtUZNoR8RTwD7ypovAu7Knt8FXFzSfncUbQUWSFoInAdsiYh9EbEf2MKbP0jMzGwWKSJq6yj1Aw9HxNLs9asRsSB7LmB/RCyQ9DCwLiKezJY9DlwPFIC3RcTfZ+1/CxyKiFsrbGuQ4v8SyOVyK4aGhqYtn5ycpK+vr+5iGzUyfqBi+7JFx9fVv1xuHkwcamw9zW77WOupV6v3yWxyLZ2nV+qA1tQyMDCwPSLylZbNyInciAhJtX161La+jcBGgHw+H4VCYdry4eFhyttm0+pqJ0EvrzyGav3LrVl2hPUjcxtaT7PbPtZ66tXqfTKbXEvn6ZU6oP21NHOd/kQ2bUP2c2/WPg6cUtJvcdZWrd3MzFqkmdDfDExdgXMV8FBJ+5XZVTxnAQciYg/wPeBcSSdkJ3DPzdrMzKxFaprekXQvxTn5kyTtpngVzjrgPkmfAF4BLs26PwpcAIwCvwE+DhAR+yTdDDyd9ftiRJSfHDYzs1lUU+hHxKoqi86p0DeAa6usZxOwqebRmZnZjPK9d8zMEuLQNzNLiEPfzCwhDn0zs4Q49M3MEuLQNzNLiEPfzCwhDn0zs4Q49M3MEuLQNzNLiEPfzCwhDn0zs4Q49M3MEuLQNzNLiEPfzCwhDn0zs4Q49M3MElLTN2dZevrXPlKxfWzdhS0eiZnNpIaP9CW9R9KOksdBSZ+TdJOk8ZL2C0rec4OkUUkvSDpvZkowM7NaNXykHxEvAMsBJM0BxoEHKX4R+lci4tbS/pJOBy4DzgDeCfxA0mkR8XqjYzAzs/rM1Jz+OcCLEfHKUfpcBAxFxOGIeBkYBc6coe2bmVkNFBHNr0TaBDwTEbdJuglYDRwEtgFrImK/pNuArRHxzew9dwCPRcT9FdY3CAwC5HK5FUNDQ9OWT05O0tfX1/S4azUyfqBi+7JFx9fVv1xuHkwcamw9zW670fVU69/qfTKbXEvn6ZU6oDW1DAwMbI+IfKVlTYe+pLcC/wWcERETknLAL4EAbgYWRsTV9YR+qXw+H9u2bZvWNjw8TKFQaGrc9aj3pGa1/uXWLDvC+pG5Da2n2W03up5q/Vu9T2aTa+k8vVIHtKYWSVVDfyamd86neJQ/ARARExHxekS8AdzOb6dwxoFTSt63OGszM7MWmYnQXwXcO/VC0sKSZZcAO7Pnm4HLJB0n6VRgCfDUDGzfzMxq1NR1+pLmAx8Grilp/pKk5RSnd8amlkXELkn3Ac8BR4BrfeWOmVlrNRX6EfEa8LtlbVccpf8twC3NbNPMzBrn2zCYmSXEoW9mlhCHvplZQhz6ZmYJceibmSXEoW9mlhCHvplZQhz6ZmYJceibmSXEoW9mlhCHvplZQhz6ZmYJceibmSXEoW9mlhCHvplZQhz6ZmYJceibmSXEoW9mlhCHvplZQpr6jlwASWPAr4HXgSMRkZd0IvBtoJ/il6NfGhH7JQn4J+AC4DfA6oh4ptkxWPuNjB9g9dpH3tQ+tu7CNozGzKqZqSP9gYhYHhH57PVa4PGIWAI8nr0GOB9Ykj0GgQ0ztH0zM6vBbE3vXATclT2/C7i4pP3uKNoKLJC0cJbGYGZmZRQRza1AehnYDwTwLxGxUdKrEbEgWy5gf0QskPQwsC4insyWPQ5cHxHbytY5SPF/AuRyuRVDQ0PTtjk5OUlfX19T467HyPiBiu3LFh1fV/9yuXkwcaix9TS77UbXU63/3n0HmDhUe/9O1urfr9nUK7X0Sh3QmloGBga2l8y8TNP0nD7wgYgYl/R7wBZJPytdGBEhqa5PlojYCGwEyOfzUSgUpi0fHh6mvG02VZqrBhi7vPIYqvUvt2bZEdaPzG1oPc1uu9H1VOv/tXseYv3Im3+dqvXvZK3+/ZpNvVJLr9QB7a+l6dCPiPHs515JDwJnAhOSFkbEnmz6Zm/WfRw4peTti7O2luqvFmg+6WhmPa6pOX1J8yW9feo5cC6wE9gMXJV1uwp4KHu+GbhSRWcBByJiTzNjMDOz2jV7pJ8DHixO2zMX+FZE/Jukp4H7JH0CeAW4NOv/KMXLNUcpXrL58Sa3b2ZmdWgq9CPiJeCPKrT/CjinQnsA1zazTTMza5z/ItfMLCEOfTOzhDj0zcwSMhPX6ZtV5ctjzTqLj/TNzBLi0DczS4hD38wsIQ59M7OEOPTNzBLi0DczS4hD38wsIQ59M7OEOPTNzBLi0DczS4hD38wsIQ59M7OEOPTNzBLiu2xaR/FdOc1mV8NH+pJOkfRDSc9J2iXps1n7TZLGJe3IHheUvOcGSaOSXpB03kwUYGZmtWvmSP8IsCYinpH0dmC7pC3Zsq9ExK2lnSWdDlwGnAG8E/iBpNMi4vUmxmBmZnVo+Eg/IvZExDPZ818DzwOLjvKWi4ChiDgcES8Do8CZjW7fzMzqp4hofiVSP/AEsBT4PLAaOAhso/i/gf2SbgO2RsQ3s/fcATwWEfdXWN8gMAiQy+VWDA0NTVs+OTlJX19fw+MdGT9QsX3ZouNntX+53DyYONTYeprddqPrqdZ/774DTBxq/XZnQ7O/X52kV2rplTqgNbUMDAxsj4h8pWVNn8iV1Ac8AHwuIg5K2gDcDET2cz1wdT3rjIiNwEaAfD4fhUJh2vLh4WHK2+qxutrJwssrr3Om+pdbs+wI60fmNrSeZrfd6Hqq9f/aPQ+xfqT2X6eZ2u5saPb3q5P0Si29Uge0v5amLtmU9BaKgX9PRHwHICImIuL1iHgDuJ3fTuGMA6eUvH1x1mZmZi3SzNU7Au4Ano+IL5e0LyzpdgmwM3u+GbhM0nGSTgWWAE81un0zM6tfM9M7fwpcAYxI2pG1fQFYJWk5xemdMeAagIjYJek+4DmKV/5c6yt3bCb42n6z2jUc+hHxJKAKix49yntuAW5pdJtmZtYc34bBzCwhDn0zs4Q49M3MEuIbrlnP8gleszfzkb6ZWUIc+mZmCXHom5klpKfn9KvN6ZqZpcpH+mZmCenpI32zekz9z3DNsiPT7vbpq32sl/hI38wsIQ59M7OEOPTNzBLi0DczS4hD38wsIb56x6xBvrePdSOHvtkM84eBdTJP75iZJcRH+mZt5v8ZWCu1/Ehf0kpJL0galbS21ds3M0tZS4/0Jc0Bvg58GNgNPC1pc0Q818pxmHWzem4kOHVLCf+vwaa0enrnTGA0Il4CkDQEXAQ49M3aoN6ppXrvXOsPm86jiGjdxqSPASsj4pPZ6yuA90fEdWX9BoHB7OV7gBfKVnUS8MtZHm4r9Eod4Fo6Va/U0it1QGtq+f2IOLnSgo48kRsRG4GN1ZZL2hYR+RYOaVb0Sh3gWjpVr9TSK3VA+2tp9YncceCUkteLszYzM2uBVof+08ASSadKeitwGbC5xWMwM0tWS6d3IuKIpOuA7wFzgE0RsauBVVWd+ukyvVIHuJZO1Su19Eod0OZaWnoi18zM2su3YTAzS4hD38wsIV0V+r10CwdJY5JGJO2QtK3d46mHpE2S9kraWdJ2oqQtkn6R/TyhnWOsVZVabpI0nu2bHZIuaOcYayHpFEk/lPScpF2SPpu1d91+OUotXbVfJL1N0lOSfprV8XdZ+6mSfpzl2Lezi1paN65umdPPbuHwc0pu4QCs6tZbOEgaA/IR0XV/cCLpbGASuDsilmZtXwL2RcS67AP5hIi4vp3jrEWVWm4CJiPi1naOrR6SFgILI+IZSW8HtgMXA6vpsv1ylFoupYv2iyQB8yNiUtJbgCeBzwKfB74TEUOSvgH8NCI2tGpc3XSk//+3cIiI/wGmbuFgLRYRTwD7ypovAu7Knt9F8R9px6tSS9eJiD0R8Uz2/NfA88AiunC/HKWWrhJFk9nLt2SPAP4MuD9rb/k+6abQXwT8Z8nr3XThL0KJAL4vaXt224lul4uIPdnz/wZy7RzMDLhO0rPZ9E/HT4mUktQP/DHwY7p8v5TVAl22XyTNkbQD2AtsAV4EXo2II1mXludYN4V+r/lARLwPOB+4Nptm6AlRnDPsjnnDyjYAfwAsB/YA69s6mjpI6gMeAD4XEQdLl3XbfqlQS9ftl4h4PSKWU7z7wJnAH7Z3RN0V+j11C4eIGM9+7gUepPgL0c0msrnYqTnZvW0eT8MiYiL7x/oGcDtdsm+yeeMHgHsi4jtZc1ful0q1dOt+AYiIV4EfAn8CLJA09YexLc+xbgr9nrmFg6T52QkqJM0HzgV2Hv1dHW8zcFX2/CrgoTaOpSlTIZm5hC7YN9lJwzuA5yPiyyWLum6/VKul2/aLpJMlLciez6N4EcrzFMP/Y1m3lu+Trrl6ByC7ROsf+e0tHG5p74gaI+ndFI/uoXgrjG91Uy2S7gUKFG8ROwHcCHwXuA94F/AKcGlEdPwJ0iq1FChOIQQwBlxTMi/ekSR9APgRMAK8kTV/geJceFftl6PUsoou2i+S3kvxRO0cigfY90XEF7N//0PAicBPgL+MiMMtG1c3hb6ZmTWnm6Z3zMysSQ59M7OEOPTNzBLi0DczS4hD38wsIQ59M7OEOPTNzBLyf5f8JrmVvWKzAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[\"Q_length\"].hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "7b146065",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[\"A_length\"].hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7fe822ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_org = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "e6fbb17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_org.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "cffdc0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"Q_length\"] < 20]\n",
    "df = df[df[\"A_length\"] < 20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "58dc6e6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 11687 entries, 0 to 11686\n",
      "Data columns (total 9 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   Q            11687 non-null  object\n",
      " 1   A            11687 non-null  object\n",
      " 2   label        11687 non-null  int64 \n",
      " 3   Q_cleaned    11687 non-null  object\n",
      " 4   A_cleaned    11687 non-null  object\n",
      " 5   Q_tokenized  11687 non-null  object\n",
      " 6   A_tokenized  11687 non-null  object\n",
      " 7   Q_length     11687 non-null  int64 \n",
      " 8   A_length     11687 non-null  int64 \n",
      "dtypes: int64(3), object(6)\n",
      "memory usage: 913.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fdc169a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[\"Q_length\"].hist(bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "fe8ccf1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[\"A_length\"].hist(bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "868bd3b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "      <th>label</th>\n",
       "      <th>Q_cleaned</th>\n",
       "      <th>A_cleaned</th>\n",
       "      <th>Q_tokenized</th>\n",
       "      <th>A_tokenized</th>\n",
       "      <th>Q_length</th>\n",
       "      <th>A_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12시 땡!</td>\n",
       "      <td>하루가 또 가네요.</td>\n",
       "      <td>0</td>\n",
       "      <td>시 땡</td>\n",
       "      <td>하루가 또 가네요</td>\n",
       "      <td>[시, 땡]</td>\n",
       "      <td>[하루, 가, 또, 가, 네요]</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1지망 학교 떨어졌어</td>\n",
       "      <td>위로해 드립니다.</td>\n",
       "      <td>0</td>\n",
       "      <td>지망 학교 떨어졌어</td>\n",
       "      <td>위로해 드립니다</td>\n",
       "      <td>[지망, 학교, 떨어졌, 어]</td>\n",
       "      <td>[위로, 해, 드립니다]</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3박4일 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "      <td>박 일 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠</td>\n",
       "      <td>[박, 일, 놀, 러, 가, 고, 싶, 다]</td>\n",
       "      <td>[여행, 은, 언제나, 좋, 죠]</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3박4일 정도 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "      <td>박 일 정도 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠</td>\n",
       "      <td>[박, 일, 정도, 놀, 러, 가, 고, 싶, 다]</td>\n",
       "      <td>[여행, 은, 언제나, 좋, 죠]</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PPL 심하네</td>\n",
       "      <td>눈살이 찌푸려지죠.</td>\n",
       "      <td>0</td>\n",
       "      <td>ppl 심하네</td>\n",
       "      <td>눈살이 찌푸려지죠</td>\n",
       "      <td>[ppl, 심하, 네]</td>\n",
       "      <td>[눈살, 이, 찌푸려, 지, 죠]</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SD카드 망가졌어</td>\n",
       "      <td>다시 새로 사는 게 마음 편해요.</td>\n",
       "      <td>0</td>\n",
       "      <td>sd카드 망가졌어</td>\n",
       "      <td>다시 새로 사는 게 마음 편해요</td>\n",
       "      <td>[sd, 카드, 망가졌, 어]</td>\n",
       "      <td>[다시, 새로, 사, 는, 게, 마음, 편해요]</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SD카드 안돼</td>\n",
       "      <td>다시 새로 사는 게 마음 편해요.</td>\n",
       "      <td>0</td>\n",
       "      <td>sd카드 안돼</td>\n",
       "      <td>다시 새로 사는 게 마음 편해요</td>\n",
       "      <td>[sd, 카드, 안, 돼]</td>\n",
       "      <td>[다시, 새로, 사, 는, 게, 마음, 편해요]</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SNS 맞팔 왜 안하지ㅠㅠ</td>\n",
       "      <td>잘 모르고 있을 수도 있어요.</td>\n",
       "      <td>0</td>\n",
       "      <td>sns 맞팔 왜 안하지</td>\n",
       "      <td>잘 모르고 있을 수도 있어요</td>\n",
       "      <td>[sns, 맞, 팔, 왜, 안, 하, 지]</td>\n",
       "      <td>[잘, 모르, 고, 있, 을, 수, 도, 있, 어요]</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SNS 시간낭비인 거 아는데 매일 하는 중</td>\n",
       "      <td>시간을 정하고 해보세요.</td>\n",
       "      <td>0</td>\n",
       "      <td>sns 시간낭비인 거 아는데 매일 하는 중</td>\n",
       "      <td>시간을 정하고 해보세요</td>\n",
       "      <td>[sns, 시간, 낭비, 인, 거, 아, 는데, 매일, 하, 는, 중]</td>\n",
       "      <td>[시간, 을, 정하, 고, 해, 보, 세요]</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SNS 시간낭비인데 자꾸 보게됨</td>\n",
       "      <td>시간을 정하고 해보세요.</td>\n",
       "      <td>0</td>\n",
       "      <td>sns 시간낭비인데 자꾸 보게됨</td>\n",
       "      <td>시간을 정하고 해보세요</td>\n",
       "      <td>[sns, 시간, 낭비, 인데, 자꾸, 보, 게, 됨]</td>\n",
       "      <td>[시간, 을, 정하, 고, 해, 보, 세요]</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Q                   A  label  \\\n",
       "0                   12시 땡!          하루가 또 가네요.      0   \n",
       "1              1지망 학교 떨어졌어           위로해 드립니다.      0   \n",
       "2             3박4일 놀러가고 싶다         여행은 언제나 좋죠.      0   \n",
       "3          3박4일 정도 놀러가고 싶다         여행은 언제나 좋죠.      0   \n",
       "4                  PPL 심하네          눈살이 찌푸려지죠.      0   \n",
       "5                SD카드 망가졌어  다시 새로 사는 게 마음 편해요.      0   \n",
       "6                  SD카드 안돼  다시 새로 사는 게 마음 편해요.      0   \n",
       "7           SNS 맞팔 왜 안하지ㅠㅠ    잘 모르고 있을 수도 있어요.      0   \n",
       "8  SNS 시간낭비인 거 아는데 매일 하는 중       시간을 정하고 해보세요.      0   \n",
       "9        SNS 시간낭비인데 자꾸 보게됨       시간을 정하고 해보세요.      0   \n",
       "\n",
       "                 Q_cleaned            A_cleaned  \\\n",
       "0                    시 땡            하루가 또 가네요     \n",
       "1               지망 학교 떨어졌어           위로해 드립니다     \n",
       "2              박 일 놀러가고 싶다         여행은 언제나 좋죠     \n",
       "3           박 일 정도 놀러가고 싶다         여행은 언제나 좋죠     \n",
       "4                  ppl 심하네          눈살이 찌푸려지죠     \n",
       "5                sd카드 망가졌어  다시 새로 사는 게 마음 편해요     \n",
       "6                  sd카드 안돼  다시 새로 사는 게 마음 편해요     \n",
       "7            sns 맞팔 왜 안하지     잘 모르고 있을 수도 있어요     \n",
       "8  sns 시간낭비인 거 아는데 매일 하는 중       시간을 정하고 해보세요     \n",
       "9        sns 시간낭비인데 자꾸 보게됨       시간을 정하고 해보세요     \n",
       "\n",
       "                               Q_tokenized                    A_tokenized  \\\n",
       "0                                   [시, 땡]              [하루, 가, 또, 가, 네요]   \n",
       "1                         [지망, 학교, 떨어졌, 어]                  [위로, 해, 드립니다]   \n",
       "2                 [박, 일, 놀, 러, 가, 고, 싶, 다]             [여행, 은, 언제나, 좋, 죠]   \n",
       "3             [박, 일, 정도, 놀, 러, 가, 고, 싶, 다]             [여행, 은, 언제나, 좋, 죠]   \n",
       "4                             [ppl, 심하, 네]             [눈살, 이, 찌푸려, 지, 죠]   \n",
       "5                         [sd, 카드, 망가졌, 어]     [다시, 새로, 사, 는, 게, 마음, 편해요]   \n",
       "6                           [sd, 카드, 안, 돼]     [다시, 새로, 사, 는, 게, 마음, 편해요]   \n",
       "7                  [sns, 맞, 팔, 왜, 안, 하, 지]  [잘, 모르, 고, 있, 을, 수, 도, 있, 어요]   \n",
       "8  [sns, 시간, 낭비, 인, 거, 아, 는데, 매일, 하, 는, 중]       [시간, 을, 정하, 고, 해, 보, 세요]   \n",
       "9           [sns, 시간, 낭비, 인데, 자꾸, 보, 게, 됨]       [시간, 을, 정하, 고, 해, 보, 세요]   \n",
       "\n",
       "   Q_length  A_length  \n",
       "0         2         5  \n",
       "1         4         3  \n",
       "2         8         5  \n",
       "3         9         5  \n",
       "4         3         5  \n",
       "5         4         7  \n",
       "6         4         7  \n",
       "7         7         9  \n",
       "8        11         7  \n",
       "9         8         7  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c6636656",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "310bb866",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_var(df, \"df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "799e7e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_var(\"df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7b0e56c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "e7969bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = df[\"Q_tokenized\"]\n",
    "answers = df[\"A_tokenized\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f769f5",
   "metadata": {},
   "source": [
    "# Step 4. Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8213f4",
   "metadata": {},
   "source": [
    "우리에게 주어진 데이터는 1만 개가량으로 적은 편에 속합니다.   \n",
    "이럴 때에 사용할 수 있는 테크닉을 배웠으니 활용해 봐야겠죠?   \n",
    "Lexical Substitution을 실제로 적용해 보도록 하겠습니다.  \n",
    "\n",
    "아래 링크를 참고하여 한국어로 사전 훈련된 Embedding 모델을 다운로드합니다.   \n",
    "Korean (w) 가 Word2Vec으로 학습한 모델이며 용량도 적당하므로 사이트에서 Korean (w)를 찾아 다운로드하고, ko.bin 파일을 얻으세요!  \n",
    "\n",
    "Kyubyong/wordvectors  \n",
    "\n",
    "다운로드한 모델을 활용해 데이터를 Augmentation 하세요! 앞서 정의한 lexical_sub() 함수를 참고하면 도움이 많이 될 겁니다.  \n",
    "\n",
    "Augmentation된 que_corpus 와 원본 ans_corpus 가 병렬을 이루도록,   \n",
    "이후엔 반대로 원본 que_corpus 와 Augmentation된 ans_corpus 가 병렬을 이루도록 하여 전체 데이터가 원래의 3배가량으로 늘어나도록 합니다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "67c997b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd779812",
   "metadata": {},
   "outputs": [],
   "source": [
    "wv = Word2Vec.load(\"./data/word2vec_ko.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "e47739fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('사본', 0.838905930519104),\n",
       " ('원문', 0.809522807598114),\n",
       " ('본문', 0.7485238909721375),\n",
       " ('필사본', 0.743165910243988),\n",
       " ('복사본', 0.7308973073959351),\n",
       " ('판본', 0.7296765446662903),\n",
       " ('인쇄물', 0.68619704246521),\n",
       " ('번역본', 0.6790832281112671),\n",
       " ('대본', 0.6752506494522095),\n",
       " ('문헌', 0.6715538501739502)]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.wv.most_similar(\"원본\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "3f36c811",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lexical_sub(sentence, wv, sentence_num=2, verbose=False):\n",
    "    if verbose: print(sentence)\n",
    "        \n",
    "    sentences = []\n",
    "    for _ in range(sentence_num):\n",
    "        sentences.append(\" \".join(sentence).split())  # to avoid overwriting the sentence\n",
    "    \n",
    "    if not sentences[0]: return None\n",
    "    \n",
    "#     res = mecab.pos(\" \".join(sentence))\n",
    "#     if verbose: print(res)\n",
    "#     indices_exchange = [i for i, word in enumerate(res) if word[1] in [\"NNG\", \"VV\", \"VV+EP\"]]\n",
    "#     if verbose: print(indices_exchange, end=' --> ')        \n",
    "#     random.shuffle(indices_exchange)\n",
    "#     unique_indices = indices_exchange[:sentence_num]\n",
    "#     if verbose: print(indices_exchange, unique_indices)\n",
    "\n",
    "    indices = list(range(len(sentence)))\n",
    "    random.shuffle(indices)    \n",
    "    unique_indices = indices[:sentence_num]\n",
    "\n",
    "    for i, index in enumerate(unique_indices):\n",
    "        word = sentences[i][index]\n",
    "        if word in wv:\n",
    "            similar_word = wv.most_similar(word)\n",
    "            if not similar_word:\n",
    "                return None\n",
    "            if verbose: print(similar_word[0][0], end=\", \")\n",
    "\n",
    "            word_sub = similar_word[0][0]\n",
    "            sentences[i][index] = word_sub\n",
    "    \n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "c8667c4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['나', '만', '일시', '켜', '서', '짜증', '폭발']\n",
      "웃기, 든, [['나', '만', '일시', '켜', '서', '웃기', '폭발'], ['든', '만', '일시', '켜', '서', '짜증', '폭발']]\n"
     ]
    }
   ],
   "source": [
    "res = lexical_sub(questions[633], wv.wv, sentence_num=2, verbose=True)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd491590",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "7f9652cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b768ba7781cf48c5a3fcd65c25c00a47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11687 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "corpus_aug = []\n",
    "count_none = 0\n",
    "\n",
    "for que, ans in tqdm(zip(questions, answers), total=len(questions)):\n",
    "    corpus_aug.append((que, ans))\n",
    "    sentences = lexical_sub(que, wv.wv, sentence_num=1)\n",
    "    for sentence in sentences:\n",
    "        if sentence is not None: \n",
    "            corpus_aug.append((sentence, ans))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f9cbcf4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35061\n",
      " 0 ['시', '땡']\n",
      " 1 ['시', '돌이']\n",
      " 2 ['시경', '땡']\n",
      " 3 ['지망', '학교', '떨어졌', '어']\n",
      " 4 ['지망', '학교', '올라갔', '어']\n",
      " 5 ['지망', '학교', '떨어졌', '어서']\n",
      " 6 ['박', '일', '놀', '러', '가', '고', '싶', '다']\n",
      " 7 ['김', '일', '놀', '러', '가', '고', '싶', '다']\n",
      " 8 ['박', '일', '울', '러', '가', '고', '싶', '다']\n",
      " 9 ['박', '일', '정도', '놀', '러', '가', '고', '싶', '다']\n",
      "10 ['박', '일', '정도', '울', '러', '가', '고', '싶', '다']\n",
      "11 ['박', '일', '만큼', '놀', '러', '가', '고', '싶', '다']\n"
     ]
    }
   ],
   "source": [
    "print(len(corpus_aug))\n",
    "for index, sentence in enumerate(corpus_aug):\n",
    "    print(f\"{index:2}\", sentence[0])\n",
    "    if index > 10: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "e5a35763",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_var(corpus_aug, \"corpus_aug_x2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "adf5212c",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_aug = load_var(\"corpus_aug_x3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58e5f77",
   "metadata": {},
   "source": [
    "### 중복 데이터 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "509aac30",
   "metadata": {},
   "outputs": [],
   "source": [
    "que_corpus, ans_corpus = zip(*corpus_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "38802d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corpus = pd.DataFrame({'questions': que_corpus, 'answers': ans_corpus})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "9e3df726",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corpus[\"questions\"] = df_corpus[\"questions\"].apply(tuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7e448110",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>questions</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(시, 땡)</td>\n",
       "      <td>[하루, 가, 또, 가, 네요]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(시, 돌이)</td>\n",
       "      <td>[하루, 가, 또, 가, 네요]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(시경, 땡)</td>\n",
       "      <td>[하루, 가, 또, 가, 네요]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  questions            answers\n",
       "0    (시, 땡)  [하루, 가, 또, 가, 네요]\n",
       "1   (시, 돌이)  [하루, 가, 또, 가, 네요]\n",
       "2   (시경, 땡)  [하루, 가, 또, 가, 네요]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_corpus.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "57bca8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corpus = df_corpus.drop_duplicates(subset=\"questions\", keep=\"first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "b5f73a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corpus_copy = df_corpus.copy()\n",
    "df_corpus_copy[\"questions\"] = df_corpus_copy[\"questions\"].apply(list)\n",
    "df_corpus = df_corpus.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a34477",
   "metadata": {},
   "source": [
    "# Step 5. 데이터 벡터화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf91b640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<start>', '12', '시', '땡', '!', '<end>']\n"
     ]
    }
   ],
   "source": [
    "sample_data = [\"12\", \"시\", \"땡\", \"!\"]\n",
    "\n",
    "print([\"<start>\"] + sample_data + [\"<end>\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75430667",
   "metadata": {},
   "source": [
    "1. 위 소스를 참고하여 타겟 데이터 전체에 <start> 토큰과 <end> 토큰을 추가해 주세요!   \n",
    "\n",
    "챗봇 훈련 데이터의 가장 큰 특징 중 하나라고 하자면 바로 소스 데이터와 타겟 데이터가 같은 언어를 사용한다는 것이겠죠.  \n",
    "앞서 배운 것처럼 이는 Embedding 층을 공유했을 때 많은 이점을 얻을 수 있습니다.  \n",
    "\n",
    "2. 특수 토큰을 더함으로써 ans_corpus 또한 완성이 되었으니, que_corpus 와 결합하여 전체 데이터에 대한 단어 사전을 구축하고 벡터화하여 enc_train 과 dec_train 을 얻으세요!  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "23177045",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "84770604",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corpus_copy = df_corpus.copy()\n",
    "df_corpus_copy[\"target_tokens\"] = [[\"<start>\"] + s + [\"<end>\"] for s in df_corpus_copy[\"answers\"]]\n",
    "df_corpus = df_corpus_copy.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "9ac9dbd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['<start>', '하루', '가', '또', '가', '네요', '<end>'],\n",
       " ['<start>', '위로', '해', '드립니다', '<end>'],\n",
       " ['<start>', '여행', '은', '언제나', '좋', '죠', '<end>']]"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgt_tokens = [[\"<start>\"] + s + [\"<end>\"] for s in ans_tokens]\n",
    "tgt_tokens[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "55ee503b",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_var(que_tokens, \"que_tokens_base\")\n",
    "save_var(ans_tokens, \"ans_tokens_base\")\n",
    "save_var(tgt_tokens, \"tgt_tokens_base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "f4b4e664",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corpus[\"questions\"] = df_corpus[\"questions\"].apply(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "e0def8ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>questions</th>\n",
       "      <th>answers</th>\n",
       "      <th>target_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['시', '땡']</td>\n",
       "      <td>['하루', '가', '또', '가', '네요']</td>\n",
       "      <td>['&lt;start&gt;', '하루', '가', '또', '가', '네요', '&lt;end&gt;']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['시', '돌이']</td>\n",
       "      <td>['하루', '가', '또', '가', '네요']</td>\n",
       "      <td>['&lt;start&gt;', '하루', '가', '또', '가', '네요', '&lt;end&gt;']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['앵커', '심상소학교', '떨어졌', '어']</td>\n",
       "      <td>['위로', '해', '드립니다']</td>\n",
       "      <td>['&lt;start&gt;', '위로', '해', '드립니다', '&lt;end&gt;']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     questions                      answers  \\\n",
       "0                   ['시', '땡']  ['하루', '가', '또', '가', '네요']   \n",
       "1                  ['시', '돌이']  ['하루', '가', '또', '가', '네요']   \n",
       "2  ['앵커', '심상소학교', '떨어졌', '어']          ['위로', '해', '드립니다']   \n",
       "\n",
       "                                     target_tokens  \n",
       "0  ['<start>', '하루', '가', '또', '가', '네요', '<end>']  \n",
       "1  ['<start>', '하루', '가', '또', '가', '네요', '<end>']  \n",
       "2          ['<start>', '위로', '해', '드립니다', '<end>']  "
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_corpus.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "ec0b72ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corpus.to_csv(\"df_corpus_x2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "96fb7955",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corpus = pd.read_csv(\"df_corpus_x3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "c0011960",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_var(df_corpus, \"df_corpus_x2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6e409dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corpus = load_var(\"df_corpus_x3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "e728ebce",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_corpus = df_corpus[\"questions\"].to_list() + df_corpus[\"target_tokens\"].to_list()\n",
    "\n",
    "tokenizer = Tokenizer(filters=\"\", lower=False, oov_token=\"<unk>\")\n",
    "tokenizer.fit_on_texts(total_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "ff5e4653",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_corpus = que_tokens + tgt_tokens\n",
    "\n",
    "tokenizer = Tokenizer(filters=\"\", lower=False, oov_token=\"<unk>\")\n",
    "tokenizer.fit_on_texts(total_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "ed9043af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6765"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "26fd6282",
   "metadata": {},
   "outputs": [],
   "source": [
    "que_seqs = tokenizer.texts_to_sequences(df_corpus[\"questions\"])\n",
    "ans_seqs = tokenizer.texts_to_sequences(df_corpus[\"target_tokens\"])\n",
    "\n",
    "enc_train = pad_sequences(que_seqs, padding=\"post\")\n",
    "dec_train = pad_sequences(ans_seqs, padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "cb041c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "que_seqs = tokenizer.texts_to_sequences(que_tokens)\n",
    "ans_seqs = tokenizer.texts_to_sequences(tgt_tokens)\n",
    "\n",
    "enc_train = pad_sequences(que_seqs, padding=\"post\")\n",
    "dec_train = pad_sequences(ans_seqs, padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "099ab2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_var(enc_train, \"enc_train_t5\")\n",
    "save_var(dec_train, \"dec_train_t5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3e121066",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_train = load_var(\"enc_train\")\n",
    "dec_train = load_var(\"dec_train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "52556b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((enc_train, dec_train)).batch(batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb4fb65",
   "metadata": {},
   "source": [
    "# Step 6. 훈련하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761889f2",
   "metadata": {},
   "source": [
    "## transformer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e23a48b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def positional_encoding(pos, d_model):\n",
    "    def cal_angle(position, i):\n",
    "        return position / np.power(10000, (2*(i//2)) / np.float32(d_model))\n",
    "\n",
    "    def get_posi_angle_vec(position):\n",
    "        return [cal_angle(position, i) for i in range(d_model)]\n",
    "\n",
    "    sinusoid_table = np.array([get_posi_angle_vec(pos_i) for pos_i in range(pos)])\n",
    "\n",
    "    sinusoid_table[:, 0::2] = np.sin(sinusoid_table[:, 0::2])\n",
    "    sinusoid_table[:, 1::2] = np.cos(sinusoid_table[:, 1::2])\n",
    "\n",
    "    return sinusoid_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4f920c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_padding_mask(seq):\n",
    "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "    return seq[:, tf.newaxis, tf.newaxis, :]\n",
    "\n",
    "def generate_lookahead_mask(size):\n",
    "    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
    "    return mask\n",
    "\n",
    "def generate_masks(src, tgt):\n",
    "    enc_mask = generate_padding_mask(src)\n",
    "    dec_enc_mask = generate_padding_mask(src)\n",
    "\n",
    "    dec_lookahead_mask = generate_lookahead_mask(tgt.shape[1])\n",
    "    dec_tgt_padding_mask = generate_padding_mask(tgt)\n",
    "    dec_mask = tf.maximum(dec_tgt_padding_mask, dec_lookahead_mask)\n",
    "\n",
    "    return enc_mask, dec_enc_mask, dec_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "95c63242",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "        \n",
    "        self.depth = d_model // self.num_heads\n",
    "        \n",
    "        self.W_q = tf.keras.layers.Dense(d_model)\n",
    "        self.W_k = tf.keras.layers.Dense(d_model)\n",
    "        self.W_v = tf.keras.layers.Dense(d_model)\n",
    "        \n",
    "        self.linear = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "    def scaled_dot_product_attention(self, Q, K, V, mask):\n",
    "        d_k = tf.cast(K.shape[-1], tf.float32)\n",
    "        QK = tf.matmul(Q, K, transpose_b=True)\n",
    "\n",
    "        scaled_qk = QK / tf.math.sqrt(d_k)\n",
    "\n",
    "        if mask is not None: scaled_qk += (mask * -1e9)  \n",
    "\n",
    "        attentions = tf.nn.softmax(scaled_qk, axis=-1)\n",
    "        out = tf.matmul(attentions, V)\n",
    "\n",
    "        return out, attentions\n",
    "        \n",
    "\n",
    "    def split_heads(self, x):\n",
    "        bsz = x.shape[0]\n",
    "        split_x = tf.reshape(x, (bsz, -1, self.num_heads, self.depth))\n",
    "        split_x = tf.transpose(split_x, perm=[0, 2, 1, 3])\n",
    "\n",
    "        return split_x\n",
    "\n",
    "    def combine_heads(self, x):\n",
    "        bsz = x.shape[0]\n",
    "        combined_x = tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "        combined_x = tf.reshape(combined_x, (bsz, -1, self.d_model))\n",
    "\n",
    "        return combined_x\n",
    "\n",
    "    \n",
    "    def call(self, Q, K, V, mask):\n",
    "        WQ = self.W_q(Q)\n",
    "        WK = self.W_k(K)\n",
    "        WV = self.W_v(V)\n",
    "        \n",
    "        WQ_splits = self.split_heads(WQ)\n",
    "        WK_splits = self.split_heads(WK)\n",
    "        WV_splits = self.split_heads(WV)\n",
    "        \n",
    "        out, attention_weights = self.scaled_dot_product_attention(\n",
    "            WQ_splits, WK_splits, WV_splits, mask)\n",
    "                        \n",
    "        out = self.combine_heads(out)\n",
    "        out = self.linear(out)\n",
    "            \n",
    "        return out, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "862b85db",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PoswiseFeedForwardNet(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, d_ff):\n",
    "        super(PoswiseFeedForwardNet, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.d_ff = d_ff\n",
    "\n",
    "        self.fc1 = tf.keras.layers.Dense(d_ff, activation='relu')\n",
    "        self.fc2 = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "    def call(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.fc2(out)\n",
    "            \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5ac362dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, n_heads, d_ff, dropout):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "\n",
    "        self.enc_self_attn = MultiHeadAttention(d_model, n_heads)\n",
    "        self.ffn = PoswiseFeedForwardNet(d_model, d_ff)\n",
    "\n",
    "        self.norm_1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.norm_2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.do = tf.keras.layers.Dropout(dropout)\n",
    "        \n",
    "    def call(self, x, mask):\n",
    "        '''\n",
    "        Multi-Head Attention\n",
    "        '''\n",
    "        residual = x\n",
    "        out = self.norm_1(x)\n",
    "        out, enc_attn = self.enc_self_attn(out, out, out, mask)\n",
    "        out = self.do(out)\n",
    "        out += residual\n",
    "        \n",
    "        '''\n",
    "        Position-Wise Feed Forward Network\n",
    "        '''\n",
    "        residual = out\n",
    "        out = self.norm_2(out)\n",
    "        out = self.ffn(out)\n",
    "        out = self.do(out)\n",
    "        out += residual\n",
    "        \n",
    "        return out, enc_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4f1cd7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "\n",
    "        self.dec_self_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.enc_dec_attn = MultiHeadAttention(d_model, num_heads)\n",
    "\n",
    "        self.ffn = PoswiseFeedForwardNet(d_model, d_ff)\n",
    "\n",
    "        self.norm_1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.norm_2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.norm_3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.do = tf.keras.layers.Dropout(dropout)\n",
    "    \n",
    "    def call(self, x, enc_out, dec_enc_mask, padding_mask):\n",
    "        '''\n",
    "        Masked Multi-Head Attention\n",
    "        '''\n",
    "        residual = x\n",
    "        out = self.norm_1(x)\n",
    "        out, dec_attn = self.dec_self_attn(out, out, out, padding_mask)\n",
    "        out = self.do(out)\n",
    "        out += residual\n",
    "\n",
    "        '''\n",
    "        Multi-Head Attention\n",
    "        '''\n",
    "        residual = out\n",
    "        out = self.norm_2(out)\n",
    "        # Q, K, V 순서에 주의하세요!\n",
    "        out, dec_enc_attn = self.enc_dec_attn(Q=out, K=enc_out, V=enc_out, mask=dec_enc_mask)\n",
    "        out = self.do(out)\n",
    "        out += residual\n",
    "        \n",
    "        '''\n",
    "        Position-Wise Feed Forward Network\n",
    "        '''\n",
    "        residual = out\n",
    "        out = self.norm_3(out)\n",
    "        out = self.ffn(out)\n",
    "        out = self.do(out)\n",
    "        out += residual\n",
    "\n",
    "        return out, dec_attn, dec_enc_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b03ceac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self,\n",
    "                    n_layers,\n",
    "                    d_model,\n",
    "                    n_heads,\n",
    "                    d_ff,\n",
    "                    dropout):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.enc_layers = [EncoderLayer(d_model, n_heads, d_ff, dropout) \n",
    "                        for _ in range(n_layers)]\n",
    "    \n",
    "        self.do = tf.keras.layers.Dropout(dropout)\n",
    "        \n",
    "    def call(self, x, mask):\n",
    "        out = x\n",
    "    \n",
    "        enc_attns = list()\n",
    "        for i in range(self.n_layers):\n",
    "            out, enc_attn = self.enc_layers[i](out, mask)\n",
    "            enc_attns.append(enc_attn)\n",
    "        \n",
    "        return out, enc_attns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d3186c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self,\n",
    "                    n_layers,\n",
    "                    d_model,\n",
    "                    n_heads,\n",
    "                    d_ff,\n",
    "                    dropout):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.dec_layers = [DecoderLayer(d_model, n_heads, d_ff, dropout) \n",
    "                            for _ in range(n_layers)]\n",
    "                            \n",
    "    def call(self, x, enc_out, dec_enc_mask, padding_mask):\n",
    "        out = x\n",
    "    \n",
    "        dec_attns = list()\n",
    "        dec_enc_attns = list()\n",
    "        for i in range(self.n_layers):\n",
    "            out, dec_attn, dec_enc_attn = \\\n",
    "            self.dec_layers[i](out, enc_out, dec_enc_mask, padding_mask)\n",
    "\n",
    "            dec_attns.append(dec_attn)\n",
    "            dec_enc_attns.append(dec_enc_attn)\n",
    "\n",
    "        return out, dec_attns, dec_enc_attns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "48a91539",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "    def __init__(self,\n",
    "                    n_layers,\n",
    "                    d_model,\n",
    "                    n_heads,\n",
    "                    d_ff,\n",
    "                    src_vocab_size,\n",
    "                    tgt_vocab_size,\n",
    "                    pos_len,\n",
    "                    dropout=0.2,\n",
    "                    shared_fc=True,\n",
    "                    shared_emb=False):\n",
    "        super(Transformer, self).__init__()\n",
    "        \n",
    "        self.d_model = tf.cast(d_model, tf.float32)\n",
    "\n",
    "        if shared_emb:\n",
    "            self.enc_emb = self.dec_emb = \\\n",
    "            tf.keras.layers.Embedding(src_vocab_size, d_model)\n",
    "        else:\n",
    "            self.enc_emb = tf.keras.layers.Embedding(src_vocab_size, d_model)\n",
    "            self.dec_emb = tf.keras.layers.Embedding(tgt_vocab_size, d_model)\n",
    "\n",
    "        self.pos_encoding = positional_encoding(pos_len, d_model)\n",
    "        self.do = tf.keras.layers.Dropout(dropout)\n",
    "\n",
    "        self.encoder = Encoder(n_layers, d_model, n_heads, d_ff, dropout)\n",
    "        self.decoder = Decoder(n_layers, d_model, n_heads, d_ff, dropout)\n",
    "\n",
    "        self.fc = tf.keras.layers.Dense(tgt_vocab_size)\n",
    "\n",
    "        self.shared_fc = shared_fc\n",
    "\n",
    "        if shared_fc:\n",
    "            self.fc.set_weights(tf.transpose(self.dec_emb.weights))\n",
    "\n",
    "    def embedding(self, emb, x):\n",
    "        seq_len = x.shape[1]\n",
    "\n",
    "        out = emb(x)\n",
    "\n",
    "        if self.shared_fc: out *= tf.math.sqrt(self.d_model)\n",
    "\n",
    "        out += self.pos_encoding[np.newaxis, ...][:, :seq_len, :]\n",
    "        out = self.do(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "        \n",
    "    def call(self, enc_in, dec_in, enc_mask, dec_enc_mask, dec_mask):\n",
    "        enc_in = self.embedding(self.enc_emb, enc_in)\n",
    "        dec_in = self.embedding(self.dec_emb, dec_in)\n",
    "\n",
    "        enc_out, enc_attns = self.encoder(enc_in, enc_mask)\n",
    "        \n",
    "        dec_out, dec_attns, dec_enc_attns = \\\n",
    "        self.decoder(dec_in, enc_out, dec_enc_mask, dec_mask)\n",
    "        \n",
    "        logits = self.fc(dec_out)\n",
    "        \n",
    "        return logits, enc_attns, dec_attns, dec_enc_attns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "ddbf6470",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model = 512\n",
    "\n",
    "transformer = Transformer(\n",
    "    n_layers=2,\n",
    "    d_model=d_model,\n",
    "    n_heads=8,\n",
    "    d_ff=2048,\n",
    "    src_vocab_size=vocab_size,\n",
    "    tgt_vocab_size=vocab_size,\n",
    "    pos_len=200,\n",
    "    dropout=0.2,\n",
    "    shared_fc=True,\n",
    "    shared_emb=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e01a99",
   "metadata": {},
   "source": [
    "## LearningRateScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "28ca987a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LearningRateScheduler(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(LearningRateScheduler, self).__init__()\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.warmup_steps = warmup_steps\n",
    "    \n",
    "    def __call__(self, step):\n",
    "        arg1 = step ** -0.5\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "        \n",
    "        return (self.d_model ** -0.5) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "16954489",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = LearningRateScheduler(d_model)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate,\n",
    "                                        beta_1=0.9,\n",
    "                                        beta_2=0.98, \n",
    "                                        epsilon=1e-9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69830479",
   "metadata": {},
   "source": [
    "## Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "11ebe597",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_sum(loss_)/tf.reduce_sum(mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed00250f",
   "metadata": {},
   "source": [
    "## Train Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "cae7257b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function()\n",
    "def train_step(src, tgt, model, optimizer):\n",
    "    tgt_in = tgt[:, :-1]  # Decoder의 input\n",
    "    gold = tgt[:, 1:]     # Decoder의 output과 비교하기 위해 right shift를 통해 생성한 최종 타겟\n",
    "\n",
    "    enc_mask, dec_enc_mask, dec_mask = generate_masks(src, tgt_in)\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions, enc_attns, dec_attns, dec_enc_attns = \\\n",
    "        model(src, tgt_in, enc_mask, dec_enc_mask, dec_mask)\n",
    "        loss = loss_function(gold, predictions)\n",
    "\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)    \n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    return loss, enc_attns, dec_attns, dec_enc_attns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a0ff82",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "c3ca447e",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "099a7ef8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70261fffd47343c7b0c1965b84c2ba70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss 458.7256\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01ae1c6b6fef43269d041ea3a3f6e146",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Loss 305.9370\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67fd2730c0a54b319f9ee5abc67612f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Loss 223.2291\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e182d048fa894964b4e96acace8fbdb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Loss 154.1464\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4aa5d1ea494b49518ee484d5adde6b4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Loss 105.1686\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d79d296f2f64163873c057cf9a055bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Loss 69.6087\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6b53d6d094f4d4b91e2aa0572cfaff6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 Loss 47.3358\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f58caee187a541a78a7578b8198bc867",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 Loss 34.4506\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43920942f7aa4c6ebe0000ee71537abc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 Loss 25.6987\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e15232b1f03547b1a7f028f4eb4445a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 Loss 20.6704\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "375cd64846b243e59c35e32cdaf6f68d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 Loss 16.0774\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4223b3f987f9455eaea31b6f1f54da17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 Loss 13.9474\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8547216d78864e3a96a596cca0ac16f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 Loss 12.8010\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "504073413b45402187db92d72c129bb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 Loss 10.9574\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "014a3d9e4455425e94387c58ed9f2819",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 Loss 9.8426\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a267e6235b244c39ab6ff54a97447de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 Loss 10.0936\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12de34acf2294a8380d5dfb2e25aa9ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 Loss 9.1313\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "990a18e62e5b4e498f6440816d85b504",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 Loss 8.2776\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5806ff1c773745449a94477fc249357e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 Loss 7.5040\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ea8933cd97349558d17d566c4d0c3ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 Loss 7.4501\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 20\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    total_loss = 0\n",
    "    \n",
    "    dataset_count = tf.data.experimental.cardinality(train_dataset).numpy()\n",
    "    tqdm_bar = tqdm(total=dataset_count)\n",
    "    \n",
    "    for (src, tgt) in train_dataset:\n",
    "        loss, enc_attns, dec_attns, dec_enc_attns = train_step(src, tgt, transformer, optimizer)\n",
    "        total_loss += loss\n",
    "        tqdm_bar.set_description(f'Epoch {epoch + 1} Loss {total_loss.numpy():.4f}')\n",
    "        tqdm_bar.update()\n",
    "    tqdm_bar.close()\n",
    "    losses.append(total_loss.numpy())\n",
    "    print(f'Epoch {epoch + 1} Loss {total_loss.numpy():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "134b22ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"t5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "4caf91a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer.save_weights(prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "b39d4923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[458.72556, 305.93698, 223.22914, 154.14638, 105.16861, 69.60865, 47.335815, 34.450607, 25.698656, 20.670425, 16.077423, 13.947396, 12.800986, 10.957445, 9.842569, 10.093627, 9.131347, 8.277581, 7.504043, 7.450125]\n"
     ]
    }
   ],
   "source": [
    "print(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "88d970da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fc7cf7dec70>]"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "5d378b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "histories = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "893b727a",
   "metadata": {},
   "outputs": [],
   "source": [
    "histories[prefix] = losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "de497938",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_var(histories, \"histories\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "ee9b31d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "histories = load_var(\"histories\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "48fa7cf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'t0': [3832.5205, 2699.2415, 2176.4763], 't2': [3019.052, 2088.4956, 1682.1465, 1293.043, 1016.2196, 890.7383, 821.02826, 798.14386, 676.56366, 530.8138, 422.03873, 345.6523, 292.3675, 251.544, 222.10175, 192.92442, 169.73122, 149.50732, 134.93729, 118.146194], 't3': [1196.5056, 770.89154, 515.7512, 332.12772, 218.50471, 153.27972, 111.07922, 87.32306, 69.94883, 60.657585, 51.169834, 46.357754, 41.018753, 36.591194, 34.529594, 31.869173, 30.55571, 27.797064, 26.021723, 24.426159], 't4': [829.39075, 553.6872, 388.4518, 256.35968, 163.90486, 106.86399, 73.23022, 55.18291, 42.760113, 34.53064, 28.88408, 25.128407, 21.6047, 19.305098, 16.911804, 15.340065, 14.466317, 13.576882, 12.711096, 12.083197]}\n"
     ]
    }
   ],
   "source": [
    "print(histories)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ae08dc",
   "metadata": {},
   "source": [
    "- t0: base. 3 epochs\n",
    "- t1: 20 epochs\n",
    "- t2: data aug. x4 --> x3\n",
    "- t3: batch size. 64 --> 128\n",
    "- t4: data aug. x3 --> x2\n",
    "- t5: fix. dataframe --> list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9c774a",
   "metadata": {},
   "source": [
    "# Step 7. 성능 측정하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8204aad3",
   "metadata": {},
   "source": [
    "주어진 질문에 적절한 답변을 하는지 확인하고, BLEU Score를 계산하는 calculate_bleu() 함수도 적용해 보세요."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15df9e6",
   "metadata": {},
   "source": [
    "```\n",
    "# 예문\n",
    "1. 지루하다, 놀러가고 싶어.\n",
    "2. 오늘 일찍 일어났더니 피곤하다.\n",
    "3. 간만에 여자친구랑 데이트 하기로 했어.\n",
    "4. 집에 있는다는 소리야.\n",
    "\n",
    "---\n",
    "\n",
    "# 제출\n",
    "\n",
    "Translations\n",
    "> 1. 잠깐 쉬 어도 돼요 . <end>\n",
    "> 2. 맛난 거 드세요 . <end>\n",
    "> 3. 떨리 겠 죠 . <end>\n",
    "> 4. 좋 아 하 면 그럴 수 있 어요 . <end>\n",
    "\n",
    "Hyperparameters\n",
    "> n_layers: 1\n",
    "> d_model: 368\n",
    "> n_heads: 8\n",
    "> d_ff: 1024\n",
    "> dropout: 0.2\n",
    "\n",
    "Training Parameters\n",
    "> Warmup Steps: 1000\n",
    "> Batch Size: 64\n",
    "> Epoch At: 10\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "830ab11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(text_tokens, model, tokenizer):\n",
    "    print(f\"- {text_tokens}\")\n",
    "    seq_tokens = tokenizer.texts_to_sequences(text_tokens)\n",
    "    padded_tokens = pad_sequences(seq_tokens, padding=\"post\")\n",
    "    \n",
    "    ids = []\n",
    "    output = tf.expand_dims([tokenizer.word_index['<start>']], 0)   \n",
    "    for i in range(vocab_size):\n",
    "        enc_padding_mask, combined_mask, dec_padding_mask = generate_masks(padded_tokens, output)\n",
    "\n",
    "        try:\n",
    "            predictions, _, _, _ = model(padded_tokens,\n",
    "                                         output,\n",
    "                                         enc_padding_mask,\n",
    "                                         combined_mask,\n",
    "                                         dec_padding_mask)\n",
    "\n",
    "            predicted_id = tf.argmax(\n",
    "                tf.math.softmax(predictions, axis=-1)[0, -1]).numpy().item()\n",
    "\n",
    "            if tokenizer.word_index['<end>'] == predicted_id:\n",
    "                result = ' '.join(tokenizer.sequences_to_texts([ids]))\n",
    "                return result\n",
    "\n",
    "            ids.append(predicted_id)\n",
    "            output = tf.concat([output, tf.expand_dims([predicted_id], 0)], axis=-1)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(\"Caught an exception:\", e)\n",
    "            break\n",
    "\n",
    "    result = ' '.join(tokenizer.sequences_to_texts([ids]))\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "e78016aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_bleu_single(model, src_sentence, tgt_sentence, tokenizer, verbose=True):\n",
    "    \n",
    "#     print(f\"src: {src_sentence}\")\n",
    "#     print(f\"tgt: {tgt_sentence}\")\n",
    "\n",
    "    reference = tgt_sentence\n",
    "    candidate = translate(src_sentence, model, tokenizer).split()\n",
    "\n",
    "    score = sentence_bleu([reference], candidate,\n",
    "                          smoothing_function=SmoothingFunction().method1)\n",
    "\n",
    "    if verbose:\n",
    "        # print(\"Source Sentence: \", src_sentence)\n",
    "        print(\"Model Prediction: \", \" \".join(candidate))\n",
    "        print(\"Real: \", \" \".join(reference))\n",
    "        print(\"Score: %lf\\n\" % score)\n",
    "        \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "76273e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_bleu(model, src_sentences, tgt_sentences, tokenizer, verbose=True):\n",
    "    total_score = 0.0\n",
    "    sample_size = len(src_sentences)\n",
    "    \n",
    "    for idx in tqdm(range(sample_size)):\n",
    "        src = \" \".join(src_sentences[idx])\n",
    "        tgt = tgt_sentences[idx]\n",
    "        score = eval_bleu_single(model, src, tgt, tokenizer, verbose)\n",
    "        if not score: continue\n",
    "        \n",
    "        total_score += score\n",
    "    \n",
    "    print(\"Num of Sample:\", sample_size)\n",
    "    print(\"Total Score:\", total_score / sample_size)\n",
    "    \n",
    "    return total_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ebb52786",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_questions = [\"지루하다, 놀러가고 싶어.\",\n",
    "                  \"오늘 일찍 일어났더니 피곤하다.\",\n",
    "                  \"간만에 여자친구랑 데이트 하기로 했어.\",\n",
    "                  \"집에 있는다는 소리야.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "433535bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['지루', '하', '다', '놀', '러', '가', '고', '싶', '어'],\n",
       " ['오늘', '일찍', '일어났', '더니', '피곤', '하', '다'],\n",
       " ['간만에', '여자', '친구', '랑', '데이트', '하', '기', '로', '했', '어'],\n",
       " ['집', '에', '있', '는다는', '소리야']]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_questions = cleaner.clean_corpus(test_questions)\n",
    "test_questions = get_tokenized_corpus(test_questions, mecab)\n",
    "test_questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c1849cfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[36721, 29576, 41665, 34028, 29759, 29952, 4288, 8121, 21349, 42258]\n"
     ]
    }
   ],
   "source": [
    "random_indices = random.sample(range(0, df_corpus.shape[0] + 1), 10)\n",
    "print(random_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "75b710ca",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 헤어지 고 난 뒤 애인\n",
      "Source Sentence:  헤어지 고 난 뒤 애인\n",
      "Model Prediction:  ['만나', '길', '바라', '요']\n",
      "Real:  ['<start>', '친구', '가', '되', '기', '쉽', '지', '않', '을', '거', '예요', '<end>']\n",
      "Score: 0.000000\n",
      "\n",
      "- 소개팅 하 고 애프터 까지 왔 지만 설렘 이 있 어\n",
      "Source Sentence:  소개팅 하 고 애프터 까지 왔 지만 설렘 이 있 어\n",
      "Model Prediction:  ['썸', '은', '사이', '가', '는', '사이', '가', '좋', '은', '일', '이', '에요']\n",
      "Real:  ['<start>', '조금', '더', '만나', '보', '고', '결정', '하', '는', '건', '어떨까', '요', '<end>']\n",
      "Score: 0.015671\n",
      "\n",
      "- 은 남자 맘 이 뭔지\n",
      "Source Sentence:  은 남자 맘 이 뭔지\n",
      "Model Prediction:  ['운명', '입니다']\n",
      "Real:  ['<start>', '사람', '맘', '은', '알', '길', '이', '없', '어요', '<end>']\n",
      "Score: 0.000000\n",
      "\n",
      "- 나가 이 멍청 한 거 지\n",
      "Source Sentence:  나가 이 멍청 한 거 지\n",
      "Model Prediction:  ['운명', '은', '사람', '은', '모두', '사람', '은', '모두', '모두', '모두', '모두', '말', '은', '거', '예요']\n",
      "Real:  ['<start>', '실수', '했', '나요', '<end>']\n",
      "Score: 0.000000\n",
      "\n",
      "- 년 동거 후 이별 개월 차\n",
      "Source Sentence:  년 동거 후 이별 개월 차\n",
      "Model Prediction:  ['많', '은', '시기', '네요']\n",
      "Real:  ['<start>', '생각', '을', '오래', '하', '면', '더욱', '지칠', '수', '있', '어요', '<end>']\n",
      "Score: 0.000000\n",
      "\n",
      "- 나 자체 을 사랑 해 줄 사람 이 있 습니까\n",
      "Source Sentence:  나 자체 을 사랑 해 줄 사람 이 있 습니까\n",
      "Model Prediction:  ['운명', '은', '사람', '은', '모두', '사람', '은', '모두', '모두', '모두', '모두', '말', '은', '거', '예요']\n",
      "Real:  ['<start>', '잘', '찾아보', '세요', '<end>']\n",
      "Score: 0.000000\n",
      "\n",
      "- 대체 불가 한 사람 이 되 고 싶 어\n",
      "Source Sentence:  대체 불가 한 사람 이 되 고 싶 어\n",
      "Model Prediction:  ['궁금', '하', '네요']\n",
      "Real:  ['<start>', '지금', '도', '그래요', '<end>']\n",
      "Score: 0.000000\n",
      "\n",
      "- 삶 살만 해서\n",
      "Source Sentence:  삶 살만 해서\n",
      "Model Prediction:  ['당신', '이', '답', '을', '수', '있', '어요']\n",
      "Real:  ['<start>', '누구', '나', '한', '번', '쯤', '시도', '해', '볼', '만', '하', '죠', '<end>']\n",
      "Score: 0.000000\n",
      "\n",
      "- 여자 친구 이 너무 챙 김 받 고 싶 어 해서\n",
      "Source Sentence:  여자 친구 이 너무 챙 김 받 고 싶 어 해서\n",
      "Model Prediction:  ['이성', '으로', '어필', '을', '어필', '해', '보', '세요']\n",
      "Real:  ['<start>', '사랑', '을', '더', '받', '고', '싶', '은', '가', '봐요', '<end>']\n",
      "Score: 0.019090\n",
      "\n",
      "- 양배추 찹쌀 최악\n",
      "Source Sentence:  양배추 찹쌀 최악\n",
      "Model Prediction:  ['제일', '방법', '이', '에요']\n",
      "Real:  ['<start>', '먹', '으면서', '다이어트', '하', '는', '분', '들', '진짜', '엄청', '대단', '한', '분', '들', '이', '에요', '<end>']\n",
      "Score: 0.006588\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for index in random_indices:\n",
    "    score = eval_bleu_single(transformer, \n",
    "                             \" \".join(df_corpus[\"questions\"].iloc[index]), \n",
    "                             df_corpus[\"target_tokens\"].iloc[index], \n",
    "                             tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "3fca2c80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19887, 25117, 4751, 11536, 32518, 12289, 16228, 30753, 3071, 19636, 15279, 17286, 23372, 31889, 16128, 16251, 21496, 4810, 10209, 19640, 30521, 30755, 28950, 5745, 16428, 33118, 19186, 22832, 25003, 23917, 29354, 12166, 18510, 21926, 21459, 25451, 32723, 13335, 33961, 31754, 14060, 11450, 31338, 5407, 26082, 19355, 33939, 4867, 18802, 15227, 1054, 28991, 8533, 18598, 30611, 20774, 31750, 16288, 31268, 25220, 23542, 10263, 26795, 10794, 20061, 14970, 24938, 11862, 21991, 13521, 31883, 11387, 13652, 7556, 13665, 6502, 6366, 27152, 18332, 31448, 8207, 14931, 7575, 11242, 416, 23118, 21411, 7583, 1578, 21383, 2508, 9024, 11699, 24074, 15056, 25251, 12799, 8536, 540, 11955]\n"
     ]
    }
   ],
   "source": [
    "indices_bleu = random.sample(range(0, df_corpus.shape[0] + 1), 100)\n",
    "print(indices_bleu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "b336df33",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_sentences = list(df_corpus[\"questions\"].iloc[indices_bleu])\n",
    "tgt_sentences = list(df_corpus[\"answers\"].iloc[indices_bleu])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "6496a57c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['아', '벌', '받', '고', '있', '는', '건가', '네'], ['달', '게', '받', '으세요'])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_sentences[0], tgt_sentences[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea676f5",
   "metadata": {},
   "source": [
    "### t0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dea8f5d",
   "metadata": {},
   "source": [
    "- n_layers: 2\n",
    "- d_model: 512\n",
    "- n_heads: 8\n",
    "- d_ff: 2048\n",
    "- dropout: 0.3\n",
    "- batch_size: 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "fdeee9e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 지루 하 다 놀 러 가 고 싶 어\n",
      "> 고백 하 게 고백 하 세요\n",
      "\n",
      "- 오늘 일찍 일어났 더니 피곤 하 다\n",
      "> 썸 이 에요\n",
      "\n",
      "- 간만에 여자 친구 랑 데이트 하 기 로 했 어\n",
      "> 다시 시작 이 되 겠 어요\n",
      "\n",
      "- 집 에 있 는다는 소리야\n",
      "> 축하 드려요\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for question in test_questions:\n",
    "    result = translate(\" \".join(question), transformer, tokenizer)\n",
    "    print(f\"> {result}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "9c3f5811",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 오후 돌이\n",
      "Source Sentence:  오후 돌이\n",
      "Model Prediction:  ['썸', '이', '에요']\n",
      "Real:  ['하루', '가', '또', '가', '네요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 오후 순이\n",
      "Source Sentence:  오후 순이\n",
      "Model Prediction:  ['썸', '이', '에요']\n",
      "Real:  ['하루', '가', '또', '가', '네요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 오전 돌이\n",
      "Source Sentence:  오전 돌이\n",
      "Model Prediction:  ['썸', '이', '에요']\n",
      "Real:  ['하루', '가', '또', '가', '네요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 캐스터 여학교 떨어졌 어서\n",
      "Source Sentence:  캐스터 여학교 떨어졌 어서\n",
      "Model Prediction:  ['사랑', '은', '언제', '든', '시작', '이', '었', '으니까요']\n",
      "Real:  ['위로', '해', '드립니다']\n",
      "Score: 0.000000\n",
      "\n",
      "- 캐스터 여학교 떨어졌 어\n",
      "Source Sentence:  캐스터 여학교 떨어졌 어\n",
      "Model Prediction:  ['사랑', '은', '언제', '든', '시작', '이', '었', '으니까요']\n",
      "Real:  ['위로', '해', '드립니다']\n",
      "Score: 0.000000\n",
      "\n",
      "- 캐스터 소학교 떨어졌 어서\n",
      "Source Sentence:  캐스터 소학교 떨어졌 어서\n",
      "Model Prediction:  ['사랑', '은', '언제', '든', '시작', '이', '었', '으니까요']\n",
      "Real:  ['위로', '해', '드립니다']\n",
      "Score: 0.000000\n",
      "\n",
      "- 캐스터 여학교 올라갔 어서\n",
      "Source Sentence:  캐스터 여학교 올라갔 어서\n",
      "Model Prediction:  ['사랑', '은', '언제', '든', '시작', '이', '었', '으니까요']\n",
      "Real:  ['위로', '해', '드립니다']\n",
      "Score: 0.000000\n",
      "\n",
      "- 윤 월 놀 러 이 는데 싶 는데\n",
      "Source Sentence:  윤 월 놀 러 이 는데 싶 는데\n",
      "Model Prediction:  ['호감', '을', '표현', '하', '고', '있', '어요']\n",
      "Real:  ['여행', '은', '언제나', '좋', '죠']\n",
      "Score: 0.000000\n",
      "\n",
      "- 윤 월 놀 니 이 는데 싶 는데\n",
      "Source Sentence:  윤 월 놀 니 이 는데 싶 는데\n",
      "Model Prediction:  ['호감', '을', '표현', '하', '고', '있', '어요']\n",
      "Real:  ['여행', '은', '언제나', '좋', '죠']\n",
      "Score: 0.000000\n",
      "\n",
      "- 윤 월 놀 러 이 는데 싫 는데\n",
      "Source Sentence:  윤 월 놀 러 이 는데 싫 는데\n",
      "Model Prediction:  ['호감', '을', '표현', '하', '고', '있', '어요']\n",
      "Real:  ['여행', '은', '언제나', '좋', '죠']\n",
      "Score: 0.000000\n",
      "\n",
      "- 윤 월 놀 러 은 는데 싶 는데\n",
      "Source Sentence:  윤 월 놀 러 은 는데 싶 는데\n",
      "Model Prediction:  ['호감', '을', '표현', '하', '고', '있', '어요']\n",
      "Real:  ['여행', '은', '언제나', '좋', '죠']\n",
      "Score: 0.000000\n",
      "\n",
      "- 김 월 만큼 놀 거든 이 지만 싶 지만\n",
      "Source Sentence:  김 월 만큼 놀 거든 이 지만 싶 지만\n",
      "Model Prediction:  ['바라', '요']\n",
      "Real:  ['여행', '은', '언제나', '좋', '죠']\n",
      "Score: 0.000000\n",
      "\n",
      "- 김 월 만큼 놀 거든 은 지만 싶 지만\n",
      "Source Sentence:  김 월 만큼 놀 거든 은 지만 싶 지만\n",
      "Model Prediction:  ['바라', '요']\n",
      "Real:  ['여행', '은', '언제나', '좋', '죠']\n",
      "Score: 0.000000\n",
      "\n",
      "- 김 월 만큼 울 거든 이 지만 싶 지만\n",
      "Source Sentence:  김 월 만큼 울 거든 이 지만 싶 지만\n",
      "Model Prediction:  ['바라', '요']\n",
      "Real:  ['여행', '은', '언제나', '좋', '죠']\n",
      "Score: 0.000000\n",
      "\n",
      "- 윤 월 만큼 놀 거든 이 지만 싶 지만\n",
      "Source Sentence:  윤 월 만큼 놀 거든 이 지만 싶 지만\n",
      "Model Prediction:  ['호감', '을', '표현', '하', '고', '있', '어요']\n",
      "Real:  ['여행', '은', '언제나', '좋', '죠']\n",
      "Score: 0.000000\n",
      "\n",
      "- ppl 약하 다섯\n",
      "Source Sentence:  ppl 약하 다섯\n",
      "Model Prediction:  ['만나', '길', '바라', '요']\n",
      "Real:  ['눈살', '이', '찌푸려', '지', '죠']\n",
      "Score: 0.000000\n",
      "\n",
      "- ppl 강하 다섯\n",
      "Source Sentence:  ppl 강하 다섯\n",
      "Model Prediction:  ['만나', '길', '바라', '요']\n",
      "Real:  ['눈살', '이', '찌푸려', '지', '죠']\n",
      "Score: 0.000000\n",
      "\n",
      "- ppl 약하 여섯\n",
      "Source Sentence:  ppl 약하 여섯\n",
      "Model Prediction:  ['만나', '길', '바라', '요']\n",
      "Real:  ['눈살', '이', '찌푸려', '지', '죠']\n",
      "Score: 0.000000\n",
      "\n",
      "- cp 단말 아름다웠 어\n",
      "Source Sentence:  cp 단말 아름다웠 어\n",
      "Model Prediction:  ['슬픈', '이야기', '네요']\n",
      "Real:  ['다시', '새로', '사', '는', '게', '마음', '편해요']\n",
      "Score: 0.000000\n",
      "\n",
      "- perl 단말 아름다웠 어\n",
      "Source Sentence:  perl 단말 아름다웠 어\n",
      "Model Prediction:  ['만나', '길', '바라', '요']\n",
      "Real:  ['다시', '새로', '사', '는', '게', '마음', '편해요']\n",
      "Score: 0.000000\n",
      "\n",
      "- cp 단말 기뻐했 어\n",
      "Source Sentence:  cp 단말 기뻐했 어\n",
      "Model Prediction:  ['슬픈', '이야기', '네요']\n",
      "Real:  ['다시', '새로', '사', '는', '게', '마음', '편해요']\n",
      "Score: 0.000000\n",
      "\n",
      "- cp 모뎀 아름다웠 어\n",
      "Source Sentence:  cp 모뎀 아름다웠 어\n",
      "Model Prediction:  ['슬픈', '이야기', '네요']\n",
      "Real:  ['다시', '새로', '사', '는', '게', '마음', '편해요']\n",
      "Score: 0.000000\n",
      "\n",
      "- perl 모뎀 앞 됐으며\n",
      "Source Sentence:  perl 모뎀 앞 됐으며\n",
      "Model Prediction:  ['만나', '길', '바라', '요']\n",
      "Real:  ['다시', '새로', '사', '는', '게', '마음', '편해요']\n",
      "Score: 0.000000\n",
      "\n",
      "- perl 모뎀 앞 됐으나\n",
      "Source Sentence:  perl 모뎀 앞 됐으나\n",
      "Model Prediction:  ['만나', '길', '바라', '요']\n",
      "Real:  ['다시', '새로', '사', '는', '게', '마음', '편해요']\n",
      "Score: 0.000000\n",
      "\n",
      "- perl 모뎀 옆 됐으며\n",
      "Source Sentence:  perl 모뎀 옆 됐으며\n",
      "Model Prediction:  ['만나', '길', '바라', '요']\n",
      "Real:  ['다시', '새로', '사', '는', '게', '마음', '편해요']\n",
      "Score: 0.000000\n",
      "\n",
      "- cp 모뎀 앞 됐으며\n",
      "Source Sentence:  cp 모뎀 앞 됐으며\n",
      "Model Prediction:  ['슬픈', '이야기', '네요']\n",
      "Real:  ['다시', '새로', '사', '는', '게', '마음', '편해요']\n",
      "Score: 0.000000\n",
      "\n",
      "- casework 주저앉 팔 정말로 옆 하 당치\n",
      "Source Sentence:  casework 주저앉 팔 정말로 옆 하 당치\n",
      "Model Prediction:  ['슬픈', '이야기', '네요']\n",
      "Real:  ['잘', '모르', '고', '있', '을', '수', '도', '있', '어요']\n",
      "Score: 0.000000\n",
      "\n",
      "- casework 주저앉 빨 정말로 옆 하 당치\n",
      "Source Sentence:  casework 주저앉 빨 정말로 옆 하 당치\n",
      "Model Prediction:  ['슬픈', '이야기', '네요']\n",
      "Real:  ['잘', '모르', '고', '있', '을', '수', '도', '있', '어요']\n",
      "Score: 0.000000\n",
      "\n",
      "- casework 주저앉 팔 정말로 옆 시키 당치\n",
      "Source Sentence:  casework 주저앉 팔 정말로 옆 시키 당치\n",
      "Model Prediction:  ['슬픈', '이야기', '네요']\n",
      "Real:  ['잘', '모르', '고', '있', '을', '수', '도', '있', '어요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 케이스워크 주저앉 팔 정말로 옆 하 당치\n",
      "Source Sentence:  케이스워크 주저앉 팔 정말로 옆 하 당치\n",
      "Model Prediction:  ['다음', '부터', '는', '만큼', '더', '좋', '은', '선택', '이', '었', '길', '바라', '요']\n",
      "Real:  ['잘', '모르', '고', '있', '을', '수', '도', '있', '어요']\n",
      "Score: 0.000000\n",
      "\n",
      "- sns 분 절약 , 거 아 는데 아침 꾀하 은 중\n",
      "Source Sentence:  sns 분 절약 , 거 아 는데 아침 꾀하 은 중\n",
      "Model Prediction:  ['만나', '길', '바라', '요']\n",
      "Real:  ['시간', '을', '정하', '고', '해', '보', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- sns 분 절약 , 거 아 지만 아침 꾀하 은 중\n",
      "Source Sentence:  sns 분 절약 , 거 아 지만 아침 꾀하 은 중\n",
      "Model Prediction:  ['만나', '길', '바라', '요']\n",
      "Real:  ['시간', '을', '정하', '고', '해', '보', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- sns 초간 절약 , 거 아 는데 아침 꾀하 은 중\n",
      "Source Sentence:  sns 초간 절약 , 거 아 는데 아침 꾀하 은 중\n",
      "Model Prediction:  ['만나', '길', '바라', '요']\n",
      "Real:  ['시간', '을', '정하', '고', '해', '보', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- sns 분 절약 , 거 아 는데 아침 시키 은 중\n",
      "Source Sentence:  sns 분 절약 , 거 아 는데 아침 시키 은 중\n",
      "Model Prediction:  ['만나', '길', '바라', '요']\n",
      "Real:  ['시간', '을', '정하', '고', '해', '보', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 케이스워크 시간 조달 라면 혹시 알아채 게끔 이루어짐\n",
      "Source Sentence:  케이스워크 시간 조달 라면 혹시 알아채 게끔 이루어짐\n",
      "Model Prediction:  ['다음', '부터', '는', '만큼', '더', '좋', '은', '선택', '이', '었', '길', '바라', '요']\n",
      "Real:  ['시간', '을', '정하', '고', '해', '보', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 케이스워크 시간 조달 라면 누가 알아채 게끔 이루어짐\n",
      "Source Sentence:  케이스워크 시간 조달 라면 누가 알아채 게끔 이루어짐\n",
      "Model Prediction:  ['다음', '부터', '는', '만큼', '더', '좋', '은', '선택', '이', '었', '길', '바라', '요']\n",
      "Real:  ['시간', '을', '정하', '고', '해', '보', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 케이스워크 시간 조달 라면 혹시 알아채 게끔 들어옴\n",
      "Source Sentence:  케이스워크 시간 조달 라면 혹시 알아채 게끔 들어옴\n",
      "Model Prediction:  ['다음', '부터', '는', '만큼', '더', '좋', '은', '선택', '이', '었', '길', '바라', '요']\n",
      "Real:  ['시간', '을', '정하', '고', '해', '보', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 케이스워크 분 조달 라면 혹시 알아채 게끔 이루어짐\n",
      "Source Sentence:  케이스워크 분 조달 라면 혹시 알아채 게끔 이루어짐\n",
      "Model Prediction:  ['다음', '부터', '는', '만큼', '더', '좋', '은', '선택', '이', '었', '길', '바라', '요']\n",
      "Real:  ['시간', '을', '정하', '고', '해', '보', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 케이스워크 보 면 나 만 때리 는데 다 행복 해 보여\n",
      "Source Sentence:  케이스워크 보 면 나 만 때리 는데 다 행복 해 보여\n",
      "Model Prediction:  ['다음', '부터', '는', '만큼', '더', '좋', '은', '선택', '이', '었', '길', '바라', '요']\n",
      "Real:  ['자랑', '하', '는', '자리', '니까요']\n",
      "Score: 0.015537\n",
      "\n",
      "- 케이스워크 보 면 나 만 걷어차 는데 다 행복 해 보여\n",
      "Source Sentence:  케이스워크 보 면 나 만 걷어차 는데 다 행복 해 보여\n",
      "Model Prediction:  ['다음', '부터', '는', '만큼', '더', '좋', '은', '선택', '이', '었', '길', '바라', '요']\n",
      "Real:  ['자랑', '하', '는', '자리', '니까요']\n",
      "Score: 0.015537\n",
      "\n",
      "- 케이스워크 보 면 나 만 때리 는데 다 행복 해서 보여\n",
      "Source Sentence:  케이스워크 보 면 나 만 때리 는데 다 행복 해서 보여\n",
      "Model Prediction:  ['다음', '부터', '는', '만큼', '더', '좋', '은', '선택', '이', '었', '길', '바라', '요']\n",
      "Real:  ['자랑', '하', '는', '자리', '니까요']\n",
      "Score: 0.015537\n",
      "\n",
      "- 케이스워크 보 면 나 만 때리 는데 는데 행복 해 보여\n",
      "Source Sentence:  케이스워크 보 면 나 만 때리 는데 는데 행복 해 보여\n",
      "Model Prediction:  ['다음', '부터', '는', '만큼', '더', '좋', '은', '선택', '이', '었', '길', '바라', '요']\n",
      "Real:  ['자랑', '하', '는', '자리', '니까요']\n",
      "Score: 0.015537\n",
      "\n",
      "- 가끔 의아 해\n",
      "Source Sentence:  가끔 의아 해\n",
      "Model Prediction:  ['나', '를', '더', '나', '봐요']\n",
      "Real:  ['그', '사람', '도', '그럴', '거', '예요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 이따금 의아 해\n",
      "Source Sentence:  이따금 의아 해\n",
      "Model Prediction:  ['참', '은', '참', '기', '힘들', '게', '없', '어요']\n",
      "Real:  ['그', '사람', '도', '그럴', '거', '예요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가끔 흡족 해\n",
      "Source Sentence:  가끔 흡족 해\n",
      "Model Prediction:  ['나', '를', '더', '나', '봐요']\n",
      "Real:  ['그', '사람', '도', '그럴', '거', '예요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가끔 의아 해서\n",
      "Source Sentence:  가끔 의아 해서\n",
      "Model Prediction:  ['나', '를', '더', '나', '봐요']\n",
      "Real:  ['그', '사람', '도', '그럴', '거', '예요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가끔 뭐 꾀하 는지 의아 해\n",
      "Source Sentence:  가끔 뭐 꾀하 는지 의아 해\n",
      "Model Prediction:  ['나', '를', '더', '나', '봐요']\n",
      "Real:  ['그', '사람', '도', '그럴', '거', '예요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가끔 어쩌 꾀하 는지 의아 해\n",
      "Source Sentence:  가끔 어쩌 꾀하 는지 의아 해\n",
      "Model Prediction:  ['나', '를', '더', '나', '봐요']\n",
      "Real:  ['그', '사람', '도', '그럴', '거', '예요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가끔 뭐 시키 는지 의아 해\n",
      "Source Sentence:  가끔 뭐 시키 는지 의아 해\n",
      "Model Prediction:  ['나', '를', '더', '나', '봐요']\n",
      "Real:  ['그', '사람', '도', '그럴', '거', '예요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가끔 뭐 꾀하 는가 의아 해\n",
      "Source Sentence:  가끔 뭐 꾀하 는가 의아 해\n",
      "Model Prediction:  ['나', '를', '더', '나', '봐요']\n",
      "Real:  ['그', '사람', '도', '그럴', '거', '예요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가끔 은 혼자 의 게 좋 다\n",
      "Source Sentence:  가끔 은 혼자 의 게 좋 다\n",
      "Model Prediction:  ['나', '를', '더', '나', '봐요']\n",
      "Real:  ['혼자', '를', '즐기', '세요']\n",
      "Score: 0.053728\n",
      "\n",
      "- 가끔 은 혼자 의 도록 좋 다\n",
      "Source Sentence:  가끔 은 혼자 의 도록 좋 다\n",
      "Model Prediction:  ['나', '를', '더', '나', '봐요']\n",
      "Real:  ['혼자', '를', '즐기', '세요']\n",
      "Score: 0.053728\n",
      "\n",
      "- 가끔 은 거기 의 게 좋 다\n",
      "Source Sentence:  가끔 은 거기 의 게 좋 다\n",
      "Model Prediction:  ['나', '를', '더', '나', '봐요']\n",
      "Real:  ['혼자', '를', '즐기', '세요']\n",
      "Score: 0.053728\n",
      "\n",
      "- 가끔 은 혼자 의 게 좋 는데\n",
      "Source Sentence:  가끔 은 혼자 의 게 좋 는데\n",
      "Model Prediction:  ['나', '를', '더', '나', '봐요']\n",
      "Real:  ['혼자', '를', '즐기', '세요']\n",
      "Score: 0.053728\n",
      "\n",
      "- 가난 한 자 의 슬픔\n",
      "Source Sentence:  가난 한 자 의 슬픔\n",
      "Model Prediction:  ['나', '를', '더', '나', '봐요']\n",
      "Real:  ['돈', '은', '다시', '들어올', '거', '예요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가난 한 면서 의 슬픔\n",
      "Source Sentence:  가난 한 면서 의 슬픔\n",
      "Model Prediction:  ['나', '를', '더', '나', '봐요']\n",
      "Real:  ['돈', '은', '다시', '들어올', '거', '예요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 부유 한 자 의 슬픔\n",
      "Source Sentence:  부유 한 자 의 슬픔\n",
      "Model Prediction:  ['추억', '이', '되', '겠', '네요']\n",
      "Real:  ['돈', '은', '다시', '들어올', '거', '예요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가난 한 자 , 슬픔\n",
      "Source Sentence:  가난 한 자 , 슬픔\n",
      "Model Prediction:  ['나', '를', '더', '나', '봐요']\n",
      "Real:  ['돈', '은', '다시', '들어올', '거', '예요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가만 없 어도 땀 난다\n",
      "Source Sentence:  가만 없 어도 땀 난다\n",
      "Model Prediction:  ['나', '를', '더', '나', '봐요']\n",
      "Real:  ['땀', '을', '식혀', '주', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가국 없 어도 땀 난다\n",
      "Source Sentence:  가국 없 어도 땀 난다\n",
      "Model Prediction:  ['나', '를', '더', '나', '봐요']\n",
      "Real:  ['땀', '을', '식혀', '주', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가만 있 어도 땀 난다\n",
      "Source Sentence:  가만 있 어도 땀 난다\n",
      "Model Prediction:  ['나', '를', '더', '나', '봐요']\n",
      "Real:  ['땀', '을', '식혀', '주', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가만 없 어도 땀 생긴다\n",
      "Source Sentence:  가만 없 어도 땀 생긴다\n",
      "Model Prediction:  ['나', '를', '더', '나', '봐요']\n",
      "Real:  ['땀', '을', '식혀', '주', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가상현실 화폐 서요 망함\n",
      "Source Sentence:  가상현실 화폐 서요 망함\n",
      "Model Prediction:  ['나', '를', '더', '나', '봐요']\n",
      "Real:  ['어서', '잊', '고', '새', '출발', '하', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가상현실 화폐 대리국 망함\n",
      "Source Sentence:  가상현실 화폐 대리국 망함\n",
      "Model Prediction:  ['나', '를', '더', '나', '봐요']\n",
      "Real:  ['어서', '잊', '고', '새', '출발', '하', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가상현실 화폐 서요 들려줌\n",
      "Source Sentence:  가상현실 화폐 서요 들려줌\n",
      "Model Prediction:  ['나', '를', '더', '나', '봐요']\n",
      "Real:  ['어서', '잊', '고', '새', '출발', '하', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가상현실 통화 서요 망함\n",
      "Source Sentence:  가상현실 통화 서요 망함\n",
      "Model Prediction:  ['나', '를', '더', '나', '봐요']\n",
      "Real:  ['어서', '잊', '고', '새', '출발', '하', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 냉각재 불 켜 고 갔 어\n",
      "Source Sentence:  냉각재 불 켜 고 갔 어\n",
      "Model Prediction:  ['만나', '길', '바라', '요']\n",
      "Real:  ['빨리', '집', '에', '돌아가', '서', '끄', '고', '나오', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 냉각재 불 켜 고 나갔 어\n",
      "Source Sentence:  냉각재 불 켜 고 나갔 어\n",
      "Model Prediction:  ['만나', '길', '바라', '요']\n",
      "Real:  ['빨리', '집', '에', '돌아가', '서', '끄', '고', '나오', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 냉각재 불 당겨 고 갔 어\n",
      "Source Sentence:  냉각재 불 당겨 고 갔 어\n",
      "Model Prediction:  ['만나', '길', '바라', '요']\n",
      "Real:  ['빨리', '집', '에', '돌아가', '서', '끄', '고', '나오', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 냉각수 불 켜 고 갔 어\n",
      "Source Sentence:  냉각수 불 켜 고 갔 어\n",
      "Model Prediction:  ['만나', '길', '바라', '요']\n",
      "Real:  ['빨리', '집', '에', '돌아가', '서', '끄', '고', '나오', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가스 성 켜 놓 는데 나온 건가 같 아\n",
      "Source Sentence:  가스 성 켜 놓 는데 나온 건가 같 아\n",
      "Model Prediction:  ['나', '를', '더', '나', '봐요']\n",
      "Real:  ['빨리', '집', '에', '돌아가', '서', '끄', '고', '나오', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가스 성 켜 놓 는데 나타난 건가 같 아\n",
      "Source Sentence:  가스 성 켜 놓 는데 나타난 건가 같 아\n",
      "Model Prediction:  ['나', '를', '더', '나', '봐요']\n",
      "Real:  ['빨리', '집', '에', '돌아가', '서', '끄', '고', '나오', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가스 성 당겨 놓 는데 나온 건가 같 아\n",
      "Source Sentence:  가스 성 당겨 놓 는데 나온 건가 같 아\n",
      "Model Prediction:  ['나', '를', '더', '나', '봐요']\n",
      "Real:  ['빨리', '집', '에', '돌아가', '서', '끄', '고', '나오', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가스 성 켜 늘어놓 는데 나온 건가 같 아\n",
      "Source Sentence:  가스 성 켜 늘어놓 는데 나온 건가 같 아\n",
      "Model Prediction:  ['나', '를', '더', '나', '봐요']\n",
      "Real:  ['빨리', '집', '에', '돌아가', '서', '끄', '고', '나오', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 냉각수 비 너무 많이 올라왔 는데\n",
      "Source Sentence:  냉각수 비 너무 많이 올라왔 는데\n",
      "Model Prediction:  ['만나', '길', '바라', '요']\n",
      "Real:  ['다음', '달', '에', '는', '더', '절약', '해봐요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 냉각수 비 너무 많이 나왔 는데\n",
      "Source Sentence:  냉각수 비 너무 많이 나왔 는데\n",
      "Model Prediction:  ['만나', '길', '바라', '요']\n",
      "Real:  ['다음', '달', '에', '는', '더', '절약', '해봐요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 냉각수 비 너무 많이 올라왔 지만\n",
      "Source Sentence:  냉각수 비 너무 많이 올라왔 지만\n",
      "Model Prediction:  ['만나', '길', '바라', '요']\n",
      "Real:  ['다음', '달', '에', '는', '더', '절약', '해봐요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 냉각수 비 너무 잘 올라왔 는데\n",
      "Source Sentence:  냉각수 비 너무 잘 올라왔 는데\n",
      "Model Prediction:  ['만나', '길', '바라', '요']\n",
      "Real:  ['다음', '달', '에', '는', '더', '절약', '해봐요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 냉각수 침습 비싼데 감기 걸렸 겠 어\n",
      "Source Sentence:  냉각수 침습 비싼데 감기 걸렸 겠 어\n",
      "Model Prediction:  ['만나', '길', '바라', '요']\n",
      "Real:  ['따뜻', '하', '게', '사세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 냉각수 비가역 비싼데 감기 걸렸 겠 어\n",
      "Source Sentence:  냉각수 비가역 비싼데 감기 걸렸 겠 어\n",
      "Model Prediction:  ['만나', '길', '바라', '요']\n",
      "Real:  ['따뜻', '하', '게', '사세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 냉각수 침습 비싼데 감기 걸렸 겠 어서\n",
      "Source Sentence:  냉각수 침습 비싼데 감기 걸렸 겠 어서\n",
      "Model Prediction:  ['만나', '길', '바라', '요']\n",
      "Real:  ['따뜻', '하', '게', '사세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 냉각수 침습 비싼데 감기 걸렸 셨 어\n",
      "Source Sentence:  냉각수 침습 비싼데 감기 걸렸 셨 어\n",
      "Model Prediction:  ['만나', '길', '바라', '요']\n",
      "Real:  ['따뜻', '하', '게', '사세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 냉각수 침습 장난 임\n",
      "Source Sentence:  냉각수 침습 장난 임\n",
      "Model Prediction:  ['만나', '길', '바라', '요']\n",
      "Real:  ['다음', '달', '에', '는', '더', '절약', '해봐요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 냉각재 침습 장난 임\n",
      "Source Sentence:  냉각재 침습 장난 임\n",
      "Model Prediction:  ['만나', '길', '바라', '요']\n",
      "Real:  ['다음', '달', '에', '는', '더', '절약', '해봐요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 냉각수 침습 장난 아님\n",
      "Source Sentence:  냉각수 침습 장난 아님\n",
      "Model Prediction:  ['만나', '길', '바라', '요']\n",
      "Real:  ['다음', '달', '에', '는', '더', '절약', '해봐요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 냉각수 침습 농담 임\n",
      "Source Sentence:  냉각수 침습 농담 임\n",
      "Model Prediction:  ['만나', '길', '바라', '요']\n",
      "Real:  ['다음', '달', '에', '는', '더', '절약', '해봐요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가족 여행 은 기 로서 했 어\n",
      "Source Sentence:  가족 여행 은 기 로서 했 어\n",
      "Model Prediction:  ['나', '를', '더', '나', '봐요']\n",
      "Real:  ['온', '가족', '이', '모두', '마음', '에', '드', '는', '곳', '으로', '가보세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가족 항해 은 기 로서 했 어\n",
      "Source Sentence:  가족 항해 은 기 로서 했 어\n",
      "Model Prediction:  ['나', '를', '더', '나', '봐요']\n",
      "Real:  ['온', '가족', '이', '모두', '마음', '에', '드', '는', '곳', '으로', '가보세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가족 여행 은 고자 로서 했 어\n",
      "Source Sentence:  가족 여행 은 고자 로서 했 어\n",
      "Model Prediction:  ['나', '를', '더', '나', '봐요']\n",
      "Real:  ['온', '가족', '이', '모두', '마음', '에', '드', '는', '곳', '으로', '가보세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가족 여행 은 기 로서 했 어서\n",
      "Source Sentence:  가족 여행 은 기 로서 했 어서\n",
      "Model Prediction:  ['나', '를', '더', '나', '봐요']\n",
      "Real:  ['온', '가족', '이', '모두', '마음', '에', '드', '는', '곳', '으로', '가보세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 친지 여행 고고\n",
      "Source Sentence:  친지 여행 고고\n",
      "Model Prediction:  ['썸', '사이', '사이', '에서', '말', '고', '싶', '은', '거', '같', '아요']\n",
      "Real:  ['온', '가족', '이', '모두', '마음', '에', '드', '는', '곳', '으로', '가보세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 친지 항해 고고\n",
      "Source Sentence:  친지 항해 고고\n",
      "Model Prediction:  ['썸', '사이', '사이', '에서', '말', '고', '싶', '은', '거', '같', '아요']\n",
      "Real:  ['온', '가족', '이', '모두', '마음', '에', '드', '는', '곳', '으로', '가보세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 친지 여행 다용\n",
      "Source Sentence:  친지 여행 다용\n",
      "Model Prediction:  ['썸', '사이', '사이', '에서', '말', '고', '싶', '은', '거', '같', '아요']\n",
      "Real:  ['온', '가족', '이', '모두', '마음', '에', '드', '는', '곳', '으로', '가보세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 주변인 여행 고고\n",
      "Source Sentence:  주변인 여행 고고\n",
      "Model Prediction:  ['그', '사람', '을', '생각', '해', '보', '세요']\n",
      "Real:  ['온', '가족', '이', '모두', '마음', '에', '드', '는', '곳', '으로', '가보세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 친지 여행 어디 로서 갖\n",
      "Source Sentence:  친지 여행 어디 로서 갖\n",
      "Model Prediction:  ['썸', '사이', '사이', '에서', '말', '고', '싶', '은', '거', '같', '아요']\n",
      "Real:  ['온', '가족', '이', '모두', '마음', '에', '드', '는', '곳', '으로', '가보세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 친지 여행 언제 로서 갖\n",
      "Source Sentence:  친지 여행 언제 로서 갖\n",
      "Model Prediction:  ['썸', '사이', '사이', '에서', '말', '고', '싶', '은', '거', '같', '아요']\n",
      "Real:  ['온', '가족', '이', '모두', '마음', '에', '드', '는', '곳', '으로', '가보세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 주변인 여행 어디 로서 갖\n",
      "Source Sentence:  주변인 여행 어디 로서 갖\n",
      "Model Prediction:  ['그', '사람', '을', '생각', '해', '보', '세요']\n",
      "Real:  ['온', '가족', '이', '모두', '마음', '에', '드', '는', '곳', '으로', '가보세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 친지 항해 어디 로서 갖\n",
      "Source Sentence:  친지 항해 어디 로서 갖\n",
      "Model Prediction:  ['썸', '사이', '사이', '에서', '말', '고', '싶', '은', '거', '같', '아요']\n",
      "Real:  ['온', '가족', '이', '모두', '마음', '에', '드', '는', '곳', '으로', '가보세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 친지 끼리 여행 간다\n",
      "Source Sentence:  친지 끼리 여행 간다\n",
      "Model Prediction:  ['썸', '사이', '사이', '에서', '말', '고', '싶', '은', '거', '같', '아요']\n",
      "Real:  ['더', '가까워질', '기회', '가', '되', '겠', '네요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 친지 서로 여행 간다\n",
      "Source Sentence:  친지 서로 여행 간다\n",
      "Model Prediction:  ['썸', '사이', '사이', '에서', '말', '고', '싶', '은', '거', '같', '아요']\n",
      "Real:  ['더', '가까워질', '기회', '가', '되', '겠', '네요']\n",
      "Score: 0.000000\n",
      "\n",
      "Num of Sample: 100\n",
      "Total Score: 0.0027706248913574975\n"
     ]
    }
   ],
   "source": [
    "score = eval_bleu(transformer, src_sentences, tgt_sentences, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67faea6e",
   "metadata": {},
   "source": [
    "### t1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73899eea",
   "metadata": {},
   "source": [
    "- n_layers: 2\n",
    "- d_model: 512\n",
    "- n_heads: 8\n",
    "- d_ff: 2048\n",
    "- dropout: 0.3\n",
    "- batch_size: 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "c5730602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 지루 하 다 놀 러 가 고 싶 어\n",
      "> 시기 가 다를 뿐 이 에요\n",
      "\n",
      "- 오늘 일찍 일어났 더니 피곤 하 다\n",
      "> 그 분 이 네요\n",
      "\n",
      "- 간만에 여자 친구 랑 데이트 하 기 로 했 어\n",
      "> 생각나 적 으로 도 적 되 는 게 도 적 는지 이상 할 적 이 에요\n",
      "\n",
      "- 집 에 있 는다는 소리야\n",
      "> 내 집 마련 축하 드려요\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for question in test_questions:\n",
    "    result = translate(\" \".join(question), transformer, tokenizer)\n",
    "    print(f\"> {result}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "647ee7d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f70cb28bc02747aca7835de993635deb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 오후 돌이\n",
      "Source Sentence:  오후 돌이\n",
      "Model Prediction:  ['그', '분', '이', '네요']\n",
      "Real:  ['하루', '가', '또', '가', '네요']\n",
      "Score: 0.062571\n",
      "\n",
      "- 오후 순이\n",
      "Source Sentence:  오후 순이\n",
      "Model Prediction:  ['그', '분', '이', '네요']\n",
      "Real:  ['하루', '가', '또', '가', '네요']\n",
      "Score: 0.062571\n",
      "\n",
      "- 오전 돌이\n",
      "Source Sentence:  오전 돌이\n",
      "Model Prediction:  ['그', '분', '이', '네요']\n",
      "Real:  ['하루', '가', '또', '가', '네요']\n",
      "Score: 0.062571\n",
      "\n",
      "- 캐스터 여학교 떨어졌 어서\n",
      "Source Sentence:  캐스터 여학교 떨어졌 어서\n",
      "Model Prediction:  ['근처', '산', '에', '가보세요']\n",
      "Real:  ['위로', '해', '드립니다']\n",
      "Score: 0.000000\n",
      "\n",
      "- 캐스터 여학교 떨어졌 어\n",
      "Source Sentence:  캐스터 여학교 떨어졌 어\n",
      "Model Prediction:  ['근처', '산', '에', '가보세요']\n",
      "Real:  ['위로', '해', '드립니다']\n",
      "Score: 0.000000\n",
      "\n",
      "- 캐스터 소학교 떨어졌 어서\n",
      "Source Sentence:  캐스터 소학교 떨어졌 어서\n",
      "Model Prediction:  ['근처', '산', '에', '가보세요']\n",
      "Real:  ['위로', '해', '드립니다']\n",
      "Score: 0.000000\n",
      "\n",
      "- 캐스터 여학교 올라갔 어서\n",
      "Source Sentence:  캐스터 여학교 올라갔 어서\n",
      "Model Prediction:  ['근처', '산', '에', '가보세요']\n",
      "Real:  ['위로', '해', '드립니다']\n",
      "Score: 0.000000\n",
      "\n",
      "- 윤 월 놀 러 이 는데 싶 는데\n",
      "Source Sentence:  윤 월 놀 러 이 는데 싶 는데\n",
      "Model Prediction:  ['은', '은', '은', '은', '은', '은', '은', '은', '알', '수', '없', '어요']\n",
      "Real:  ['여행', '은', '언제나', '좋', '죠']\n",
      "Score: 0.017033\n",
      "\n",
      "- 윤 월 놀 니 이 는데 싶 는데\n",
      "Source Sentence:  윤 월 놀 니 이 는데 싶 는데\n",
      "Model Prediction:  ['은', '은', '은', '은', '은', '은', '은', '은', '알', '수', '없', '어요']\n",
      "Real:  ['여행', '은', '언제나', '좋', '죠']\n",
      "Score: 0.017033\n",
      "\n",
      "- 윤 월 놀 러 이 는데 싫 는데\n",
      "Source Sentence:  윤 월 놀 러 이 는데 싫 는데\n",
      "Model Prediction:  ['은', '은', '은', '은', '은', '은', '은', '은', '알', '수', '없', '어요']\n",
      "Real:  ['여행', '은', '언제나', '좋', '죠']\n",
      "Score: 0.017033\n",
      "\n",
      "- 윤 월 놀 러 은 는데 싶 는데\n",
      "Source Sentence:  윤 월 놀 러 은 는데 싶 는데\n",
      "Model Prediction:  ['은', '은', '은', '은', '은', '은', '은', '은', '알', '수', '없', '어요']\n",
      "Real:  ['여행', '은', '언제나', '좋', '죠']\n",
      "Score: 0.017033\n",
      "\n",
      "- 김 월 만큼 놀 거든 이 지만 싶 지만\n",
      "Source Sentence:  김 월 만큼 놀 거든 이 지만 싶 지만\n",
      "Model Prediction:  ['이제', '더', '다면', '신뢰', '을', '가', '있', '을', '거', '예요']\n",
      "Real:  ['여행', '은', '언제나', '좋', '죠']\n",
      "Score: 0.000000\n",
      "\n",
      "- 김 월 만큼 놀 거든 은 지만 싶 지만\n",
      "Source Sentence:  김 월 만큼 놀 거든 은 지만 싶 지만\n",
      "Model Prediction:  ['이제', '더', '다면', '신뢰', '을', '가', '있', '을', '거', '예요']\n",
      "Real:  ['여행', '은', '언제나', '좋', '죠']\n",
      "Score: 0.000000\n",
      "\n",
      "- 김 월 만큼 울 거든 이 지만 싶 지만\n",
      "Source Sentence:  김 월 만큼 울 거든 이 지만 싶 지만\n",
      "Model Prediction:  ['이제', '더', '다면', '신뢰', '을', '가', '있', '을', '거', '예요']\n",
      "Real:  ['여행', '은', '언제나', '좋', '죠']\n",
      "Score: 0.000000\n",
      "\n",
      "- 윤 월 만큼 놀 거든 이 지만 싶 지만\n",
      "Source Sentence:  윤 월 만큼 놀 거든 이 지만 싶 지만\n",
      "Model Prediction:  ['은', '은', '은', '은', '은', '은', '은', '은', '알', '수', '없', '어요']\n",
      "Real:  ['여행', '은', '언제나', '좋', '죠']\n",
      "Score: 0.017033\n",
      "\n",
      "- ppl 약하 다섯\n",
      "Source Sentence:  ppl 약하 다섯\n",
      "Model Prediction:  ['잘', '모르', '겠', '지요']\n",
      "Real:  ['눈살', '이', '찌푸려', '지', '죠']\n",
      "Score: 0.000000\n",
      "\n",
      "- ppl 강하 다섯\n",
      "Source Sentence:  ppl 강하 다섯\n",
      "Model Prediction:  ['잘', '모르', '겠', '지요']\n",
      "Real:  ['눈살', '이', '찌푸려', '지', '죠']\n",
      "Score: 0.000000\n",
      "\n",
      "- ppl 약하 여섯\n",
      "Source Sentence:  ppl 약하 여섯\n",
      "Model Prediction:  ['잘', '모르', '겠', '지요']\n",
      "Real:  ['눈살', '이', '찌푸려', '지', '죠']\n",
      "Score: 0.000000\n",
      "\n",
      "- cp 단말 아름다웠 어\n",
      "Source Sentence:  cp 단말 아름다웠 어\n",
      "Model Prediction:  ['자신', '만', '의', '자신']\n",
      "Real:  ['다시', '새로', '사', '는', '게', '마음', '편해요']\n",
      "Score: 0.000000\n",
      "\n",
      "- perl 단말 아름다웠 어\n",
      "Source Sentence:  perl 단말 아름다웠 어\n",
      "Model Prediction:  ['잘', '모르', '겠', '지요']\n",
      "Real:  ['다시', '새로', '사', '는', '게', '마음', '편해요']\n",
      "Score: 0.000000\n",
      "\n",
      "- cp 단말 기뻐했 어\n",
      "Source Sentence:  cp 단말 기뻐했 어\n",
      "Model Prediction:  ['자신', '만', '의', '자신']\n",
      "Real:  ['다시', '새로', '사', '는', '게', '마음', '편해요']\n",
      "Score: 0.000000\n",
      "\n",
      "- cp 모뎀 아름다웠 어\n",
      "Source Sentence:  cp 모뎀 아름다웠 어\n",
      "Model Prediction:  ['자신', '만', '의', '자신']\n",
      "Real:  ['다시', '새로', '사', '는', '게', '마음', '편해요']\n",
      "Score: 0.000000\n",
      "\n",
      "- perl 모뎀 앞 됐으며\n",
      "Source Sentence:  perl 모뎀 앞 됐으며\n",
      "Model Prediction:  ['잘', '모르', '겠', '지요']\n",
      "Real:  ['다시', '새로', '사', '는', '게', '마음', '편해요']\n",
      "Score: 0.000000\n",
      "\n",
      "- perl 모뎀 앞 됐으나\n",
      "Source Sentence:  perl 모뎀 앞 됐으나\n",
      "Model Prediction:  ['잘', '모르', '겠', '지요']\n",
      "Real:  ['다시', '새로', '사', '는', '게', '마음', '편해요']\n",
      "Score: 0.000000\n",
      "\n",
      "- perl 모뎀 옆 됐으며\n",
      "Source Sentence:  perl 모뎀 옆 됐으며\n",
      "Model Prediction:  ['잘', '모르', '겠', '지요']\n",
      "Real:  ['다시', '새로', '사', '는', '게', '마음', '편해요']\n",
      "Score: 0.000000\n",
      "\n",
      "- cp 모뎀 앞 됐으며\n",
      "Source Sentence:  cp 모뎀 앞 됐으며\n",
      "Model Prediction:  ['자신', '만', '의', '자신']\n",
      "Real:  ['다시', '새로', '사', '는', '게', '마음', '편해요']\n",
      "Score: 0.000000\n",
      "\n",
      "- casework 주저앉 팔 정말로 옆 하 당치\n",
      "Source Sentence:  casework 주저앉 팔 정말로 옆 하 당치\n",
      "Model Prediction:  ['자신', '만', '의', '자신']\n",
      "Real:  ['잘', '모르', '고', '있', '을', '수', '도', '있', '어요']\n",
      "Score: 0.000000\n",
      "\n",
      "- casework 주저앉 빨 정말로 옆 하 당치\n",
      "Source Sentence:  casework 주저앉 빨 정말로 옆 하 당치\n",
      "Model Prediction:  ['자신', '만', '의', '자신']\n",
      "Real:  ['잘', '모르', '고', '있', '을', '수', '도', '있', '어요']\n",
      "Score: 0.000000\n",
      "\n",
      "- casework 주저앉 팔 정말로 옆 시키 당치\n",
      "Source Sentence:  casework 주저앉 팔 정말로 옆 시키 당치\n",
      "Model Prediction:  ['자신', '만', '의', '자신']\n",
      "Real:  ['잘', '모르', '고', '있', '을', '수', '도', '있', '어요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 케이스워크 주저앉 팔 정말로 옆 하 당치\n",
      "Source Sentence:  케이스워크 주저앉 팔 정말로 옆 하 당치\n",
      "Model Prediction:  ['충분히', '충분히', '충분히', '충분히', '충분히', '충분히', '충분히', '아름다워요']\n",
      "Real:  ['잘', '모르', '고', '있', '을', '수', '도', '있', '어요']\n",
      "Score: 0.000000\n",
      "\n",
      "- sns 분 절약 , 거 아 는데 아침 꾀하 은 중\n",
      "Source Sentence:  sns 분 절약 , 거 아 는데 아침 꾀하 은 중\n",
      "Model Prediction:  ['잘', '모르', '겠', '지요']\n",
      "Real:  ['시간', '을', '정하', '고', '해', '보', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- sns 분 절약 , 거 아 지만 아침 꾀하 은 중\n",
      "Source Sentence:  sns 분 절약 , 거 아 지만 아침 꾀하 은 중\n",
      "Model Prediction:  ['잘', '모르', '겠', '지요']\n",
      "Real:  ['시간', '을', '정하', '고', '해', '보', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- sns 초간 절약 , 거 아 는데 아침 꾀하 은 중\n",
      "Source Sentence:  sns 초간 절약 , 거 아 는데 아침 꾀하 은 중\n",
      "Model Prediction:  ['잘', '모르', '겠', '지요']\n",
      "Real:  ['시간', '을', '정하', '고', '해', '보', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- sns 분 절약 , 거 아 는데 아침 시키 은 중\n",
      "Source Sentence:  sns 분 절약 , 거 아 는데 아침 시키 은 중\n",
      "Model Prediction:  ['잘', '모르', '겠', '지요']\n",
      "Real:  ['시간', '을', '정하', '고', '해', '보', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 케이스워크 시간 조달 라면 혹시 알아채 게끔 이루어짐\n",
      "Source Sentence:  케이스워크 시간 조달 라면 혹시 알아채 게끔 이루어짐\n",
      "Model Prediction:  ['충분히', '충분히', '충분히', '충분히', '충분히', '충분히', '충분히', '아름다워요']\n",
      "Real:  ['시간', '을', '정하', '고', '해', '보', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 케이스워크 시간 조달 라면 누가 알아채 게끔 이루어짐\n",
      "Source Sentence:  케이스워크 시간 조달 라면 누가 알아채 게끔 이루어짐\n",
      "Model Prediction:  ['충분히', '충분히', '충분히', '충분히', '충분히', '충분히', '충분히', '아름다워요']\n",
      "Real:  ['시간', '을', '정하', '고', '해', '보', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 케이스워크 시간 조달 라면 혹시 알아채 게끔 들어옴\n",
      "Source Sentence:  케이스워크 시간 조달 라면 혹시 알아채 게끔 들어옴\n",
      "Model Prediction:  ['충분히', '충분히', '충분히', '충분히', '충분히', '충분히', '충분히', '아름다워요']\n",
      "Real:  ['시간', '을', '정하', '고', '해', '보', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 케이스워크 분 조달 라면 혹시 알아채 게끔 이루어짐\n",
      "Source Sentence:  케이스워크 분 조달 라면 혹시 알아채 게끔 이루어짐\n",
      "Model Prediction:  ['충분히', '충분히', '충분히', '충분히', '충분히', '충분히', '충분히', '아름다워요']\n",
      "Real:  ['시간', '을', '정하', '고', '해', '보', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 케이스워크 보 면 나 만 때리 는데 다 행복 해 보여\n",
      "Source Sentence:  케이스워크 보 면 나 만 때리 는데 다 행복 해 보여\n",
      "Model Prediction:  ['충분히', '충분히', '충분히', '충분히', '충분히', '충분히', '충분히', '아름다워요']\n",
      "Real:  ['자랑', '하', '는', '자리', '니까요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 케이스워크 보 면 나 만 걷어차 는데 다 행복 해 보여\n",
      "Source Sentence:  케이스워크 보 면 나 만 걷어차 는데 다 행복 해 보여\n",
      "Model Prediction:  ['충분히', '충분히', '충분히', '충분히', '충분히', '충분히', '충분히', '아름다워요']\n",
      "Real:  ['자랑', '하', '는', '자리', '니까요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 케이스워크 보 면 나 만 때리 는데 다 행복 해서 보여\n",
      "Source Sentence:  케이스워크 보 면 나 만 때리 는데 다 행복 해서 보여\n",
      "Model Prediction:  ['충분히', '충분히', '충분히', '충분히', '충분히', '충분히', '충분히', '아름다워요']\n",
      "Real:  ['자랑', '하', '는', '자리', '니까요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 케이스워크 보 면 나 만 때리 는데 는데 행복 해 보여\n",
      "Source Sentence:  케이스워크 보 면 나 만 때리 는데 는데 행복 해 보여\n",
      "Model Prediction:  ['충분히', '충분히', '충분히', '충분히', '충분히', '충분히', '충분히', '아름다워요']\n",
      "Real:  ['자랑', '하', '는', '자리', '니까요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가끔 의아 해\n",
      "Source Sentence:  가끔 의아 해\n",
      "Model Prediction:  ['저', '요']\n",
      "Real:  ['그', '사람', '도', '그럴', '거', '예요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 이따금 의아 해\n",
      "Source Sentence:  이따금 의아 해\n",
      "Model Prediction:  ['알', '수', '없', '는', '게', '사랑', '이', '에요']\n",
      "Real:  ['그', '사람', '도', '그럴', '거', '예요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가끔 흡족 해\n",
      "Source Sentence:  가끔 흡족 해\n",
      "Model Prediction:  ['저', '요']\n",
      "Real:  ['그', '사람', '도', '그럴', '거', '예요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가끔 의아 해서\n",
      "Source Sentence:  가끔 의아 해서\n",
      "Model Prediction:  ['저', '요']\n",
      "Real:  ['그', '사람', '도', '그럴', '거', '예요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가끔 뭐 꾀하 는지 의아 해\n",
      "Source Sentence:  가끔 뭐 꾀하 는지 의아 해\n",
      "Model Prediction:  ['저', '요']\n",
      "Real:  ['그', '사람', '도', '그럴', '거', '예요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가끔 어쩌 꾀하 는지 의아 해\n",
      "Source Sentence:  가끔 어쩌 꾀하 는지 의아 해\n",
      "Model Prediction:  ['저', '요']\n",
      "Real:  ['그', '사람', '도', '그럴', '거', '예요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가끔 뭐 시키 는지 의아 해\n",
      "Source Sentence:  가끔 뭐 시키 는지 의아 해\n",
      "Model Prediction:  ['저', '요']\n",
      "Real:  ['그', '사람', '도', '그럴', '거', '예요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가끔 뭐 꾀하 는가 의아 해\n",
      "Source Sentence:  가끔 뭐 꾀하 는가 의아 해\n",
      "Model Prediction:  ['저', '요']\n",
      "Real:  ['그', '사람', '도', '그럴', '거', '예요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가끔 은 혼자 의 게 좋 다\n",
      "Source Sentence:  가끔 은 혼자 의 게 좋 다\n",
      "Model Prediction:  ['저', '요']\n",
      "Real:  ['혼자', '를', '즐기', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가끔 은 혼자 의 도록 좋 다\n",
      "Source Sentence:  가끔 은 혼자 의 도록 좋 다\n",
      "Model Prediction:  ['저', '요']\n",
      "Real:  ['혼자', '를', '즐기', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가끔 은 거기 의 게 좋 다\n",
      "Source Sentence:  가끔 은 거기 의 게 좋 다\n",
      "Model Prediction:  ['저', '요']\n",
      "Real:  ['혼자', '를', '즐기', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가끔 은 혼자 의 게 좋 는데\n",
      "Source Sentence:  가끔 은 혼자 의 게 좋 는데\n",
      "Model Prediction:  ['저', '요']\n",
      "Real:  ['혼자', '를', '즐기', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가난 한 자 의 슬픔\n",
      "Source Sentence:  가난 한 자 의 슬픔\n",
      "Model Prediction:  ['저', '요']\n",
      "Real:  ['돈', '은', '다시', '들어올', '거', '예요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가난 한 면서 의 슬픔\n",
      "Source Sentence:  가난 한 면서 의 슬픔\n",
      "Model Prediction:  ['저', '요']\n",
      "Real:  ['돈', '은', '다시', '들어올', '거', '예요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 부유 한 자 의 슬픔\n",
      "Source Sentence:  부유 한 자 의 슬픔\n",
      "Model Prediction:  ['이제', '최선', '의', '선택', '일거', '예요']\n",
      "Real:  ['돈', '은', '다시', '들어올', '거', '예요']\n",
      "Score: 0.040825\n",
      "\n",
      "- 가난 한 자 , 슬픔\n",
      "Source Sentence:  가난 한 자 , 슬픔\n",
      "Model Prediction:  ['저', '요']\n",
      "Real:  ['돈', '은', '다시', '들어올', '거', '예요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가만 없 어도 땀 난다\n",
      "Source Sentence:  가만 없 어도 땀 난다\n",
      "Model Prediction:  ['저', '요']\n",
      "Real:  ['땀', '을', '식혀', '주', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가국 없 어도 땀 난다\n",
      "Source Sentence:  가국 없 어도 땀 난다\n",
      "Model Prediction:  ['저', '요']\n",
      "Real:  ['땀', '을', '식혀', '주', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가만 있 어도 땀 난다\n",
      "Source Sentence:  가만 있 어도 땀 난다\n",
      "Model Prediction:  ['저', '요']\n",
      "Real:  ['땀', '을', '식혀', '주', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가만 없 어도 땀 생긴다\n",
      "Source Sentence:  가만 없 어도 땀 생긴다\n",
      "Model Prediction:  ['저', '요']\n",
      "Real:  ['땀', '을', '식혀', '주', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가상현실 화폐 서요 망함\n",
      "Source Sentence:  가상현실 화폐 서요 망함\n",
      "Model Prediction:  ['저', '요']\n",
      "Real:  ['어서', '잊', '고', '새', '출발', '하', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가상현실 화폐 대리국 망함\n",
      "Source Sentence:  가상현실 화폐 대리국 망함\n",
      "Model Prediction:  ['저', '요']\n",
      "Real:  ['어서', '잊', '고', '새', '출발', '하', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가상현실 화폐 서요 들려줌\n",
      "Source Sentence:  가상현실 화폐 서요 들려줌\n",
      "Model Prediction:  ['저', '요']\n",
      "Real:  ['어서', '잊', '고', '새', '출발', '하', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가상현실 통화 서요 망함\n",
      "Source Sentence:  가상현실 통화 서요 망함\n",
      "Model Prediction:  ['저', '요']\n",
      "Real:  ['어서', '잊', '고', '새', '출발', '하', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 냉각재 불 켜 고 갔 어\n",
      "Source Sentence:  냉각재 불 켜 고 갔 어\n",
      "Model Prediction:  ['잘', '모르', '겠', '지요']\n",
      "Real:  ['빨리', '집', '에', '돌아가', '서', '끄', '고', '나오', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 냉각재 불 켜 고 나갔 어\n",
      "Source Sentence:  냉각재 불 켜 고 나갔 어\n",
      "Model Prediction:  ['잘', '모르', '겠', '지요']\n",
      "Real:  ['빨리', '집', '에', '돌아가', '서', '끄', '고', '나오', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 냉각재 불 당겨 고 갔 어\n",
      "Source Sentence:  냉각재 불 당겨 고 갔 어\n",
      "Model Prediction:  ['잘', '모르', '겠', '지요']\n",
      "Real:  ['빨리', '집', '에', '돌아가', '서', '끄', '고', '나오', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 냉각수 불 켜 고 갔 어\n",
      "Source Sentence:  냉각수 불 켜 고 갔 어\n",
      "Model Prediction:  ['잘', '모르', '겠', '지요']\n",
      "Real:  ['빨리', '집', '에', '돌아가', '서', '끄', '고', '나오', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가스 성 켜 놓 는데 나온 건가 같 아\n",
      "Source Sentence:  가스 성 켜 놓 는데 나온 건가 같 아\n",
      "Model Prediction:  ['저', '요']\n",
      "Real:  ['빨리', '집', '에', '돌아가', '서', '끄', '고', '나오', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가스 성 켜 놓 는데 나타난 건가 같 아\n",
      "Source Sentence:  가스 성 켜 놓 는데 나타난 건가 같 아\n",
      "Model Prediction:  ['저', '요']\n",
      "Real:  ['빨리', '집', '에', '돌아가', '서', '끄', '고', '나오', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가스 성 당겨 놓 는데 나온 건가 같 아\n",
      "Source Sentence:  가스 성 당겨 놓 는데 나온 건가 같 아\n",
      "Model Prediction:  ['저', '요']\n",
      "Real:  ['빨리', '집', '에', '돌아가', '서', '끄', '고', '나오', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가스 성 켜 늘어놓 는데 나온 건가 같 아\n",
      "Source Sentence:  가스 성 켜 늘어놓 는데 나온 건가 같 아\n",
      "Model Prediction:  ['저', '요']\n",
      "Real:  ['빨리', '집', '에', '돌아가', '서', '끄', '고', '나오', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 냉각수 비 너무 많이 올라왔 는데\n",
      "Source Sentence:  냉각수 비 너무 많이 올라왔 는데\n",
      "Model Prediction:  ['잘', '모르', '겠', '지요']\n",
      "Real:  ['다음', '달', '에', '는', '더', '절약', '해봐요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 냉각수 비 너무 많이 나왔 는데\n",
      "Source Sentence:  냉각수 비 너무 많이 나왔 는데\n",
      "Model Prediction:  ['잘', '모르', '겠', '지요']\n",
      "Real:  ['다음', '달', '에', '는', '더', '절약', '해봐요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 냉각수 비 너무 많이 올라왔 지만\n",
      "Source Sentence:  냉각수 비 너무 많이 올라왔 지만\n",
      "Model Prediction:  ['잘', '모르', '겠', '지요']\n",
      "Real:  ['다음', '달', '에', '는', '더', '절약', '해봐요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 냉각수 비 너무 잘 올라왔 는데\n",
      "Source Sentence:  냉각수 비 너무 잘 올라왔 는데\n",
      "Model Prediction:  ['잘', '모르', '겠', '지요']\n",
      "Real:  ['다음', '달', '에', '는', '더', '절약', '해봐요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 냉각수 침습 비싼데 감기 걸렸 겠 어\n",
      "Source Sentence:  냉각수 침습 비싼데 감기 걸렸 겠 어\n",
      "Model Prediction:  ['잘', '모르', '겠', '지요']\n",
      "Real:  ['따뜻', '하', '게', '사세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 냉각수 비가역 비싼데 감기 걸렸 겠 어\n",
      "Source Sentence:  냉각수 비가역 비싼데 감기 걸렸 겠 어\n",
      "Model Prediction:  ['잘', '모르', '겠', '지요']\n",
      "Real:  ['따뜻', '하', '게', '사세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 냉각수 침습 비싼데 감기 걸렸 겠 어서\n",
      "Source Sentence:  냉각수 침습 비싼데 감기 걸렸 겠 어서\n",
      "Model Prediction:  ['잘', '모르', '겠', '지요']\n",
      "Real:  ['따뜻', '하', '게', '사세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 냉각수 침습 비싼데 감기 걸렸 셨 어\n",
      "Source Sentence:  냉각수 침습 비싼데 감기 걸렸 셨 어\n",
      "Model Prediction:  ['잘', '모르', '겠', '지요']\n",
      "Real:  ['따뜻', '하', '게', '사세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 냉각수 침습 장난 임\n",
      "Source Sentence:  냉각수 침습 장난 임\n",
      "Model Prediction:  ['잘', '모르', '겠', '지요']\n",
      "Real:  ['다음', '달', '에', '는', '더', '절약', '해봐요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 냉각재 침습 장난 임\n",
      "Source Sentence:  냉각재 침습 장난 임\n",
      "Model Prediction:  ['잘', '모르', '겠', '지요']\n",
      "Real:  ['다음', '달', '에', '는', '더', '절약', '해봐요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 냉각수 침습 장난 아님\n",
      "Source Sentence:  냉각수 침습 장난 아님\n",
      "Model Prediction:  ['잘', '모르', '겠', '지요']\n",
      "Real:  ['다음', '달', '에', '는', '더', '절약', '해봐요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 냉각수 침습 농담 임\n",
      "Source Sentence:  냉각수 침습 농담 임\n",
      "Model Prediction:  ['잘', '모르', '겠', '지요']\n",
      "Real:  ['다음', '달', '에', '는', '더', '절약', '해봐요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가족 여행 은 기 로서 했 어\n",
      "Source Sentence:  가족 여행 은 기 로서 했 어\n",
      "Model Prediction:  ['저', '요']\n",
      "Real:  ['온', '가족', '이', '모두', '마음', '에', '드', '는', '곳', '으로', '가보세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가족 항해 은 기 로서 했 어\n",
      "Source Sentence:  가족 항해 은 기 로서 했 어\n",
      "Model Prediction:  ['저', '요']\n",
      "Real:  ['온', '가족', '이', '모두', '마음', '에', '드', '는', '곳', '으로', '가보세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가족 여행 은 고자 로서 했 어\n",
      "Source Sentence:  가족 여행 은 고자 로서 했 어\n",
      "Model Prediction:  ['저', '요']\n",
      "Real:  ['온', '가족', '이', '모두', '마음', '에', '드', '는', '곳', '으로', '가보세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가족 여행 은 기 로서 했 어서\n",
      "Source Sentence:  가족 여행 은 기 로서 했 어서\n",
      "Model Prediction:  ['저', '요']\n",
      "Real:  ['온', '가족', '이', '모두', '마음', '에', '드', '는', '곳', '으로', '가보세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 친지 여행 고고\n",
      "Source Sentence:  친지 여행 고고\n",
      "Model Prediction:  ['보', '세요']\n",
      "Real:  ['온', '가족', '이', '모두', '마음', '에', '드', '는', '곳', '으로', '가보세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 친지 항해 고고\n",
      "Source Sentence:  친지 항해 고고\n",
      "Model Prediction:  ['보', '세요']\n",
      "Real:  ['온', '가족', '이', '모두', '마음', '에', '드', '는', '곳', '으로', '가보세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 친지 여행 다용\n",
      "Source Sentence:  친지 여행 다용\n",
      "Model Prediction:  ['보', '세요']\n",
      "Real:  ['온', '가족', '이', '모두', '마음', '에', '드', '는', '곳', '으로', '가보세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 주변인 여행 고고\n",
      "Source Sentence:  주변인 여행 고고\n",
      "Model Prediction:  ['소주', '한', '잔']\n",
      "Real:  ['온', '가족', '이', '모두', '마음', '에', '드', '는', '곳', '으로', '가보세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 친지 여행 어디 로서 갖\n",
      "Source Sentence:  친지 여행 어디 로서 갖\n",
      "Model Prediction:  ['보', '세요']\n",
      "Real:  ['온', '가족', '이', '모두', '마음', '에', '드', '는', '곳', '으로', '가보세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 친지 여행 언제 로서 갖\n",
      "Source Sentence:  친지 여행 언제 로서 갖\n",
      "Model Prediction:  ['보', '세요']\n",
      "Real:  ['온', '가족', '이', '모두', '마음', '에', '드', '는', '곳', '으로', '가보세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 주변인 여행 어디 로서 갖\n",
      "Source Sentence:  주변인 여행 어디 로서 갖\n",
      "Model Prediction:  ['소주', '한', '잔']\n",
      "Real:  ['온', '가족', '이', '모두', '마음', '에', '드', '는', '곳', '으로', '가보세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 친지 항해 어디 로서 갖\n",
      "Source Sentence:  친지 항해 어디 로서 갖\n",
      "Model Prediction:  ['보', '세요']\n",
      "Real:  ['온', '가족', '이', '모두', '마음', '에', '드', '는', '곳', '으로', '가보세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 친지 끼리 여행 간다\n",
      "Source Sentence:  친지 끼리 여행 간다\n",
      "Model Prediction:  ['보', '세요']\n",
      "Real:  ['더', '가까워질', '기회', '가', '되', '겠', '네요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 친지 서로 여행 간다\n",
      "Source Sentence:  친지 서로 여행 간다\n",
      "Model Prediction:  ['보', '세요']\n",
      "Real:  ['더', '가까워질', '기회', '가', '되', '겠', '네요']\n",
      "Score: 0.000000\n",
      "\n",
      "Num of Sample: 100\n",
      "Total Score: 0.0031370396377935735\n"
     ]
    }
   ],
   "source": [
    "score = eval_bleu(transformer, src_sentences, tgt_sentences, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c67ec9",
   "metadata": {},
   "source": [
    "### t2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c559016",
   "metadata": {},
   "source": [
    "- n_layers: 2\n",
    "- d_model: 512\n",
    "- n_heads: 8\n",
    "- d_ff: 2048\n",
    "- dropout: 0.3\n",
    "- batch_size: 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "d4caf4d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 지루 하 다 놀 러 가 고 싶 어\n",
      "> 죠\n",
      "\n",
      "- 오늘 일찍 일어났 더니 피곤 하 다\n",
      "> 따뜻 할 시기 네요\n",
      "\n",
      "- 간만에 여자 친구 랑 데이트 하 기 로 했 어\n",
      "> 헤어짐 은 헤어짐 은 헤어짐 을 좋아하 헤어짐 도 으로 습니다\n",
      "\n",
      "- 집 에 있 는다는 소리야\n",
      "> 조심히 오 세요\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for question in test_questions:\n",
    "    result = translate(\" \".join(question), transformer, tokenizer)\n",
    "    print(f\"> {result}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "0c2930f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 아 벌 받 고 있 는 건가 네\n",
      "Model Prediction:  수십 번 어야 하나 봅니다\n",
      "Real:  달 게 받 으세요\n",
      "Score: 0.000000\n",
      "\n",
      "- 헤어진지 열흘 됐 는데 연락 하 고 싶 다섯\n",
      "Model Prediction:  서로 에게 부담 없 는 선물 이 좋 아요\n",
      "Real:  후회 하 지 않 는다면 연락 해 보 세요\n",
      "Score: 0.000000\n",
      "\n",
      "- 머리카락 이 정말 빠져\n",
      "Model Prediction:  저 도 그러 그러 그러 그러 그러 그러 그러 는 게 좋 겠 어요\n",
      "Real:  스트레스 받 지 마세요\n",
      "Score: 0.000000\n",
      "\n",
      "- 자율 주행 승용차 나오 겠 지\n",
      "Model Prediction:  기다리 고 말 이 기다리 고 말 고 기다리 고 기다리 고 기다리 세요\n",
      "Real:  가까운 미래 에 나올 거 같 아요\n",
      "Score: 0.000000\n",
      "\n",
      "- 죽 고 못 사 는 관계\n",
      "Model Prediction:  나쁜 생각 멈추 나쁜 나쁜 나쁜 생각 멈추 세요\n",
      "Real:  연애 할 때 가능 하 죠\n",
      "Score: 0.000000\n",
      "\n",
      "- 졸업식 에 가 도 된 나\n",
      "Model Prediction:  잠 을 깨 요 기운 내요\n",
      "Real:  졸업식 에 가 서 축하 해 주 세요\n",
      "Score: 0.000000\n",
      "\n",
      "- 공허 하 네\n",
      "Model Prediction:  죠\n",
      "Real:  제 가 채워줄 게요\n",
      "Score: 0.000000\n",
      "\n",
      "- 여지 를 준 짝 녀 버려야 겠죠\n",
      "Model Prediction:  잘 견뎌 내 상대방 이 에요\n",
      "Real:  오해 가 아니 라면 정리 하 는 게 덜 상처 일 것 같 아요\n",
      "Score: 0.000000\n",
      "\n",
      "- 농사 짓 고 다른가\n",
      "Model Prediction:  서로 에게 부담 없 는 선물 이 좋 아요\n",
      "Real:  생각 하 기 는 쉬운데 실천 하 기 는 어려운 것 같 아요\n",
      "Score: 0.018285\n",
      "\n",
      "- 술 을 마시 러 나갈까 어디 론가 떠나 볼까\n",
      "Model Prediction:  연락 이 후 에 연락 하 는 잔 하 기 좋 죠\n",
      "Real:  어디 든 좋 죠\n",
      "Score: 0.036021\n",
      "\n",
      "- 강우 땜 에 눈 아파\n",
      "Model Prediction:  잊 고 새 출발 하 고 사랑 을 생각 해 보 세요\n",
      "Real:  이쁜 마스크 사 드리 고 싶 네요\n",
      "Score: 0.017033\n",
      "\n",
      "- 너무 가슴 이 조르 네\n",
      "Model Prediction:  죠\n",
      "Real:  무슨 마음 인지 알 겠 어서 더 마음 이 아프 네요\n",
      "Score: 0.000000\n",
      "\n",
      "- 정말 예쁘 고 죽 고 싶 어\n",
      "Model Prediction:  사랑 의 일부 로 이유 를 가 쉬운 일 이 었 을 것 같 아요\n",
      "Real:  당신 은 누구 보다 소중 한 사람 이 에요\n",
      "Score: 0.013218\n",
      "\n",
      "- 좋 아 하 는 사람 도 에 공부 를 못 하 겠 어\n",
      "Model Prediction:  마음 의 정리 가 안 좋 겠 어요\n",
      "Real:  충분히 그럴 수 있 어요\n",
      "Score: 0.027776\n",
      "\n",
      "- 결국 약혼 했 어\n",
      "Model Prediction:  서로 에게 부담 없 는 선물 이 좋 아요\n",
      "Real:  마음 이 더 복잡 하 겠 어요\n",
      "Score: 0.023980\n",
      "\n",
      "- 정말로 돌아올까\n",
      "Model Prediction:  사랑 의 일부 로 이유 를 가 쉬운 일 이 었 을 것 같 아요\n",
      "Real:  돌아오 길 바란다면 연락 해 보 세요\n",
      "Score: 0.000000\n",
      "\n",
      "- 이렇게 가짜 끝 인 걸까\n",
      "Model Prediction:  사랑 이 모두 정답 이 될 거 예요\n",
      "Real:  인연 이 거기 까지 인 가 봐요\n",
      "Score: 0.027776\n",
      "\n",
      "- 먹통 이 야 침울 하 다\n",
      "Model Prediction:  드세요\n",
      "Real:  대화 의 눈높이 가 맞 는 사람 만나 세요\n",
      "Score: 0.000000\n",
      "\n",
      "- 요즘 제정신 이 오로지 야\n",
      "Model Prediction:  좋 죠\n",
      "Real:  그럴 때 가 있 죠\n",
      "Score: 0.033366\n",
      "\n",
      "- 술 이 주꾸미 도 아니 고\n",
      "Model Prediction:  연락 이 후 에 연락 하 는 잔 하 기 좋 죠\n",
      "Real:  술 은 끊 는 게 좋 죠\n",
      "Score: 0.039864\n",
      "\n",
      "- 여자 친구 가 말 를 듣 기 좋 게 해\n",
      "Model Prediction:  잘 견뎌 내 상대방 이 에요\n",
      "Real:  말 도 예쁘 게 하 는 사람 이 네요\n",
      "Score: 0.024762\n",
      "\n",
      "- 여지 를 준 짝 녀 봐야 겠죠\n",
      "Model Prediction:  잘 견뎌 내 상대방 이 에요\n",
      "Real:  오해 가 아니 라면 정리 하 는 게 덜 상처 일 것 같 아요\n",
      "Score: 0.000000\n",
      "\n",
      "- 상사병 극복 하 고 싶 어\n",
      "Model Prediction:  축하 합니다\n",
      "Real:  시간 이 해결 해 줄 거 예요\n",
      "Score: 0.000000\n",
      "\n",
      "- 밥 너무 많이 함\n",
      "Model Prediction:  죠\n",
      "Real:  소분 해서 냉동실 에 보관 해 보 세요\n",
      "Score: 0.000000\n",
      "\n",
      "- 그냥 차단 과 하 지\n",
      "Model Prediction:  좋 아 했 봅니다\n",
      "Real:  스스로 에게 하 는 말 인가요\n",
      "Score: 0.000000\n",
      "\n",
      "- 짝 녀 가 어떻게 하 면 내 확신 을 하 게 할까\n",
      "Model Prediction:  나쁜 생각 멈추 세요\n",
      "Real:  우선 꾸준히 연락 하 고 잘 해 줘 보 세요\n",
      "Score: 0.017927\n",
      "\n",
      "- 사람 이 변하 든\n",
      "Model Prediction:  살 면서 들 이 좋 아 하 앞 으로 살 면서 살 아서 더 좋 겠 네요\n",
      "Real:  사랑 은 변하 고 사람 은 안 변해요\n",
      "Score: 0.000000\n",
      "\n",
      "- 충동 감 이 떨어져 있 는 지금\n",
      "Model Prediction:  말 해 보 세요 생각 해 볼게요\n",
      "Real:  저 도 진짜 힘들 었 는데 지금 은 좋 은 사람 만나 행복 해요\n",
      "Score: 0.000000\n",
      "\n",
      "- 헤어진지 달 반 정도 됬 네\n",
      "Model Prediction:  서로 에게 부담 없 는 선물 이 좋 아요\n",
      "Real:  금방 지나갈 거 예요\n",
      "Score: 0.000000\n",
      "\n",
      "- 집착 같 아서\n",
      "Model Prediction:  조심히 오 세요\n",
      "Real:  차분히 생각 해 보 세요 사랑 은 소유 가 아니 에요\n",
      "Score: 0.007895\n",
      "\n",
      "- 썸 타 는 건가 티 내 고 싶 진 않 아\n",
      "Model Prediction:  짧 으면 짧 을 수록 좋 겠 지요\n",
      "Real:  누구 에게 요\n",
      "Score: 0.000000\n",
      "\n",
      "- 제 외국어 뭐 선택 합니까\n",
      "Model Prediction:  서로 사랑 으로 잊 는 거 같 네요\n",
      "Real:  요즘 은 잘 안 배우 는 언어 도 좋 은 거 같 아요\n",
      "Score: 0.034795\n",
      "\n",
      "- 못하 된 사람\n",
      "Model Prediction:  당신\n",
      "Real:  못 된 사람 은 이제 잊 어 버려요\n",
      "Score: 0.000000\n",
      "\n",
      "- 이별 의 시간\n",
      "Model Prediction:  사랑 이 모두 정답 이 될 거 예요\n",
      "Real:  길 지 않 길 바랄 게요\n",
      "Score: 0.000000\n",
      "\n",
      "- 이런 게 동거 니\n",
      "Model Prediction:  사랑 이 모두 정답 이 될 거 예요\n",
      "Real:  알 다가 도 모르 는 게 연애 같 아요\n",
      "Score: 0.000000\n",
      "\n",
      "- 휴 반년 이 라는 시간 잊 었 다 생각 했 지만 또 다시\n",
      "Model Prediction:  아이구\n",
      "Real:  후폭풍 이 무섭 죠\n",
      "Score: 0.000000\n",
      "\n",
      "- 짝 남 에게 밤 에 자주 산책 하 려고 해도 될까\n",
      "Model Prediction:  나쁜 생각 멈추 세요\n",
      "Real:  밤 데이트 신청 멋지 네요\n",
      "Score: 0.000000\n",
      "\n",
      "- 취업 못 시키 는 기간 이 길 어 진다\n",
      "Model Prediction:  긴 시간 이 겠 어요\n",
      "Real:  다음 공채 때 는 될 거 예요\n",
      "Score: 0.000000\n",
      "\n",
      "- 혼자 썸 타 는 기분 은 야\n",
      "Model Prediction:  조금 만 더 견뎌 받 지 세요\n",
      "Real:  직접 적 이 든 간접 적 이 든 의사 를 확실히 밝혀 보 세요\n",
      "Score: 0.012152\n",
      "\n",
      "- 좋 아 하 은 감정 이 나 를 슬프 게 도 해\n",
      "Model Prediction:  마음 의 정리 가 안 좋 겠 어요\n",
      "Real:  사랑 과 슬픔 은 동전 의 양면 과 같 죠\n",
      "Score: 0.021632\n",
      "\n",
      "- 태 핑 할까\n",
      "Model Prediction:  항상 못 해 본 는 일 이 있 는 것 같 아요\n",
      "Real:  구릿빛 피부 좋 죠\n",
      "Score: 0.000000\n",
      "\n",
      "- 자꾸 뭘 사 게 돼\n",
      "Model Prediction:  기다리 고 말 이 기다리 고 말 고 기다리 고 기다리 고 기다리 세요\n",
      "Real:  마음 이 헛헛 한가 봐요\n",
      "Score: 0.014284\n",
      "\n",
      "- 음식 많이 가리 는 남자 를 사 겨 도 괜찮 습니까\n",
      "Model Prediction:  음\n",
      "Real:  다 먹 으면 좋 겠 지만 큰 문제 는 되 지 않 을 거 예요\n",
      "Score: 0.000000\n",
      "\n",
      "- 뭔 비밀 이 그렇게 높 은지\n",
      "Model Prediction:  긴 시간 이 었 을 수 있 을 거 예요\n",
      "Real:  하나 씩 비밀 을 공유 해 보 세요\n",
      "Score: 0.021105\n",
      "\n",
      "- 구 썸남 보 고 싶 어서\n",
      "Model Prediction:  조급 하 게 생각 하 지 마세요\n",
      "Real:  썸 으로 끝날 사이 가 아니 었 네요\n",
      "Score: 0.000000\n",
      "\n",
      "- 상처 받 고자 싫 다\n",
      "Model Prediction:  축하 합니다\n",
      "Real:  무덤덤 해질 수 있 거예요\n",
      "Score: 0.000000\n",
      "\n",
      "- 현실 적 문제 로 연애 포기 해야 할 듯\n",
      "Model Prediction:  힘들 때 가 있 죠\n",
      "Real:  잠시 쉬 어도 괜찮 아요\n",
      "Score: 0.000000\n",
      "\n",
      "- 메모리 카드 어디 는데 두 었 을까\n",
      "Model Prediction:  한 번 만 더 궁금 한 번 만 더 해요\n",
      "Real:  발 이 달렸 나 봐요\n",
      "Score: 0.000000\n",
      "\n",
      "- 밤 이상 되 면\n",
      "Model Prediction:  내일 은 나 은 하루 이 가 또 데이트 가 나 봐요\n",
      "Real:  생각날 거 예요\n",
      "Score: 0.000000\n",
      "\n",
      "- 화장 이 안 받 다섯\n",
      "Model Prediction:  것 을 아니 라고 하 면서 상처 받 을 것 같 습니다\n",
      "Real:  각질 제거 먼저 하 세요\n",
      "Score: 0.017033\n",
      "\n",
      "- 기력 은 없 어\n",
      "Model Prediction:  잘 견뎌 내 고 있 는 게 아니 었 나 봐요\n",
      "Real:  자신 의 감정 을 주변 사람 들 에게 터놓 고 이야기 해 보 세요\n",
      "Score: 0.014351\n",
      "\n",
      "- 서로 싫어하 는 줄 알 았 는데 짝사랑 이 었 네요\n",
      "Model Prediction:  지금 연락 해 보 세요\n",
      "Real:  안타깝 게 생각 해요\n",
      "Score: 0.000000\n",
      "\n",
      "- 아침 안 잡아먹 는데 자꾸 먹 으라고 그래\n",
      "Model Prediction:  수십 번 어야 하나 봅니다\n",
      "Real:  챙겨 주 고 싶 나 봐요\n",
      "Score: 0.000000\n",
      "\n",
      "- 문자 왔 다는 데 읽 다가 점액 터졌 어\n",
      "Model Prediction:  소원 을 비세 요\n",
      "Real:  마음껏 우세요\n",
      "Score: 0.000000\n",
      "\n",
      "- 여자 친구 가 잠 이 너무 많 아\n",
      "Model Prediction:  잘 견뎌 내 상대방 이 에요\n",
      "Real:  미인 은 잠꾸러기 라던데요\n",
      "Score: 0.000000\n",
      "\n",
      "- 오늘 연락 왔었 어\n",
      "Model Prediction:  따뜻 할 시기 네요\n",
      "Real:  기다리 던 연락 이 었 길 바랍니다\n",
      "Score: 0.000000\n",
      "\n",
      "- 좋 아 하 는 감정 를 혼자 서 정리 할 수 있 을까요\n",
      "Model Prediction:  마음 의 정리 가 안 좋 겠 어요\n",
      "Real:  본인 이 하 기 나름 일 거 예요\n",
      "Score: 0.000000\n",
      "\n",
      "- 괜찮 았었 지만\n",
      "Model Prediction:  서로 에게 부담 없 는 선물 이 좋 아요\n",
      "Real:  울 어도 괜찮 아요\n",
      "Score: 0.023980\n",
      "\n",
      "- 우린 운명 이 었 어\n",
      "Model Prediction:  어떨까 요\n",
      "Real:  운명 이 아니 였 다면 사랑 도 할 수 없 었 겠 지요\n",
      "Score: 0.000000\n",
      "\n",
      "- 헤어짐 이 인생 이 었 으면 좋 겠 어\n",
      "Model Prediction:  서로 에게 부담 없 는 선물 이 좋 아요\n",
      "Real:  현실 을 직시 할 필요 도 있 어요\n",
      "Score: 0.000000\n",
      "\n",
      "- 제 가 집착 하 는 중 은 에요\n",
      "Model Prediction:  서로 사랑 으로 잊 는 거 같 네요\n",
      "Real:  사랑 은 소유 하 는 것 이 아니 랍니다\n",
      "Score: 0.029150\n",
      "\n",
      "- 우리 계속 엇갈림\n",
      "Model Prediction:  어떨까 요\n",
      "Real:  타이밍 이 안 맞 았 나 봐요\n",
      "Score: 0.000000\n",
      "\n",
      "- 남자 들 은 좋 아 하 면 무조건 답장 이 빠른 가요\n",
      "Model Prediction:  잘 견뎌 내 었 나 봐요\n",
      "Real:  답 할 수 있 는 상황 이 면 빠르 죠\n",
      "Score: 0.000000\n",
      "\n",
      "- 이렇게 못 알 아 듣 니\n",
      "Model Prediction:  사랑 이 모두 정답 이 될 거 예요\n",
      "Real:  노력 하 겠 습니다\n",
      "Score: 0.000000\n",
      "\n",
      "- 아프 니까 너무 생각나 고 힘드 네\n",
      "Model Prediction:  수십 번 어야 하나 봅니다\n",
      "Real:  아플 땐 더 약해 지나 봐요\n",
      "Score: 0.000000\n",
      "\n",
      "- 헤어진 여자 친구 가 준 편지 못 버리 겠 어\n",
      "Model Prediction:  서로 에게 부담 없 는 선물 이 좋 아요\n",
      "Real:  마음 에 버리 세요\n",
      "Score: 0.000000\n",
      "\n",
      "- 헤어진 지 주 가 흘렀 네\n",
      "Model Prediction:  서로 에게 부담 없 는 선물 이 좋 아요\n",
      "Real:  어느덧 주 가 흘렀 나 봐요\n",
      "Score: 0.000000\n",
      "\n",
      "- 부드러운 좀 하 지\n",
      "Model Prediction:  습니다 습니다\n",
      "Real:  사람 들 이 중간 을 몰라요\n",
      "Score: 0.000000\n",
      "\n",
      "- 이별 준비 시키 려고\n",
      "Model Prediction:  사랑 이 모두 정답 이 될 거 예요\n",
      "Real:  쉽 지 않 은 결정 이 었 을 텐데 마음 고생 많 았 어요\n",
      "Score: 0.013121\n",
      "\n",
      "- 연인 가 엄청 소심 해\n",
      "Model Prediction:  마음 의 정리 를 하 겠 어요\n",
      "Real:  더 신경 써 주 세요\n",
      "Score: 0.000000\n",
      "\n",
      "- 좋 아 하 는 마음 이 앞 생길 것 같 다고 떠난 여자\n",
      "Model Prediction:  마음 의 정리 가 안 좋 겠 어요\n",
      "Real:  이제 그녀 를 놓아주 세요\n",
      "Score: 0.000000\n",
      "\n",
      "- 자 고 일어나 때문 피곤 해\n",
      "Model Prediction:  기다리 고 말 이 기다리 고 말 고 기다리 고 기다리 고 기다리 세요\n",
      "Real:  요즘 바쁜가 봐요\n",
      "Score: 0.000000\n",
      "\n",
      "- 친구 랑 비교 하 면 내 가 작아져\n",
      "Model Prediction:  잘못 안 좋 은 분 이 만나 세요\n",
      "Real:  당신 은 생각 보다 큰 사람 이 에요\n",
      "Score: 0.033032\n",
      "\n",
      "- 수도 이 얼 었 나 봐\n",
      "Model Prediction:  더 잘 할 수 있 을 거 예요\n",
      "Real:  잘 녹여 보 세요\n",
      "Score: 0.027776\n",
      "\n",
      "- 친구 랑 없 으면 내 가 작아져\n",
      "Model Prediction:  잘못 안 좋 은 분 이 만나 세요\n",
      "Real:  당신 은 생각 보다 큰 사람 이 에요\n",
      "Score: 0.033032\n",
      "\n",
      "- 비오 은 날 뭐 할까\n",
      "Model Prediction:  봅니다\n",
      "Real:  실내 데이트 요\n",
      "Score: 0.000000\n",
      "\n",
      "- 불 그날 뻔 했 어\n",
      "Model Prediction:  그럴 수 있 어요\n",
      "Real:  조심 하 세요\n",
      "Score: 0.000000\n",
      "\n",
      "- 남자 친구 , 틀리 는 맞춤법 이 거슬려\n",
      "Model Prediction:  잘 견뎌 내 었 나 봐요\n",
      "Real:  지적 하 지 말 고 맞 는 걸로 계속 이야기 해 주 세요\n",
      "Score: 0.000000\n",
      "\n",
      "- 매일 매일 눈물 로 보내\n",
      "Model Prediction:  조금 더 라도 더 잘 해 주 세요\n",
      "Real:  울 고 싶 을 때 한껏 울 어 버려요\n",
      "Score: 0.000000\n",
      "\n",
      "- 이 사람 이랑 결혼 이 옳 은 걸까\n",
      "Model Prediction:  사랑 이 모두 정답 이 될 거 예요\n",
      "Real:  결혼 에 는 옳 고 그름 이 없 어요\n",
      "Score: 0.024512\n",
      "\n",
      "- 심심 한데 뭐 시키 면 좋 을까\n",
      "Model Prediction:  모든 날 들 이 있 어요\n",
      "Real:  저 랑 이야기 해요\n",
      "Score: 0.000000\n",
      "\n",
      "- 허전 하 는데\n",
      "Model Prediction:  당신 이 아픈 가요\n",
      "Real:  제 가 채워 드릴게요\n",
      "Score: 0.000000\n",
      "\n",
      "- 수분 크림 바르 고 자 면 나아질 거 니라\n",
      "Model Prediction:  더 잘 할 수 있 을 거 예요\n",
      "Real:  예뻐질 거 예요\n",
      "Score: 0.058739\n",
      "\n",
      "- 월 이 익숙 해 지 지 않 네\n",
      "Model Prediction:  딱 좋 을 때 네요\n",
      "Real:  조금 만 더 힘내 세요\n",
      "Score: 0.000000\n",
      "\n",
      "- 재혼 했 어\n",
      "Model Prediction:  지만 에 대한 지켜보 는 건 취업 에 성공 할 거 예요\n",
      "Real:  좋 겠 어요\n",
      "Score: 0.000000\n",
      "\n",
      "- 전 여자 친구 부친상 다녀왔 어\n",
      "Model Prediction:  잊 고 새 잊 으세요\n",
      "Real:  인간 적 예 를 다 하 셨 네요\n",
      "Score: 0.000000\n",
      "\n",
      "- 어떠 고 있 는 게 잘 하 고 있 는 건지\n",
      "Model Prediction:  조금 더 잘 해 주 는 것 도 좋 을 것 같 아요\n",
      "Real:  충분히 잘 하 고 있 을 거 라 생각 해요\n",
      "Score: 0.018477\n",
      "\n",
      "- 수염 기르 고 싶 다\n",
      "Model Prediction:  더 잘 할 수 있 을 거 예요\n",
      "Real:  지저분 해요\n",
      "Score: 0.000000\n",
      "\n",
      "- 나 잘 살 경우 있 겠 지\n",
      "Model Prediction:  괜찮 아 질 거 예요\n",
      "Real:  지금 보다 더 잘 살 거 예요\n",
      "Score: 0.076163\n",
      "\n",
      "- 이것 또한 받아들이 는 것 이 겠 죠\n",
      "Model Prediction:  사랑 이 모두 정답 이 될 거 예요\n",
      "Real:  받아들여야 할 부분 도 있 을 거 예요\n",
      "Score: 0.058739\n",
      "\n",
      "- 내 가 원 하 는 사람 이 되 기 어려워\n",
      "Model Prediction:  자신 있 다면 만나 세요\n",
      "Real:  다른 사람 들 이 원 하 는 내 가 되 는 건 어려워요\n",
      "Score: 0.000000\n",
      "\n",
      "- 얼 어 죽 는 주\n",
      "Model Prediction:  남 의 눈 을 의식 하 는 사람 은 남 을 거 예요\n",
      "Real:  감기 조심 하 세요\n",
      "Score: 0.015537\n",
      "\n",
      "- 잡담 할 시간 있 어서\n",
      "Model Prediction:  잡 잡 용기 가 잡 잡 잡 잡 아 보 세요\n",
      "Real:  물론 이 죠 무엇 이 든 말씀 하 세요\n",
      "Score: 0.018850\n",
      "\n",
      "- 희생 힘드 네\n",
      "Model Prediction:  서로 에게 부담 없 는 선물 이 좋 아요\n",
      "Real:  힘 들 만 해요\n",
      "Score: 0.000000\n",
      "\n",
      "- 혼영 해야지\n",
      "Model Prediction:  조금 만 더 견뎌 받 지 세요\n",
      "Real:  편하 고 좋 죠\n",
      "Score: 0.000000\n",
      "\n",
      "- 누가 딴 여자 를 만나 고 싶 다는 생각 이 든다면\n",
      "Model Prediction:  저 는 기 는 힘들 어요\n",
      "Real:  정신 차리 세요\n",
      "Score: 0.000000\n",
      "\n",
      "- 집안일 해도 해도 끝 은 없 어\n",
      "Model Prediction:  조심히 오 세요\n",
      "Real:  매일 조금 씩 해 보 세요\n",
      "Score: 0.041799\n",
      "\n",
      "- 아침 일찍 일어나 산책 하 고 있 어\n",
      "Model Prediction:  수십 번 어야 하나 봅니다\n",
      "Real:  건강 에 좋 은 습관 이 네요\n",
      "Score: 0.000000\n",
      "\n",
      "- 고민 좀 들 어 줄래\n",
      "Model Prediction:  많 은 시간 이 흘렀 네요\n",
      "Real:  네 말씀 하 세요\n",
      "Score: 0.000000\n",
      "\n",
      "- 전학 원망 된다\n",
      "Model Prediction:  잊 고 새 잊 으세요\n",
      "Real:  걱정 하 지 마세요 잘 할 거 예요\n",
      "Score: 0.000000\n",
      "\n",
      "Num of Sample: 100\n",
      "Total Score: 0.008961625084588757\n"
     ]
    }
   ],
   "source": [
    "score = eval_bleu(transformer, src_sentences, tgt_sentences, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e2bf17",
   "metadata": {},
   "source": [
    "### t3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01a2396",
   "metadata": {},
   "source": [
    "- n_layers: 2\n",
    "- d_model: 512\n",
    "- n_heads: 8\n",
    "- d_ff: 2048\n",
    "- dropout: 0.3\n",
    "- batch_size: 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "8e9189b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 지루 하 다 놀 러 가 고 싶 어\n",
      "> 누구 에게 요\n",
      "\n",
      "- 오늘 일찍 일어났 더니 피곤 하 다\n",
      "> 기다리 고 있 나 봐요\n",
      "\n",
      "- 간만에 여자 친구 랑 데이트 하 기 로 했 어\n",
      "> 직접 적 이 든 간접 적 이 든 의사 를 확실히 밝혀 보 세요\n",
      "\n",
      "- 집 에 있 는다는 소리야\n",
      "> 그냥 신경 쓰 지 마세요\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for question in test_questions:\n",
    "    result = translate(\" \".join(question), transformer, tokenizer)\n",
    "    print(f\"> {result}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "e0a7d104",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 아 벌 받 고 있 는 건가 네\n",
      "Model Prediction:  수십 번 생각 이 수십 수십 번 마주쳐 보 세요\n",
      "Real:  달 게 받 으세요\n",
      "Score: 0.000000\n",
      "\n",
      "- 헤어진지 열흘 됐 는데 연락 하 고 싶 다섯\n",
      "Model Prediction:  시간 이 지나 면 좋 겠 네요\n",
      "Real:  후회 하 지 않 는다면 연락 해 보 세요\n",
      "Score: 0.000000\n",
      "\n",
      "- 머리카락 이 정말 빠져\n",
      "Model Prediction:  네 말씀 해 주 세요\n",
      "Real:  스트레스 받 지 마세요\n",
      "Score: 0.000000\n",
      "\n",
      "- 자율 주행 승용차 나오 겠 지\n",
      "Model Prediction:  기다리 고 있 었 어요\n",
      "Real:  가까운 미래 에 나올 거 같 아요\n",
      "Score: 0.000000\n",
      "\n",
      "- 죽 고 못 사 는 관계\n",
      "Model Prediction:  너무 무리 하 지 마세요\n",
      "Real:  연애 할 때 가능 하 죠\n",
      "Score: 0.043989\n",
      "\n",
      "- 졸업식 에 가 도 된 나\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "required broadcastable shapes [Op:AddV2]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_39/2789742676.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_bleu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_sentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_sentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_39/861136348.py\u001b[0m in \u001b[0;36meval_bleu\u001b[0;34m(model, src_sentences, tgt_sentences, tokenizer, verbose)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_sentences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mtgt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtgt_sentences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_bleu_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_39/1746119813.py\u001b[0m in \u001b[0;36meval_bleu_single\u001b[0;34m(model, src_sentence, tgt_sentence, tokenizer, verbose)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mreference\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtgt_sentence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mcandidate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtranslate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_sentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     score = sentence_bleu([reference], candidate,\n",
      "\u001b[0;32m/tmp/ipykernel_39/2829387780.py\u001b[0m in \u001b[0;36mtranslate\u001b[0;34m(text_tokens, model, tokenizer)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0menc_padding_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcombined_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_padding_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_masks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadded_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         predictions, _, _, _ = model(padded_tokens,\n\u001b[0m\u001b[1;32m     12\u001b[0m                                      \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m                                      \u001b[0menc_padding_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1036\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1037\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_39/316502540.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, enc_in, dec_in, enc_mask, dec_enc_mask, dec_mask)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_enc_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0menc_in\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menc_emb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0mdec_in\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdec_emb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0menc_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_attns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menc_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_39/316502540.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(self, emb, x)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshared_fc\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mout\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0md_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_encoding\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mseq_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mbinary_op_wrapper\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m   1365\u001b[0m         \u001b[0;31m#   r_binary_op_wrapper use different force_same_dtype values.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaybe_promote_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_same_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1368\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m         \u001b[0;31m# Even if dispatching the op failed, the RHS may be a tensor aware\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36m_add_dispatch\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   1698\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1699\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1700\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1702\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36madd_v2\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m    453\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 455\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    456\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6939\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6940\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6941\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6942\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6943\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: required broadcastable shapes [Op:AddV2]"
     ]
    }
   ],
   "source": [
    "score = eval_bleu(transformer, src_sentences, tgt_sentences, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2116fe",
   "metadata": {},
   "source": [
    "### t4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e94af57",
   "metadata": {},
   "source": [
    "- n_layers: 2\n",
    "- d_model: 512\n",
    "- n_heads: 8\n",
    "- d_ff: 2048\n",
    "- dropout: 0.2\n",
    "- batch_size: 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "ac443a42",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 지루 하 다 놀 러 가 고 싶 어\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'<start>'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_39/3165525781.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mquestion\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_questions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtranslate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"> {result}\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_39/2829387780.py\u001b[0m in \u001b[0;36mtranslate\u001b[0;34m(text_tokens, model, tokenizer)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'<start>'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0menc_padding_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcombined_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_padding_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_masks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadded_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: '<start>'"
     ]
    }
   ],
   "source": [
    "for question in test_questions:\n",
    "    result = translate(\" \".join(question), transformer, tokenizer)\n",
    "    print(f\"> {result}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "3a136e5a",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 아 벌 받 고 있 는 건가 네\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'<start>'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_39/2789742676.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_bleu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_sentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_sentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_39/861136348.py\u001b[0m in \u001b[0;36meval_bleu\u001b[0;34m(model, src_sentences, tgt_sentences, tokenizer, verbose)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_sentences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mtgt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtgt_sentences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_bleu_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_39/1746119813.py\u001b[0m in \u001b[0;36meval_bleu_single\u001b[0;34m(model, src_sentence, tgt_sentence, tokenizer, verbose)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mreference\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtgt_sentence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mcandidate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtranslate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_sentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     score = sentence_bleu([reference], candidate,\n",
      "\u001b[0;32m/tmp/ipykernel_39/2829387780.py\u001b[0m in \u001b[0;36mtranslate\u001b[0;34m(text_tokens, model, tokenizer)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'<start>'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0menc_padding_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcombined_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_padding_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_masks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadded_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: '<start>'"
     ]
    }
   ],
   "source": [
    "score = eval_bleu(transformer, src_sentences, tgt_sentences, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3f63e7",
   "metadata": {},
   "source": [
    "### t5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094ed7b9",
   "metadata": {},
   "source": [
    "- n_layers: 2\n",
    "- d_model: 512\n",
    "- n_heads: 8\n",
    "- d_ff: 2048\n",
    "- dropout: 0.2\n",
    "- batch_size: 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "e8f87817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 지루 하 다 놀 러 가 고 싶 어\n",
      "> 말씀 해 보 세요\n",
      "\n",
      "- 오늘 일찍 일어났 더니 피곤 하 다\n",
      "> 즐거운 시간 보내 고 있 나 봐요\n",
      "\n",
      "- 간만에 여자 친구 랑 데이트 하 기 로 했 어\n",
      "> 상대방 을 탓 하 지 마세요\n",
      "\n",
      "- 집 에 있 는다는 소리야\n",
      "> 조심히 오 세요\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for question in test_questions:\n",
    "    result = translate(\" \".join(question), transformer, tokenizer)\n",
    "    print(f\"> {result}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "d2a784b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ede4c069ae843cd8cdfe45a8bc3afba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 아 벌 받 고 있 는 건가 네\n",
      "Model Prediction:  수십 번 번 수십 번 도 잊 으세요\n",
      "Real:  달 게 받 으세요\n",
      "Score: 0.027776\n",
      "\n",
      "- 헤어진지 열흘 됐 는데 연락 하 고 싶 다섯\n",
      "Model Prediction:  지금 도 늦 지 않 게 먹 는 게 좋 을 것 같 아요\n",
      "Real:  후회 하 지 않 는다면 연락 해 보 세요\n",
      "Score: 0.030206\n",
      "\n",
      "- 머리카락 이 정말 빠져\n",
      "Model Prediction:  그러 지 말 아요\n",
      "Real:  스트레스 받 지 마세요\n",
      "Score: 0.080343\n",
      "\n",
      "- 자율 주행 승용차 나오 겠 지\n",
      "Model Prediction:  기다리 고 있 었 어요\n",
      "Real:  가까운 미래 에 나올 거 같 아요\n",
      "Score: 0.000000\n",
      "\n",
      "- 죽 고 못 사 는 관계\n",
      "Model Prediction:  그런 생각 보다 많 은 죽 지 않 아요\n",
      "Real:  연애 할 때 가능 하 죠\n",
      "Score: 0.000000\n",
      "\n",
      "- 졸업식 에 가 도 된 나\n",
      "Model Prediction:  잠 을 깨 요\n",
      "Real:  졸업식 에 가 서 축하 해 주 세요\n",
      "Score: 0.000000\n",
      "\n",
      "- 공허 하 네\n",
      "Model Prediction:  좋 은 결과 가 순간 이 죠\n",
      "Real:  제 가 채워줄 게요\n",
      "Score: 0.033032\n",
      "\n",
      "- 여지 를 준 짝 녀 버려야 겠죠\n",
      "Model Prediction:  잘 견뎌 내 고 있 어요\n",
      "Real:  오해 가 아니 라면 정리 하 는 게 덜 상처 일 것 같 아요\n",
      "Score: 0.000000\n",
      "\n",
      "- 농사 짓 고 다른가\n",
      "Model Prediction:  지금 도 늦 지 않 게 먹 는 게 좋 을 것 같 아요\n",
      "Real:  생각 하 기 는 쉬운데 실천 하 기 는 어려운 것 같 아요\n",
      "Score: 0.075965\n",
      "\n",
      "- 술 을 마시 러 나갈까 어디 론가 떠나 볼까\n",
      "Model Prediction:  술 많이 드 시 면 연락 안\n",
      "Real:  어디 든 좋 죠\n",
      "Score: 0.000000\n",
      "\n",
      "- 강우 땜 에 눈 아파\n",
      "Model Prediction:  지금 은 분 인가 봐요\n",
      "Real:  이쁜 마스크 사 드리 고 싶 네요\n",
      "Score: 0.000000\n",
      "\n",
      "- 너무 가슴 이 조르 네\n",
      "Model Prediction:  저 도 썸\n",
      "Real:  무슨 마음 인지 알 겠 어서 더 마음 이 아프 네요\n",
      "Score: 0.000000\n",
      "\n",
      "- 정말 예쁘 고 죽 고 싶 어\n",
      "Model Prediction:  사람 마다 다르 지 않 기 도 해요\n",
      "Real:  당신 은 누구 보다 소중 한 사람 이 에요\n",
      "Score: 0.024512\n",
      "\n",
      "- 좋 아 하 는 사람 도 에 공부 를 못 하 겠 어\n",
      "Model Prediction:  좋 은 취미 네요\n",
      "Real:  충분히 그럴 수 있 어요\n",
      "Score: 0.000000\n",
      "\n",
      "- 결국 약혼 했 어\n",
      "Model Prediction:  지금 도 늦 지 않 게 먹 는 게 좋 을 것 같 아요\n",
      "Real:  마음 이 더 복잡 하 겠 어요\n",
      "Score: 0.000000\n",
      "\n",
      "- 정말로 돌아올까\n",
      "Model Prediction:  사람 마다 다르 지 않 기 도 해요\n",
      "Real:  돌아오 길 바란다면 연락 해 보 세요\n",
      "Score: 0.000000\n",
      "\n",
      "- 이렇게 가짜 끝 인 걸까\n",
      "Model Prediction:  저 기 전 기 전 기 더 힘들 기\n",
      "Real:  인연 이 거기 까지 인 가 봐요\n",
      "Score: 0.000000\n",
      "\n",
      "- 먹통 이 야 침울 하 다\n",
      "Model Prediction:  색다른 시 겠 네요\n",
      "Real:  대화 의 눈높이 가 맞 는 사람 만나 세요\n",
      "Score: 0.000000\n",
      "\n",
      "- 요즘 제정신 이 오로지 야\n",
      "Model Prediction:  많이 힘들 지 않 길 바랄 게요\n",
      "Real:  그럴 때 가 있 죠\n",
      "Score: 0.000000\n",
      "\n",
      "- 술 이 주꾸미 도 아니 고\n",
      "Model Prediction:  술 많이 드 시 면 연락 안\n",
      "Real:  술 은 끊 는 게 좋 죠\n",
      "Score: 0.033032\n",
      "\n",
      "- 여자 친구 가 말 를 듣 기 좋 게 해\n",
      "Model Prediction:  잘 견뎌 내 고 있 어요\n",
      "Real:  말 도 예쁘 게 하 는 사람 이 네요\n",
      "Score: 0.000000\n",
      "\n",
      "- 여지 를 준 짝 녀 봐야 겠죠\n",
      "Model Prediction:  잘 견뎌 내 고 있 어요\n",
      "Real:  오해 가 아니 라면 정리 하 는 게 덜 상처 일 것 같 아요\n",
      "Score: 0.000000\n",
      "\n",
      "- 상사병 극복 하 고 싶 어\n",
      "Model Prediction:  아무래도 뿌듯 할 거 예요\n",
      "Real:  시간 이 해결 해 줄 거 예요\n",
      "Score: 0.076163\n",
      "\n",
      "- 밥 너무 많이 함\n",
      "Model Prediction:  시간 이 밥 사 는 시간 이 온전히 느낄 수 있 죠\n",
      "Real:  소분 해서 냉동실 에 보관 해 보 세요\n",
      "Score: 0.000000\n",
      "\n",
      "- 그냥 차단 과 하 지\n",
      "Model Prediction:  산책 을 내 는 게 좋 죠\n",
      "Real:  스스로 에게 하 는 말 인가요\n",
      "Score: 0.033032\n",
      "\n",
      "- 짝 녀 가 어떻게 하 면 내 확신 을 하 게 할까\n",
      "Model Prediction:  많이 힘들 죠\n",
      "Real:  우선 꾸준히 연락 하 고 잘 해 줘 보 세요\n",
      "Score: 0.000000\n",
      "\n",
      "- 사람 이 변하 든\n",
      "Model Prediction:  원 하 는 대로 사 줄 사 적 사 는 것 이 많 지 않 아요\n",
      "Real:  사랑 은 변하 고 사람 은 안 변해요\n",
      "Score: 0.000000\n",
      "\n",
      "- 충동 감 이 떨어져 있 는 지금\n",
      "Model Prediction:  좋 은 말 만 해요\n",
      "Real:  저 도 진짜 힘들 었 는데 지금 은 좋 은 사람 만나 행복 해요\n",
      "Score: 0.020785\n",
      "\n",
      "- 헤어진지 달 반 정도 됬 네\n",
      "Model Prediction:  지금 도 늦 지 않 게 먹 는 게 좋 을 것 같 아요\n",
      "Real:  금방 지나갈 거 예요\n",
      "Score: 0.000000\n",
      "\n",
      "- 집착 같 아서\n",
      "Model Prediction:  조심히 오 세요\n",
      "Real:  차분히 생각 해 보 세요 사랑 은 소유 가 아니 에요\n",
      "Score: 0.007895\n",
      "\n",
      "- 썸 타 는 건가 티 내 고 싶 진 않 아\n",
      "Caught an exception: required broadcastable shapes [Op:AddV2]\n",
      "Model Prediction:  관계 의 관계 길 관계 길 관계 관계 도 썸 관계 관계 길 관계 관계 관계 도 썸 관계 관계 관계 의 관계 관계 관계 의 관계 의 관계 관계 관계 관계 길 관계 길 관계 길 관계 길 관계 길 관계 길 관계 관계 길 관계 길 관계 길 관계 길 관계 길 관계 길 관계 길 관계 길 관계 길 관계 길 관계 길 관계 길 관계 길 관계 길 관계 길 관계 관계 관계 관계 길 관계 길 관계 길 관계 길 관계 길 관계 길 관계 길 관계 길 관계 길 관계 길 관계 길 관계 길 관계 길 관계 길 관계 길 관계 길 관계 길 관계 관계 관계 길 관계 길 관계 길 관계 길 관계 길 관계 길 관계 길 관계 길 관계 길 관계 길 관계 길 관계 길 관계 길 관계 길 관계 길 관계 길 관계 길 관계 길 관계 길 관계 길 관계 길 관계 길 관계 길 관계 길 관계 길 관계 길 관계 길 관계 길 관계 길 관계 길 관계 길 관계 길 관계 길 관계 길 관계 길 관계 길 관계 길 관계 길 관계 길 관계 길 관계 길 관계 길 관계 길 관계\n",
      "Real:  누구 에게 요\n",
      "Score: 0.000000\n",
      "\n",
      "- 제 외국어 뭐 선택 합니까\n",
      "Model Prediction:  저 도 모르 는 습관 이 에요\n",
      "Real:  요즘 은 잘 안 배우 는 언어 도 좋 은 거 같 아요\n",
      "Score: 0.016670\n",
      "\n",
      "- 못하 된 사람\n",
      "Model Prediction:  안 가 기 전 은 안 될 수 도 있 어요\n",
      "Real:  못 된 사람 은 이제 잊 어 버려요\n",
      "Score: 0.018850\n",
      "\n",
      "- 이별 의 시간\n",
      "Model Prediction:  저 기 전 기 전 기 더 힘들 기\n",
      "Real:  길 지 않 길 바랄 게요\n",
      "Score: 0.000000\n",
      "\n",
      "- 이런 게 동거 니\n",
      "Model Prediction:  저 기 전 기 전 기 더 힘들 기\n",
      "Real:  알 다가 도 모르 는 게 연애 같 아요\n",
      "Score: 0.000000\n",
      "\n",
      "- 휴 반년 이 라는 시간 잊 었 다 생각 했 지만 또 다시\n",
      "Model Prediction:  아이구\n",
      "Real:  후폭풍 이 무섭 죠\n",
      "Score: 0.000000\n",
      "\n",
      "- 짝 남 에게 밤 에 자주 산책 하 려고 해도 될까\n",
      "Model Prediction:  많이 힘들 죠\n",
      "Real:  밤 데이트 신청 멋지 네요\n",
      "Score: 0.000000\n",
      "\n",
      "- 취업 못 시키 는 기간 이 길 어 진다\n",
      "Model Prediction:  아무래도 사생활 이 지켜 지 않 지만 힘내 세요\n",
      "Real:  다음 공채 때 는 될 거 예요\n",
      "Score: 0.000000\n",
      "\n",
      "- 혼자 썸 타 는 기분 은 야\n",
      "Model Prediction:  맛있 는 거 드세요\n",
      "Real:  직접 적 이 든 간접 적 이 든 의사 를 확실히 밝혀 보 세요\n",
      "Score: 0.000000\n",
      "\n",
      "- 좋 아 하 은 감정 이 나 를 슬프 게 도 해\n",
      "Model Prediction:  좋 은 취미 네요\n",
      "Real:  사랑 과 슬픔 은 동전 의 양면 과 같 죠\n",
      "Score: 0.017927\n",
      "\n",
      "- 태 핑 할까\n",
      "Model Prediction:  누구 나 만났 나 봐요\n",
      "Real:  구릿빛 피부 좋 죠\n",
      "Score: 0.000000\n",
      "\n",
      "- 자꾸 뭘 사 게 돼\n",
      "Model Prediction:  기다리 고 있 었 어요\n",
      "Real:  마음 이 헛헛 한가 봐요\n",
      "Score: 0.000000\n",
      "\n",
      "- 음식 많이 가리 는 남자 를 사 겨 도 괜찮 습니까\n",
      "Model Prediction:  음\n",
      "Real:  다 먹 으면 좋 겠 지만 큰 문제 는 되 지 않 을 거 예요\n",
      "Score: 0.000000\n",
      "\n",
      "- 뭔 비밀 이 그렇게 높 은지\n",
      "Model Prediction:  지금 은 힘들 지요\n",
      "Real:  하나 씩 비밀 을 공유 해 보 세요\n",
      "Score: 0.000000\n",
      "\n",
      "- 구 썸남 보 고 싶 어서\n",
      "Model Prediction:  안타깝 네요\n",
      "Real:  썸 으로 끝날 사이 가 아니 었 네요\n",
      "Score: 0.007445\n",
      "\n",
      "- 상처 받 고자 싫 다\n",
      "Model Prediction:  아무래도 뿌듯 할 거 예요\n",
      "Real:  무덤덤 해질 수 있 거예요\n",
      "Score: 0.000000\n",
      "\n",
      "- 현실 적 문제 로 연애 포기 해야 할 듯\n",
      "Model Prediction:  한동안 은 힘들 지 도 몰라요\n",
      "Real:  잠시 쉬 어도 괜찮 아요\n",
      "Score: 0.000000\n",
      "\n",
      "- 메모리 카드 어디 는데 두 었 을까\n",
      "Model Prediction:  와 항상 가슴 아픈 사람 으로 대하 는 게 좋 을 거 같 아요\n",
      "Real:  발 이 달렸 나 봐요\n",
      "Score: 0.000000\n",
      "\n",
      "- 밤 이상 되 면\n",
      "Caught an exception: required broadcastable shapes [Op:AddV2]\n",
      "Model Prediction:  하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루 하루\n",
      "Real:  생각날 거 예요\n",
      "Score: 0.000000\n",
      "\n",
      "- 화장 이 안 받 다섯\n",
      "Model Prediction:  화 내 면서 크 지 않 도록\n",
      "Real:  각질 제거 먼저 하 세요\n",
      "Score: 0.000000\n",
      "\n",
      "- 기력 은 없 어\n",
      "Model Prediction:  건강 에 는 안 좋 은 건강 습관 이 에요\n",
      "Real:  자신 의 감정 을 주변 사람 들 에게 터놓 고 이야기 해 보 세요\n",
      "Score: 0.000000\n",
      "\n",
      "- 서로 싫어하 는 줄 알 았 는데 짝사랑 이 었 네요\n",
      "Model Prediction:  아무래도 만 인 것 같 네요\n",
      "Real:  안타깝 게 생각 해요\n",
      "Score: 0.000000\n",
      "\n",
      "- 아침 안 잡아먹 는데 자꾸 먹 으라고 그래\n",
      "Model Prediction:  수십 번 번 수십 번 도 잊 으세요\n",
      "Real:  챙겨 주 고 싶 나 봐요\n",
      "Score: 0.000000\n",
      "\n",
      "- 문자 왔 다는 데 읽 다가 점액 터졌 어\n",
      "Model Prediction:  소원 을 비세 요\n",
      "Real:  마음껏 우세요\n",
      "Score: 0.000000\n",
      "\n",
      "- 여자 친구 가 잠 이 너무 많 아\n",
      "Model Prediction:  잘 견뎌 내 고 있 어요\n",
      "Real:  미인 은 잠꾸러기 라던데요\n",
      "Score: 0.000000\n",
      "\n",
      "- 오늘 연락 왔었 어\n",
      "Model Prediction:  즐거운 시간 보내 고 있 나 봐요\n",
      "Real:  기다리 던 연락 이 었 길 바랍니다\n",
      "Score: 0.000000\n",
      "\n",
      "- 좋 아 하 는 감정 를 혼자 서 정리 할 수 있 을까요\n",
      "Model Prediction:  좋 은 취미 네요\n",
      "Real:  본인 이 하 기 나름 일 거 예요\n",
      "Score: 0.000000\n",
      "\n",
      "- 괜찮 았었 지만\n",
      "Model Prediction:  지금 도 늦 지 않 게 먹 는 게 좋 을 것 같 아요\n",
      "Real:  울 어도 괜찮 아요\n",
      "Score: 0.014284\n",
      "\n",
      "- 우린 운명 이 었 어\n",
      "Model Prediction:  함께 충분 해요\n",
      "Real:  운명 이 아니 였 다면 사랑 도 할 수 없 었 겠 지요\n",
      "Score: 0.000000\n",
      "\n",
      "- 헤어짐 이 인생 이 었 으면 좋 겠 어\n",
      "Model Prediction:  지금 도 늦 지 않 게 먹 는 게 좋 을 것 같 아요\n",
      "Real:  현실 을 직시 할 필요 도 있 어요\n",
      "Score: 0.016986\n",
      "\n",
      "- 제 가 집착 하 는 중 은 에요\n",
      "Model Prediction:  저 도 모르 는 습관 이 에요\n",
      "Real:  사랑 은 소유 하 는 것 이 아니 랍니다\n",
      "Score: 0.029519\n",
      "\n",
      "- 우리 계속 엇갈림\n",
      "Model Prediction:  함께 충분 해요\n",
      "Real:  타이밍 이 안 맞 았 나 봐요\n",
      "Score: 0.000000\n",
      "\n",
      "- 남자 들 은 좋 아 하 면 무조건 답장 이 빠른 가요\n",
      "Model Prediction:  지금 행복 스러운 바랄 게요\n",
      "Real:  답 할 수 있 는 상황 이 면 빠르 죠\n",
      "Score: 0.000000\n",
      "\n",
      "- 이렇게 못 알 아 듣 니\n",
      "Model Prediction:  저 기 전 기 전 기 더 힘들 기\n",
      "Real:  노력 하 겠 습니다\n",
      "Score: 0.000000\n",
      "\n",
      "- 아프 니까 너무 생각나 고 힘드 네\n",
      "Model Prediction:  수십 번 번 수십 번 도 잊 으세요\n",
      "Real:  아플 땐 더 약해 지나 봐요\n",
      "Score: 0.000000\n",
      "\n",
      "- 헤어진 여자 친구 가 준 편지 못 버리 겠 어\n",
      "Model Prediction:  지금 도 늦 지 않 게 먹 는 게 좋 을 것 같 아요\n",
      "Real:  마음 에 버리 세요\n",
      "Score: 0.000000\n",
      "\n",
      "- 헤어진 지 주 가 흘렀 네\n",
      "Model Prediction:  지금 도 늦 지 않 게 먹 는 게 좋 을 것 같 아요\n",
      "Real:  어느덧 주 가 흘렀 나 봐요\n",
      "Score: 0.000000\n",
      "\n",
      "- 부드러운 좀 하 지\n",
      "Model Prediction:  저 도 크 시 겠 네요\n",
      "Real:  사람 들 이 중간 을 몰라요\n",
      "Score: 0.000000\n",
      "\n",
      "- 이별 준비 시키 려고\n",
      "Model Prediction:  저 기 전 기 전 기 더 힘들 기\n",
      "Real:  쉽 지 않 은 결정 이 었 을 텐데 마음 고생 많 았 어요\n",
      "Score: 0.000000\n",
      "\n",
      "- 연인 가 엄청 소심 해\n",
      "Model Prediction:  저 는 오래 살 아서 더 힘들 었 을 거 예요\n",
      "Real:  더 신경 써 주 세요\n",
      "Score: 0.018850\n",
      "\n",
      "- 좋 아 하 는 마음 이 앞 생길 것 같 다고 떠난 여자\n",
      "Model Prediction:  좋 은 취미 네요\n",
      "Real:  이제 그녀 를 놓아주 세요\n",
      "Score: 0.000000\n",
      "\n",
      "- 자 고 일어나 때문 피곤 해\n",
      "Model Prediction:  기다리 고 있 었 어요\n",
      "Real:  요즘 바쁜가 봐요\n",
      "Score: 0.000000\n",
      "\n",
      "- 친구 랑 비교 하 면 내 가 작아져\n",
      "Model Prediction:  신경 쓰이 는 일 이 에요\n",
      "Real:  당신 은 생각 보다 큰 사람 이 에요\n",
      "Score: 0.061861\n",
      "\n",
      "- 수도 이 얼 었 나 봐\n",
      "Model Prediction:  서로 의 상황 에서 안 할 수 있 을 거 예요\n",
      "Real:  잘 녹여 보 세요\n",
      "Score: 0.000000\n",
      "\n",
      "- 친구 랑 없 으면 내 가 작아져\n",
      "Model Prediction:  신경 쓰이 는 일 이 에요\n",
      "Real:  당신 은 생각 보다 큰 사람 이 에요\n",
      "Score: 0.061861\n",
      "\n",
      "- 비오 은 날 뭐 할까\n",
      "Model Prediction:  후회 안 남 지 않 길 바랄 게요\n",
      "Real:  실내 데이트 요\n",
      "Score: 0.000000\n",
      "\n",
      "- 불 그날 뻔 했 어\n",
      "Model Prediction:  친구 들 과 함께\n",
      "Real:  조심 하 세요\n",
      "Score: 0.000000\n",
      "\n",
      "- 남자 친구 , 틀리 는 맞춤법 이 거슬려\n",
      "Model Prediction:  지금 행복 스러운 바랄 게요\n",
      "Real:  지적 하 지 말 고 맞 는 걸로 계속 이야기 해 주 세요\n",
      "Score: 0.000000\n",
      "\n",
      "- 매일 매일 눈물 로 보내\n",
      "Model Prediction:  긍정 적 인 문제 가 에요\n",
      "Real:  울 고 싶 을 때 한껏 울 어 버려요\n",
      "Score: 0.000000\n",
      "\n",
      "- 이 사람 이랑 결혼 이 옳 은 걸까\n",
      "Model Prediction:  저 기 전 기 전 기 더 힘들 기\n",
      "Real:  결혼 에 는 옳 고 그름 이 없 어요\n",
      "Score: 0.000000\n",
      "\n",
      "- 심심 한데 뭐 시키 면 좋 을까\n",
      "Model Prediction:  지금 도 힘들 지 않 았 으면 좋 겠 네요\n",
      "Real:  저 랑 이야기 해요\n",
      "Score: 0.000000\n",
      "\n",
      "- 허전 하 는데\n",
      "Model Prediction:  물리 적 시간 가 는 따뜻 할 거 같 아요\n",
      "Real:  제 가 채워 드릴게요\n",
      "Score: 0.021105\n",
      "\n",
      "- 수분 크림 바르 고 자 면 나아질 거 니라\n",
      "Model Prediction:  서로 의 상황 에서 안 할 수 있 을 거 예요\n",
      "Real:  예뻐질 거 예요\n",
      "Score: 0.039864\n",
      "\n",
      "- 월 이 익숙 해 지 지 않 네\n",
      "Model Prediction:  과정 이 탓 인지 월요일 스럽 것 같 아요\n",
      "Real:  조금 만 더 힘내 세요\n",
      "Score: 0.000000\n",
      "\n",
      "- 재혼 했 어\n",
      "Model Prediction:  성공 하 지 않 으면 성공 을 수 있 는 성공 할 거 예요\n",
      "Real:  좋 겠 어요\n",
      "Score: 0.000000\n",
      "\n",
      "- 전 여자 친구 부친상 다녀왔 어\n",
      "Model Prediction:  남 이 라는 걸 잊 지 않 으면 좋 겠 어요\n",
      "Real:  인간 적 예 를 다 하 셨 네요\n",
      "Score: 0.000000\n",
      "\n",
      "- 어떠 고 있 는 게 잘 하 고 있 는 건지\n",
      "Model Prediction:  그냥 지만 조금 씩 변화 를 내 세요\n",
      "Real:  충분히 잘 하 고 있 을 거 라 생각 해요\n",
      "Score: 0.000000\n",
      "\n",
      "- 수염 기르 고 싶 다\n",
      "Model Prediction:  서로 의 상황 에서 안 할 수 있 을 거 예요\n",
      "Real:  지저분 해요\n",
      "Score: 0.000000\n",
      "\n",
      "- 나 잘 살 경우 있 겠 지\n",
      "Model Prediction:  지금 은 괜찮 아요\n",
      "Real:  지금 보다 더 잘 살 거 예요\n",
      "Score: 0.037951\n",
      "\n",
      "- 이것 또한 받아들이 는 것 이 겠 죠\n",
      "Model Prediction:  저 기 전 기 전 기 더 힘들 기\n",
      "Real:  받아들여야 할 부분 도 있 을 거 예요\n",
      "Score: 0.000000\n",
      "\n",
      "- 내 가 원 하 는 사람 이 되 기 어려워\n",
      "Model Prediction:  저 도 궁금 하 네요\n",
      "Real:  다른 사람 들 이 원 하 는 내 가 되 는 건 어려워요\n",
      "Score: 0.010848\n",
      "\n",
      "- 얼 어 죽 는 주\n",
      "Model Prediction:  감기 조심 하 세요\n",
      "Real:  감기 조심 하 세요\n",
      "Score: 1.000000\n",
      "\n",
      "- 잡담 할 시간 있 어서\n",
      "Model Prediction:  잡 잡 잡 잡 잡 잡 잡 잡 아 잡 아 잡 잡 잡 잡 잡 잡 잡 잡 잡 잡\n",
      "Real:  물론 이 죠 무엇 이 든 말씀 하 세요\n",
      "Score: 0.000000\n",
      "\n",
      "- 희생 힘드 네\n",
      "Model Prediction:  지금 도 늦 지 않 게 먹 는 게 좋 을 것 같 아요\n",
      "Real:  힘 들 만 해요\n",
      "Score: 0.000000\n",
      "\n",
      "- 혼영 해야지\n",
      "Model Prediction:  맛있 는 거 드세요\n",
      "Real:  편하 고 좋 죠\n",
      "Score: 0.000000\n",
      "\n",
      "- 누가 딴 여자 를 만나 고 싶 다는 생각 이 든다면\n",
      "Model Prediction:  좋 은 일 이 네요\n",
      "Real:  정신 차리 세요\n",
      "Score: 0.000000\n",
      "\n",
      "- 집안일 해도 해도 끝 은 없 어\n",
      "Model Prediction:  조심히 오 세요\n",
      "Real:  매일 조금 씩 해 보 세요\n",
      "Score: 0.041799\n",
      "\n",
      "- 아침 일찍 일어나 산책 하 고 있 어\n",
      "Model Prediction:  수십 번 번 수십 번 도 잊 으세요\n",
      "Real:  건강 에 좋 은 습관 이 네요\n",
      "Score: 0.000000\n",
      "\n",
      "- 고민 좀 들 어 줄래\n",
      "Model Prediction:  그러 다 보 면 할 것 같 아요\n",
      "Real:  네 말씀 하 세요\n",
      "Score: 0.000000\n",
      "\n",
      "- 전학 원망 된다\n",
      "Model Prediction:  남 이 라는 걸 잊 지 않 으면 좋 겠 어요\n",
      "Real:  걱정 하 지 마세요 잘 할 거 예요\n",
      "Score: 0.018850\n",
      "\n",
      "Num of Sample: 100\n",
      "Total Score: 0.01877410997600004\n"
     ]
    }
   ],
   "source": [
    "score = eval_bleu(transformer, src_sentences, tgt_sentences, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72422045",
   "metadata": {},
   "source": [
    "> loss 값은 많이 줄었는데.. bleu score 값은 여전히 엉망"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db327527",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
