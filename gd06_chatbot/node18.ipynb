{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9a5c6d5",
   "metadata": {},
   "source": [
    "평가문항\t상세기준\n",
    "\n",
    "1. 챗봇 훈련데이터 전처리 과정이 체계적으로 진행되었는가?\t\n",
    "> 챗봇 훈련데이터를 위한 전처리와 augmentation이 적절히 수행되어 3만개 가량의 훈련데이터셋이 구축되었다.\n",
    "\n",
    "2. transformer 모델을 활용한 챗봇 모델이 과적합을 피해 안정적으로 훈련되었는가?\t\n",
    "> 과적합을 피할 수 있는 하이퍼파라미터 셋이 적절히 제시되었다.\n",
    "\n",
    "3. 챗봇이 사용자의 질문에 그럴듯한 형태로 답하는 사례가 있는가?\n",
    "> 주어진 예문을 포함하여 챗봇에 던진 질문에 적절히 답하는 사례가 제출되었다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e92d2edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일 저장 커스텀 모듈\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../custom\")\n",
    "\n",
    "from importlib import reload\n",
    "import custom_utils\n",
    "reload(custom_utils)\n",
    "\n",
    "from custom_utils import save_var, load_var\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5e803f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import re\n",
    "import os\n",
    "import io\n",
    "import random\n",
    "import logging\n",
    "import math\n",
    "\n",
    "from tqdm import tqdm\n",
    "# from tqdm.notebook import tqdm\n",
    "\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from nltk.translate.bleu_score import SmoothingFunction\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "import sentencepiece as spm\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d209f57d",
   "metadata": {},
   "source": [
    "# Step 1. 데이터 다운로드"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad6a11e",
   "metadata": {},
   "source": [
    "읽어 온 데이터의 질문과 답변을 각각 questions, answers 변수에 나눠서 저장하세요!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9d8dc3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/ChatbotData.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bea3095f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11823 entries, 0 to 11822\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Q       11823 non-null  object\n",
      " 1   A       11823 non-null  object\n",
      " 2   label   11823 non-null  int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 277.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f9b4b9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = df[\"Q\"]\n",
    "answers = df[\"A\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7ee5ef84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'12시 땡!'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c68be039",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'하루가 또 가네요.'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8481afaa",
   "metadata": {},
   "source": [
    "# Step 2. 데이터 정제"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ec68fa",
   "metadata": {},
   "source": [
    "아래 조건을 만족하는 preprocess_sentence() 함수를 구현하세요.\n",
    "\n",
    "- 영문자의 경우, 모두 소문자로 변환합니다.\n",
    "- 영문자와 한글, 숫자, 그리고 주요 특수문자를 제외하곤 정규식을 활용하여 모두 제거합니다.\n",
    "\n",
    "문장부호 양옆에 공백을 추가하는 등 이전과 다르게 생략된 기능들은 우리가 사용할 토크나이저가 지원하기 때문에 굳이 구현하지 않아도 괜찮습니다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa84f629",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextCleaner:\n",
    "    def __init__(self):\n",
    "        self.punct_space_re = re.compile(r\"([?.!,])\")\n",
    "        self.multiple_spaces_re = re.compile(r'[\" \"]+')\n",
    "        self.allowed_chars_re = re.compile(r\"[^a-zA-Z가-힣?.!,]+\")\n",
    "        self.email_re = re.compile(r'([a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+)')\n",
    "        self.url_re = re.compile(r'(http|ftp|https)://(?:[-\\w.]|(?:%[\\da-fA-F]{2}))+')\n",
    "        self.korean_chars_re = re.compile(r'([ㄱ-ㅎㅏ-ㅣ]+)')\n",
    "        self.html_tag_re = re.compile(r'<[^>]*>')\n",
    "        self.special_chars_re = re.compile(r'[-=+,#/\\?:^$.@*\\\"※~&%ㆍ!』\\\\‘|\\(\\)\\[\\]\\<\\>`\\'…》]')\n",
    "        \n",
    "    def clean_text(self, text):\n",
    "        try:\n",
    "            text = text.strip().lower()\n",
    "            text = self.punct_space_re.sub(r\" \\1 \", text)\n",
    "            text = self.multiple_spaces_re.sub(\" \", text)\n",
    "            text = self.allowed_chars_re.sub(\" \", text)\n",
    "            text = self.email_re.sub(\"\", text)\n",
    "            text = self.url_re.sub(\"\", text)\n",
    "            text = self.korean_chars_re.sub(\"\", text)\n",
    "            text = self.html_tag_re.sub(\"\", text)\n",
    "            text = self.special_chars_re.sub(\"\", text)\n",
    "            text = text.replace('\\n', '.')\n",
    "            return text\n",
    "        except TypeError:\n",
    "            print(\"Warning: Input was not a string or bytes-like object.\")\n",
    "            print(text)\n",
    "            return text\n",
    "\n",
    "    # 데이터 정제\n",
    "    def clean_corpus(self, corpus):\n",
    "        \n",
    "        self.corpus_cleaned = []\n",
    "        \n",
    "        for sentence in corpus:\n",
    "            self.corpus_cleaned.append(self.clean_text(sentence))\n",
    "    \n",
    "        return self.corpus_cleaned\n",
    "\n",
    "    # get unique data for the corpus1 \n",
    "    def get_unique_corpus1(self, corpus1, corpus2):\n",
    "        seen_sentences = set()\n",
    "        unique_corpus1 = []\n",
    "        unique_corpus2 = []\n",
    "        original_length = len(corpus1)\n",
    "        for sent1, sent2 in zip(corpus1, corpus2):\n",
    "            sent1_str = ' '.join(sent1)\n",
    "            if sent1_str not in seen_sentences:\n",
    "                seen_sentences.add(sent1_str)\n",
    "                unique_corpus1.append(sent1)\n",
    "                unique_corpus2.append(sent2)\n",
    "        removed_length = original_length - len(unique_corpus1)\n",
    "        print(f\"removed: {removed_length}\")\n",
    "        return [unique_corpus1, unique_corpus2]\n",
    "\n",
    "\n",
    "    # get unique data for the corpus1,2\n",
    "    def get_unique_corpus_both(self, corpus):\n",
    "\n",
    "        self.unique_corpus = self.get_unique_corpus1(corpus[1], corpus[0])  # for corpus2.\n",
    "        self.unique_corpus = self.get_unique_corpus1(self.unique_corpus[1], self.unique_corpus[0])  # for corpus1.\n",
    "    \n",
    "        return self.unique_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f27d09f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaner = TextCleaner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "64761f41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' 시 땡  ', ' 지망 학교 떨어졌어', ' 박 일 놀러가고 싶다']\n"
     ]
    }
   ],
   "source": [
    "tmp = cleaner.clean_corpus(df[\"Q\"].iloc[:3])\n",
    "print(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8cd11b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Q_cleaned\"] = cleaner.clean_corpus(df[\"Q\"])\n",
    "df[\"A_cleaned\"] = cleaner.clean_corpus(df[\"A\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "fdc73e67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11823 entries, 0 to 11822\n",
      "Data columns (total 5 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   Q          11823 non-null  object\n",
      " 1   A          11823 non-null  object\n",
      " 2   label      11823 non-null  int64 \n",
      " 3   Q_cleaned  11823 non-null  object\n",
      " 4   A_cleaned  11823 non-null  object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 462.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "bf761915",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "      <th>label</th>\n",
       "      <th>Q_cleaned</th>\n",
       "      <th>A_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12시 땡!</td>\n",
       "      <td>하루가 또 가네요.</td>\n",
       "      <td>0</td>\n",
       "      <td>시 땡</td>\n",
       "      <td>하루가 또 가네요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1지망 학교 떨어졌어</td>\n",
       "      <td>위로해 드립니다.</td>\n",
       "      <td>0</td>\n",
       "      <td>지망 학교 떨어졌어</td>\n",
       "      <td>위로해 드립니다</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3박4일 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "      <td>박 일 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Q            A  label     Q_cleaned     A_cleaned\n",
       "0        12시 땡!   하루가 또 가네요.      0         시 땡     하루가 또 가네요  \n",
       "1   1지망 학교 떨어졌어    위로해 드립니다.      0    지망 학교 떨어졌어    위로해 드립니다  \n",
       "2  3박4일 놀러가고 싶다  여행은 언제나 좋죠.      0   박 일 놀러가고 싶다  여행은 언제나 좋죠  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb6f380",
   "metadata": {},
   "source": [
    "# Step 3. 데이터 토큰화"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee4e0b5",
   "metadata": {},
   "source": [
    "토큰화에는 KoNLPy의 mecab 클래스를 사용합니다.  \n",
    "아래 조건을 만족하는 build_corpus() 함수를 구현하세요!  \n",
    "\n",
    "1. 소스 문장 데이터와 타겟 문장 데이터를 입력으로 받습니다.\n",
    "2. 데이터를 앞서 정의한 preprocess_sentence() 함수로 정제하고, 토큰화합니다.\n",
    "3. 토큰화는 전달받은 토크나이즈 함수를 사용합니다. 이번엔 mecab.morphs 함수를 전달하시면 됩니다.\n",
    "4. 토큰의 개수가 일정 길이 이상인 문장은 데이터에서 제외합니다.\n",
    "5. 중복되는 문장은 데이터에서 제외합니다. 소스 : 타겟 쌍을 비교하지 않고 소스는 소스대로 타겟은 타겟대로 검사합니다. 중복 쌍이 흐트러지지 않도록 유의하세요!\n",
    "\n",
    "구현한 함수를 활용하여 questions 와 answers 를 각각 que_corpus , ans_corpus 에 토큰화하여 저장합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83c09149",
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Mecab\n",
    "\n",
    "mecab = Mecab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e57d37ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['시', '땡']\n"
     ]
    }
   ],
   "source": [
    "res = mecab.morphs(tmp[0])\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e43ec3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokenized_sentence(sentence, tokenizer):\n",
    "    return tokenizer.morphs(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed38b954",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokenized_corpus(corpus, tokenizer):\n",
    "    corpus_tokenized = []\n",
    "    for sentence in corpus:\n",
    "        corpus_tokenized.append(get_tokenized_sentence(sentence, tokenizer))\n",
    "    return corpus_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "88b4d1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Q_tokenized\"] = get_tokenized_corpus(df[\"Q_cleaned\"], mecab)\n",
    "df[\"A_tokenized\"] = get_tokenized_corpus(df[\"A_cleaned\"], mecab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0ccba63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:, \"Q_length\"] = df[\"Q_tokenized\"].apply(lambda x: len(x))\n",
    "df.loc[:, \"A_length\"] = df[\"A_tokenized\"].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "94a5ea98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "      <th>label</th>\n",
       "      <th>Q_cleaned</th>\n",
       "      <th>A_cleaned</th>\n",
       "      <th>Q_tokenized</th>\n",
       "      <th>A_tokenized</th>\n",
       "      <th>Q_length</th>\n",
       "      <th>A_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12시 땡!</td>\n",
       "      <td>하루가 또 가네요.</td>\n",
       "      <td>0</td>\n",
       "      <td>시 땡</td>\n",
       "      <td>하루가 또 가네요</td>\n",
       "      <td>[시, 땡]</td>\n",
       "      <td>[하루, 가, 또, 가, 네요]</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1지망 학교 떨어졌어</td>\n",
       "      <td>위로해 드립니다.</td>\n",
       "      <td>0</td>\n",
       "      <td>지망 학교 떨어졌어</td>\n",
       "      <td>위로해 드립니다</td>\n",
       "      <td>[지망, 학교, 떨어졌, 어]</td>\n",
       "      <td>[위로, 해, 드립니다]</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3박4일 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "      <td>박 일 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠</td>\n",
       "      <td>[박, 일, 놀, 러, 가, 고, 싶, 다]</td>\n",
       "      <td>[여행, 은, 언제나, 좋, 죠]</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Q            A  label     Q_cleaned     A_cleaned  \\\n",
       "0        12시 땡!   하루가 또 가네요.      0         시 땡     하루가 또 가네요     \n",
       "1   1지망 학교 떨어졌어    위로해 드립니다.      0    지망 학교 떨어졌어    위로해 드립니다     \n",
       "2  3박4일 놀러가고 싶다  여행은 언제나 좋죠.      0   박 일 놀러가고 싶다  여행은 언제나 좋죠     \n",
       "\n",
       "                Q_tokenized         A_tokenized  Q_length  A_length  \n",
       "0                    [시, 땡]   [하루, 가, 또, 가, 네요]         2         5  \n",
       "1          [지망, 학교, 떨어졌, 어]       [위로, 해, 드립니다]         4         3  \n",
       "2  [박, 일, 놀, 러, 가, 고, 싶, 다]  [여행, 은, 언제나, 좋, 죠]         8         5  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "ec7261c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[\"Q_length\"].hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "5323a41d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[\"A_length\"].hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2f04119c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_org = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "563e1aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_org.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "cc5a5cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"Q_length\"] < 20]\n",
    "df = df[df[\"A_length\"] < 20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ef05683b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 11687 entries, 0 to 11686\n",
      "Data columns (total 9 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   Q            11687 non-null  object\n",
      " 1   A            11687 non-null  object\n",
      " 2   label        11687 non-null  int64 \n",
      " 3   Q_cleaned    11687 non-null  object\n",
      " 4   A_cleaned    11687 non-null  object\n",
      " 5   Q_tokenized  11687 non-null  object\n",
      " 6   A_tokenized  11687 non-null  object\n",
      " 7   Q_length     11687 non-null  int64 \n",
      " 8   A_length     11687 non-null  int64 \n",
      "dtypes: int64(3), object(6)\n",
      "memory usage: 913.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e818b6e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[\"Q_length\"].hist(bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "92f94a4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[\"A_length\"].hist(bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ad2b13b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "      <th>label</th>\n",
       "      <th>Q_cleaned</th>\n",
       "      <th>A_cleaned</th>\n",
       "      <th>Q_tokenized</th>\n",
       "      <th>A_tokenized</th>\n",
       "      <th>Q_length</th>\n",
       "      <th>A_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12시 땡!</td>\n",
       "      <td>하루가 또 가네요.</td>\n",
       "      <td>0</td>\n",
       "      <td>시 땡</td>\n",
       "      <td>하루가 또 가네요</td>\n",
       "      <td>[시, 땡]</td>\n",
       "      <td>[하루, 가, 또, 가, 네요]</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1지망 학교 떨어졌어</td>\n",
       "      <td>위로해 드립니다.</td>\n",
       "      <td>0</td>\n",
       "      <td>지망 학교 떨어졌어</td>\n",
       "      <td>위로해 드립니다</td>\n",
       "      <td>[지망, 학교, 떨어졌, 어]</td>\n",
       "      <td>[위로, 해, 드립니다]</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3박4일 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "      <td>박 일 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠</td>\n",
       "      <td>[박, 일, 놀, 러, 가, 고, 싶, 다]</td>\n",
       "      <td>[여행, 은, 언제나, 좋, 죠]</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3박4일 정도 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "      <td>박 일 정도 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠</td>\n",
       "      <td>[박, 일, 정도, 놀, 러, 가, 고, 싶, 다]</td>\n",
       "      <td>[여행, 은, 언제나, 좋, 죠]</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PPL 심하네</td>\n",
       "      <td>눈살이 찌푸려지죠.</td>\n",
       "      <td>0</td>\n",
       "      <td>ppl 심하네</td>\n",
       "      <td>눈살이 찌푸려지죠</td>\n",
       "      <td>[ppl, 심하, 네]</td>\n",
       "      <td>[눈살, 이, 찌푸려, 지, 죠]</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SD카드 망가졌어</td>\n",
       "      <td>다시 새로 사는 게 마음 편해요.</td>\n",
       "      <td>0</td>\n",
       "      <td>sd카드 망가졌어</td>\n",
       "      <td>다시 새로 사는 게 마음 편해요</td>\n",
       "      <td>[sd, 카드, 망가졌, 어]</td>\n",
       "      <td>[다시, 새로, 사, 는, 게, 마음, 편해요]</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SD카드 안돼</td>\n",
       "      <td>다시 새로 사는 게 마음 편해요.</td>\n",
       "      <td>0</td>\n",
       "      <td>sd카드 안돼</td>\n",
       "      <td>다시 새로 사는 게 마음 편해요</td>\n",
       "      <td>[sd, 카드, 안, 돼]</td>\n",
       "      <td>[다시, 새로, 사, 는, 게, 마음, 편해요]</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SNS 맞팔 왜 안하지ㅠㅠ</td>\n",
       "      <td>잘 모르고 있을 수도 있어요.</td>\n",
       "      <td>0</td>\n",
       "      <td>sns 맞팔 왜 안하지</td>\n",
       "      <td>잘 모르고 있을 수도 있어요</td>\n",
       "      <td>[sns, 맞, 팔, 왜, 안, 하, 지]</td>\n",
       "      <td>[잘, 모르, 고, 있, 을, 수, 도, 있, 어요]</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SNS 시간낭비인 거 아는데 매일 하는 중</td>\n",
       "      <td>시간을 정하고 해보세요.</td>\n",
       "      <td>0</td>\n",
       "      <td>sns 시간낭비인 거 아는데 매일 하는 중</td>\n",
       "      <td>시간을 정하고 해보세요</td>\n",
       "      <td>[sns, 시간, 낭비, 인, 거, 아, 는데, 매일, 하, 는, 중]</td>\n",
       "      <td>[시간, 을, 정하, 고, 해, 보, 세요]</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SNS 시간낭비인데 자꾸 보게됨</td>\n",
       "      <td>시간을 정하고 해보세요.</td>\n",
       "      <td>0</td>\n",
       "      <td>sns 시간낭비인데 자꾸 보게됨</td>\n",
       "      <td>시간을 정하고 해보세요</td>\n",
       "      <td>[sns, 시간, 낭비, 인데, 자꾸, 보, 게, 됨]</td>\n",
       "      <td>[시간, 을, 정하, 고, 해, 보, 세요]</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Q                   A  label  \\\n",
       "0                   12시 땡!          하루가 또 가네요.      0   \n",
       "1              1지망 학교 떨어졌어           위로해 드립니다.      0   \n",
       "2             3박4일 놀러가고 싶다         여행은 언제나 좋죠.      0   \n",
       "3          3박4일 정도 놀러가고 싶다         여행은 언제나 좋죠.      0   \n",
       "4                  PPL 심하네          눈살이 찌푸려지죠.      0   \n",
       "5                SD카드 망가졌어  다시 새로 사는 게 마음 편해요.      0   \n",
       "6                  SD카드 안돼  다시 새로 사는 게 마음 편해요.      0   \n",
       "7           SNS 맞팔 왜 안하지ㅠㅠ    잘 모르고 있을 수도 있어요.      0   \n",
       "8  SNS 시간낭비인 거 아는데 매일 하는 중       시간을 정하고 해보세요.      0   \n",
       "9        SNS 시간낭비인데 자꾸 보게됨       시간을 정하고 해보세요.      0   \n",
       "\n",
       "                 Q_cleaned            A_cleaned  \\\n",
       "0                    시 땡            하루가 또 가네요     \n",
       "1               지망 학교 떨어졌어           위로해 드립니다     \n",
       "2              박 일 놀러가고 싶다         여행은 언제나 좋죠     \n",
       "3           박 일 정도 놀러가고 싶다         여행은 언제나 좋죠     \n",
       "4                  ppl 심하네          눈살이 찌푸려지죠     \n",
       "5                sd카드 망가졌어  다시 새로 사는 게 마음 편해요     \n",
       "6                  sd카드 안돼  다시 새로 사는 게 마음 편해요     \n",
       "7            sns 맞팔 왜 안하지     잘 모르고 있을 수도 있어요     \n",
       "8  sns 시간낭비인 거 아는데 매일 하는 중       시간을 정하고 해보세요     \n",
       "9        sns 시간낭비인데 자꾸 보게됨       시간을 정하고 해보세요     \n",
       "\n",
       "                               Q_tokenized                    A_tokenized  \\\n",
       "0                                   [시, 땡]              [하루, 가, 또, 가, 네요]   \n",
       "1                         [지망, 학교, 떨어졌, 어]                  [위로, 해, 드립니다]   \n",
       "2                 [박, 일, 놀, 러, 가, 고, 싶, 다]             [여행, 은, 언제나, 좋, 죠]   \n",
       "3             [박, 일, 정도, 놀, 러, 가, 고, 싶, 다]             [여행, 은, 언제나, 좋, 죠]   \n",
       "4                             [ppl, 심하, 네]             [눈살, 이, 찌푸려, 지, 죠]   \n",
       "5                         [sd, 카드, 망가졌, 어]     [다시, 새로, 사, 는, 게, 마음, 편해요]   \n",
       "6                           [sd, 카드, 안, 돼]     [다시, 새로, 사, 는, 게, 마음, 편해요]   \n",
       "7                  [sns, 맞, 팔, 왜, 안, 하, 지]  [잘, 모르, 고, 있, 을, 수, 도, 있, 어요]   \n",
       "8  [sns, 시간, 낭비, 인, 거, 아, 는데, 매일, 하, 는, 중]       [시간, 을, 정하, 고, 해, 보, 세요]   \n",
       "9           [sns, 시간, 낭비, 인데, 자꾸, 보, 게, 됨]       [시간, 을, 정하, 고, 해, 보, 세요]   \n",
       "\n",
       "   Q_length  A_length  \n",
       "0         2         5  \n",
       "1         4         3  \n",
       "2         8         5  \n",
       "3         9         5  \n",
       "4         3         5  \n",
       "5         4         7  \n",
       "6         4         7  \n",
       "7         7         9  \n",
       "8        11         7  \n",
       "9         8         7  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "be0b5ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "cdf00cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_var(df, \"df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9dc694a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_var(\"df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6cc2b44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1535438a",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = df[\"Q_tokenized\"]\n",
    "answers = df[\"A_tokenized\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8ed8d6",
   "metadata": {},
   "source": [
    "# Step 4. Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72b2966",
   "metadata": {},
   "source": [
    "우리에게 주어진 데이터는 1만 개가량으로 적은 편에 속합니다.   \n",
    "이럴 때에 사용할 수 있는 테크닉을 배웠으니 활용해 봐야겠죠?   \n",
    "Lexical Substitution을 실제로 적용해 보도록 하겠습니다.  \n",
    "\n",
    "아래 링크를 참고하여 한국어로 사전 훈련된 Embedding 모델을 다운로드합니다.   \n",
    "Korean (w) 가 Word2Vec으로 학습한 모델이며 용량도 적당하므로 사이트에서 Korean (w)를 찾아 다운로드하고, ko.bin 파일을 얻으세요!  \n",
    "\n",
    "Kyubyong/wordvectors  \n",
    "\n",
    "다운로드한 모델을 활용해 데이터를 Augmentation 하세요! 앞서 정의한 lexical_sub() 함수를 참고하면 도움이 많이 될 겁니다.  \n",
    "\n",
    "Augmentation된 que_corpus 와 원본 ans_corpus 가 병렬을 이루도록,   \n",
    "이후엔 반대로 원본 que_corpus 와 Augmentation된 ans_corpus 가 병렬을 이루도록 하여 전체 데이터가 원래의 3배가량으로 늘어나도록 합니다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa48ad72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4edd390d",
   "metadata": {},
   "outputs": [],
   "source": [
    "wv = Word2Vec.load(\"./data/word2vec_ko.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3195b444",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lexical_sub(sentence, wv, sentence_num=2):\n",
    "    sentences = []\n",
    "    for _ in range(sentence_num):\n",
    "        sentences.append(\" \".join(sentence).split())\n",
    "    \n",
    "    if not sentences[0]: return None\n",
    "    \n",
    "    indices = list(range(len(sentences[0])))\n",
    "    random.shuffle(indices)\n",
    "    unique_indices = indices[:sentence_num]\n",
    "\n",
    "    for i, index in enumerate(unique_indices):\n",
    "        word = sentences[i][index]\n",
    "        if word in wv:\n",
    "            similar_word = wv.most_similar(word)\n",
    "            if not similar_word:\n",
    "                return None\n",
    "\n",
    "            word_sub = similar_word[0][0]\n",
    "            sentences[i][index] = word_sub\n",
    "    \n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d98d6ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "338347a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29d0bb5b342e4bef9783e8b7e809a79f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11687 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "corpus_aug = []\n",
    "count_none = 0\n",
    "\n",
    "for que, ans in tqdm(zip(questions, answers), total=len(questions)):\n",
    "    corpus_aug.append((que, ans))\n",
    "    sentences = lexical_sub(que, wv.wv, sentence_num=2)\n",
    "    for sentence in sentences:\n",
    "        if sentence is not None: \n",
    "            corpus_aug.append((sentence, ans))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7c988118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35061\n",
      " 0 ['시', '땡']\n",
      " 1 ['시', '돌이']\n",
      " 2 ['시경', '땡']\n",
      " 3 ['지망', '학교', '떨어졌', '어']\n",
      " 4 ['지망', '학교', '올라갔', '어']\n",
      " 5 ['지망', '학교', '떨어졌', '어서']\n",
      " 6 ['박', '일', '놀', '러', '가', '고', '싶', '다']\n",
      " 7 ['김', '일', '놀', '러', '가', '고', '싶', '다']\n",
      " 8 ['박', '일', '울', '러', '가', '고', '싶', '다']\n",
      " 9 ['박', '일', '정도', '놀', '러', '가', '고', '싶', '다']\n",
      "10 ['박', '일', '정도', '울', '러', '가', '고', '싶', '다']\n",
      "11 ['박', '일', '만큼', '놀', '러', '가', '고', '싶', '다']\n"
     ]
    }
   ],
   "source": [
    "print(len(corpus_aug))\n",
    "for index, sentence in enumerate(corpus_aug):\n",
    "    print(f\"{index:2}\", sentence[0])\n",
    "    if index > 10: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c62ac905",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_var(corpus_aug, \"corpus_aug_x3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "306d503a",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_aug = load_var(\"corpus_aug_x3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73123127",
   "metadata": {},
   "source": [
    "# Step 5. 데이터 벡터화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9dd3c35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<start>', '12', '시', '땡', '!', '<end>']\n"
     ]
    }
   ],
   "source": [
    "sample_data = [\"12\", \"시\", \"땡\", \"!\"]\n",
    "\n",
    "print([\"<start>\"] + sample_data + [\"<end>\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551e6af6",
   "metadata": {},
   "source": [
    "1. 위 소스를 참고하여 타겟 데이터 전체에 <start> 토큰과 <end> 토큰을 추가해 주세요!   \n",
    "\n",
    "챗봇 훈련 데이터의 가장 큰 특징 중 하나라고 하자면 바로 소스 데이터와 타겟 데이터가 같은 언어를 사용한다는 것이겠죠.  \n",
    "앞서 배운 것처럼 이는 Embedding 층을 공유했을 때 많은 이점을 얻을 수 있습니다.  \n",
    "\n",
    "2. 특수 토큰을 더함으로써 ans_corpus 또한 완성이 되었으니, que_corpus 와 결합하여 전체 데이터에 대한 단어 사전을 구축하고 벡터화하여 enc_train 과 dec_train 을 얻으세요!  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d4966dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "que_corpus, ans_corpus = zip(*corpus_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f40b050f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corpus = pd.DataFrame({'questions': que_corpus, 'answers': ans_corpus})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "14df51db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corpus[\"questions\"] = df_corpus[\"questions\"].apply(tuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e8290f68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>questions</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(시, 땡)</td>\n",
       "      <td>[하루, 가, 또, 가, 네요]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(시, 돌이)</td>\n",
       "      <td>[하루, 가, 또, 가, 네요]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(시경, 땡)</td>\n",
       "      <td>[하루, 가, 또, 가, 네요]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  questions            answers\n",
       "0    (시, 땡)  [하루, 가, 또, 가, 네요]\n",
       "1   (시, 돌이)  [하루, 가, 또, 가, 네요]\n",
       "2   (시경, 땡)  [하루, 가, 또, 가, 네요]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_corpus.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8ff9b81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corpus = df_corpus.drop_duplicates(subset=\"questions\", keep=\"first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "168d910a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corpus_copy = df_corpus.copy()\n",
    "df_corpus_copy[\"questions\"] = df_corpus_copy[\"questions\"].apply(list)\n",
    "df_corpus = df_corpus.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "339cbda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "dae1b792",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corpus_copy = df_corpus.copy()\n",
    "df_corpus_copy[\"target_tokens\"] = [[\"<start>\"] + s + [\"<end>\"] for s in df_corpus_copy[\"answers\"]]\n",
    "df_corpus = df_corpus_copy.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "6157c759",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corpus[\"questions\"] = df_corpus[\"questions\"].apply(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "256c9c85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>questions</th>\n",
       "      <th>answers</th>\n",
       "      <th>target_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[시, 땡]</td>\n",
       "      <td>[하루, 가, 또, 가, 네요]</td>\n",
       "      <td>[&lt;start&gt;, 하루, 가, 또, 가, 네요, &lt;end&gt;]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[시, 돌이]</td>\n",
       "      <td>[하루, 가, 또, 가, 네요]</td>\n",
       "      <td>[&lt;start&gt;, 하루, 가, 또, 가, 네요, &lt;end&gt;]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[시경, 땡]</td>\n",
       "      <td>[하루, 가, 또, 가, 네요]</td>\n",
       "      <td>[&lt;start&gt;, 하루, 가, 또, 가, 네요, &lt;end&gt;]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  questions            answers                      target_tokens\n",
       "0    [시, 땡]  [하루, 가, 또, 가, 네요]  [<start>, 하루, 가, 또, 가, 네요, <end>]\n",
       "1   [시, 돌이]  [하루, 가, 또, 가, 네요]  [<start>, 하루, 가, 또, 가, 네요, <end>]\n",
       "2   [시경, 땡]  [하루, 가, 또, 가, 네요]  [<start>, 하루, 가, 또, 가, 네요, <end>]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_corpus.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "8650c9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corpus.to_csv(\"df_corpus_x3.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1bf2fb23",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corpus = pd.read_csv(\"df_corpus_x3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "1d702b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_var(df_corpus, \"df_corpus_x3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "64412afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corpus = load_var(\"df_corpus_x3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "922f2a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_corpus = df_corpus[\"questions\"].to_list() + df_corpus[\"target_tokens\"].to_list()\n",
    "\n",
    "tokenizer = Tokenizer(filters=\"\", lower=False, oov_token=\"<unk>\")\n",
    "tokenizer.fit_on_texts(total_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4f35dffc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8552"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "94f56d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "que_seqs = tokenizer.texts_to_sequences(df_corpus[\"questions\"])\n",
    "ans_seqs = tokenizer.texts_to_sequences(df_corpus[\"target_tokens\"])\n",
    "\n",
    "enc_train = pad_sequences(que_seqs, padding=\"post\")\n",
    "dec_train = pad_sequences(ans_seqs, padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "8ea00fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_var(enc_train, \"enc_train_x3\")\n",
    "save_var(dec_train, \"dec_train_x3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fe7d8117",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_train = load_var(\"enc_train\")\n",
    "dec_train = load_var(\"dec_train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "dffe4022",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((enc_train, dec_train)).batch(batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa9f3e2",
   "metadata": {},
   "source": [
    "# Step 6. 훈련하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405f8de5",
   "metadata": {},
   "source": [
    "## transformer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d3c1c9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def positional_encoding(pos, d_model):\n",
    "    def cal_angle(position, i):\n",
    "        return position / np.power(10000, (2*(i//2)) / np.float32(d_model))\n",
    "\n",
    "    def get_posi_angle_vec(position):\n",
    "        return [cal_angle(position, i) for i in range(d_model)]\n",
    "\n",
    "    sinusoid_table = np.array([get_posi_angle_vec(pos_i) for pos_i in range(pos)])\n",
    "\n",
    "    sinusoid_table[:, 0::2] = np.sin(sinusoid_table[:, 0::2])\n",
    "    sinusoid_table[:, 1::2] = np.cos(sinusoid_table[:, 1::2])\n",
    "\n",
    "    return sinusoid_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "673d2eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_padding_mask(seq):\n",
    "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "    return seq[:, tf.newaxis, tf.newaxis, :]\n",
    "\n",
    "def generate_lookahead_mask(size):\n",
    "    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
    "    return mask\n",
    "\n",
    "def generate_masks(src, tgt):\n",
    "    enc_mask = generate_padding_mask(src)\n",
    "    dec_enc_mask = generate_padding_mask(src)\n",
    "\n",
    "    dec_lookahead_mask = generate_lookahead_mask(tgt.shape[1])\n",
    "    dec_tgt_padding_mask = generate_padding_mask(tgt)\n",
    "    dec_mask = tf.maximum(dec_tgt_padding_mask, dec_lookahead_mask)\n",
    "\n",
    "    return enc_mask, dec_enc_mask, dec_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c405b072",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "        \n",
    "        self.depth = d_model // self.num_heads\n",
    "        \n",
    "        self.W_q = tf.keras.layers.Dense(d_model)\n",
    "        self.W_k = tf.keras.layers.Dense(d_model)\n",
    "        self.W_v = tf.keras.layers.Dense(d_model)\n",
    "        \n",
    "        self.linear = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "    def scaled_dot_product_attention(self, Q, K, V, mask):\n",
    "        d_k = tf.cast(K.shape[-1], tf.float32)\n",
    "        QK = tf.matmul(Q, K, transpose_b=True)\n",
    "\n",
    "        scaled_qk = QK / tf.math.sqrt(d_k)\n",
    "\n",
    "        if mask is not None: scaled_qk += (mask * -1e9)  \n",
    "\n",
    "        attentions = tf.nn.softmax(scaled_qk, axis=-1)\n",
    "        out = tf.matmul(attentions, V)\n",
    "\n",
    "        return out, attentions\n",
    "        \n",
    "\n",
    "    def split_heads(self, x):\n",
    "        bsz = x.shape[0]\n",
    "        split_x = tf.reshape(x, (bsz, -1, self.num_heads, self.depth))\n",
    "        split_x = tf.transpose(split_x, perm=[0, 2, 1, 3])\n",
    "\n",
    "        return split_x\n",
    "\n",
    "    def combine_heads(self, x):\n",
    "        bsz = x.shape[0]\n",
    "        combined_x = tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "        combined_x = tf.reshape(combined_x, (bsz, -1, self.d_model))\n",
    "\n",
    "        return combined_x\n",
    "\n",
    "    \n",
    "    def call(self, Q, K, V, mask):\n",
    "        WQ = self.W_q(Q)\n",
    "        WK = self.W_k(K)\n",
    "        WV = self.W_v(V)\n",
    "        \n",
    "        WQ_splits = self.split_heads(WQ)\n",
    "        WK_splits = self.split_heads(WK)\n",
    "        WV_splits = self.split_heads(WV)\n",
    "        \n",
    "        out, attention_weights = self.scaled_dot_product_attention(\n",
    "            WQ_splits, WK_splits, WV_splits, mask)\n",
    "                        \n",
    "        out = self.combine_heads(out)\n",
    "        out = self.linear(out)\n",
    "            \n",
    "        return out, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fdbd927f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PoswiseFeedForwardNet(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, d_ff):\n",
    "        super(PoswiseFeedForwardNet, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.d_ff = d_ff\n",
    "\n",
    "        self.fc1 = tf.keras.layers.Dense(d_ff, activation='relu')\n",
    "        self.fc2 = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "    def call(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.fc2(out)\n",
    "            \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f717ca4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, n_heads, d_ff, dropout):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "\n",
    "        self.enc_self_attn = MultiHeadAttention(d_model, n_heads)\n",
    "        self.ffn = PoswiseFeedForwardNet(d_model, d_ff)\n",
    "\n",
    "        self.norm_1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.norm_2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.do = tf.keras.layers.Dropout(dropout)\n",
    "        \n",
    "    def call(self, x, mask):\n",
    "        '''\n",
    "        Multi-Head Attention\n",
    "        '''\n",
    "        residual = x\n",
    "        out = self.norm_1(x)\n",
    "        out, enc_attn = self.enc_self_attn(out, out, out, mask)\n",
    "        out = self.do(out)\n",
    "        out += residual\n",
    "        \n",
    "        '''\n",
    "        Position-Wise Feed Forward Network\n",
    "        '''\n",
    "        residual = out\n",
    "        out = self.norm_2(out)\n",
    "        out = self.ffn(out)\n",
    "        out = self.do(out)\n",
    "        out += residual\n",
    "        \n",
    "        return out, enc_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0a27e20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "\n",
    "        self.dec_self_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.enc_dec_attn = MultiHeadAttention(d_model, num_heads)\n",
    "\n",
    "        self.ffn = PoswiseFeedForwardNet(d_model, d_ff)\n",
    "\n",
    "        self.norm_1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.norm_2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.norm_3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.do = tf.keras.layers.Dropout(dropout)\n",
    "    \n",
    "    def call(self, x, enc_out, dec_enc_mask, padding_mask):\n",
    "        '''\n",
    "        Masked Multi-Head Attention\n",
    "        '''\n",
    "        residual = x\n",
    "        out = self.norm_1(x)\n",
    "        out, dec_attn = self.dec_self_attn(out, out, out, padding_mask)\n",
    "        out = self.do(out)\n",
    "        out += residual\n",
    "\n",
    "        '''\n",
    "        Multi-Head Attention\n",
    "        '''\n",
    "        residual = out\n",
    "        out = self.norm_2(out)\n",
    "        # Q, K, V 순서에 주의하세요!\n",
    "        out, dec_enc_attn = self.enc_dec_attn(Q=out, K=enc_out, V=enc_out, mask=dec_enc_mask)\n",
    "        out = self.do(out)\n",
    "        out += residual\n",
    "        \n",
    "        '''\n",
    "        Position-Wise Feed Forward Network\n",
    "        '''\n",
    "        residual = out\n",
    "        out = self.norm_3(out)\n",
    "        out = self.ffn(out)\n",
    "        out = self.do(out)\n",
    "        out += residual\n",
    "\n",
    "        return out, dec_attn, dec_enc_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4e05d1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self,\n",
    "                    n_layers,\n",
    "                    d_model,\n",
    "                    n_heads,\n",
    "                    d_ff,\n",
    "                    dropout):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.enc_layers = [EncoderLayer(d_model, n_heads, d_ff, dropout) \n",
    "                        for _ in range(n_layers)]\n",
    "    \n",
    "        self.do = tf.keras.layers.Dropout(dropout)\n",
    "        \n",
    "    def call(self, x, mask):\n",
    "        out = x\n",
    "    \n",
    "        enc_attns = list()\n",
    "        for i in range(self.n_layers):\n",
    "            out, enc_attn = self.enc_layers[i](out, mask)\n",
    "            enc_attns.append(enc_attn)\n",
    "        \n",
    "        return out, enc_attns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "002cab48",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self,\n",
    "                    n_layers,\n",
    "                    d_model,\n",
    "                    n_heads,\n",
    "                    d_ff,\n",
    "                    dropout):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.dec_layers = [DecoderLayer(d_model, n_heads, d_ff, dropout) \n",
    "                            for _ in range(n_layers)]\n",
    "                            \n",
    "    def call(self, x, enc_out, dec_enc_mask, padding_mask):\n",
    "        out = x\n",
    "    \n",
    "        dec_attns = list()\n",
    "        dec_enc_attns = list()\n",
    "        for i in range(self.n_layers):\n",
    "            out, dec_attn, dec_enc_attn = \\\n",
    "            self.dec_layers[i](out, enc_out, dec_enc_mask, padding_mask)\n",
    "\n",
    "            dec_attns.append(dec_attn)\n",
    "            dec_enc_attns.append(dec_enc_attn)\n",
    "\n",
    "        return out, dec_attns, dec_enc_attns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "651d28e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "    def __init__(self,\n",
    "                    n_layers,\n",
    "                    d_model,\n",
    "                    n_heads,\n",
    "                    d_ff,\n",
    "                    src_vocab_size,\n",
    "                    tgt_vocab_size,\n",
    "                    pos_len,\n",
    "                    dropout=0.2,\n",
    "                    shared_fc=True,\n",
    "                    shared_emb=False):\n",
    "        super(Transformer, self).__init__()\n",
    "        \n",
    "        self.d_model = tf.cast(d_model, tf.float32)\n",
    "\n",
    "        if shared_emb:\n",
    "            self.enc_emb = self.dec_emb = \\\n",
    "            tf.keras.layers.Embedding(src_vocab_size, d_model)\n",
    "        else:\n",
    "            self.enc_emb = tf.keras.layers.Embedding(src_vocab_size, d_model)\n",
    "            self.dec_emb = tf.keras.layers.Embedding(tgt_vocab_size, d_model)\n",
    "\n",
    "        self.pos_encoding = positional_encoding(pos_len, d_model)\n",
    "        self.do = tf.keras.layers.Dropout(dropout)\n",
    "\n",
    "        self.encoder = Encoder(n_layers, d_model, n_heads, d_ff, dropout)\n",
    "        self.decoder = Decoder(n_layers, d_model, n_heads, d_ff, dropout)\n",
    "\n",
    "        self.fc = tf.keras.layers.Dense(tgt_vocab_size)\n",
    "\n",
    "        self.shared_fc = shared_fc\n",
    "\n",
    "        if shared_fc:\n",
    "            self.fc.set_weights(tf.transpose(self.dec_emb.weights))\n",
    "\n",
    "    def embedding(self, emb, x):\n",
    "        seq_len = x.shape[1]\n",
    "\n",
    "        out = emb(x)\n",
    "\n",
    "        if self.shared_fc: out *= tf.math.sqrt(self.d_model)\n",
    "\n",
    "        out += self.pos_encoding[np.newaxis, ...][:, :seq_len, :]\n",
    "        out = self.do(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "        \n",
    "    def call(self, enc_in, dec_in, enc_mask, dec_enc_mask, dec_mask):\n",
    "        enc_in = self.embedding(self.enc_emb, enc_in)\n",
    "        dec_in = self.embedding(self.dec_emb, dec_in)\n",
    "\n",
    "        enc_out, enc_attns = self.encoder(enc_in, enc_mask)\n",
    "        \n",
    "        dec_out, dec_attns, dec_enc_attns = \\\n",
    "        self.decoder(dec_in, enc_out, dec_enc_mask, dec_mask)\n",
    "        \n",
    "        logits = self.fc(dec_out)\n",
    "        \n",
    "        return logits, enc_attns, dec_attns, dec_enc_attns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "811858f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model = 512\n",
    "\n",
    "transformer = Transformer(\n",
    "    n_layers=2,\n",
    "    d_model=d_model,\n",
    "    n_heads=8,\n",
    "    d_ff=2048,\n",
    "    src_vocab_size=vocab_size,\n",
    "    tgt_vocab_size=vocab_size,\n",
    "    pos_len=200,\n",
    "    dropout=0.3,\n",
    "    shared_fc=True,\n",
    "    shared_emb=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "78530857",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fc8cfd9c550>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer.load_weights(\"t1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e960625",
   "metadata": {},
   "source": [
    "## LearningRateScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ac8b8b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LearningRateScheduler(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(LearningRateScheduler, self).__init__()\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.warmup_steps = warmup_steps\n",
    "    \n",
    "    def __call__(self, step):\n",
    "        arg1 = step ** -0.5\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "        \n",
    "        return (self.d_model ** -0.5) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "be3d6d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = LearningRateScheduler(d_model)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate,\n",
    "                                        beta_1=0.9,\n",
    "                                        beta_2=0.98, \n",
    "                                        epsilon=1e-9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849561b4",
   "metadata": {},
   "source": [
    "## Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a58b2bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_sum(loss_)/tf.reduce_sum(mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddbe93e1",
   "metadata": {},
   "source": [
    "## Train Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "faee2b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function()\n",
    "def train_step(src, tgt, model, optimizer):\n",
    "    tgt_in = tgt[:, :-1]  # Decoder의 input\n",
    "    gold = tgt[:, 1:]     # Decoder의 output과 비교하기 위해 right shift를 통해 생성한 최종 타겟\n",
    "\n",
    "    enc_mask, dec_enc_mask, dec_mask = generate_masks(src, tgt_in)\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions, enc_attns, dec_attns, dec_enc_attns = \\\n",
    "        model(src, tgt_in, enc_mask, dec_enc_mask, dec_mask)\n",
    "        loss = loss_function(gold, predictions)\n",
    "\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)    \n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    return loss, enc_attns, dec_attns, dec_enc_attns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664dda26",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "97c27007",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "e0a8a204",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99da4bf9ebf44790a49c240170d3a23b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/266 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss 1196.5056\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f17f91abde5b45b09df289752340e2e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/266 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Loss 770.8915\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce0ffbbb22834a23882928fbb5a832b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/266 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Loss 515.7512\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e38dd708f6842d0ac8e9134359932ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/266 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Loss 332.1277\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "774ec1967ba646df9175f669d6738b97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/266 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Loss 218.5047\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f64dea52c364f7480976144434c6bc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/266 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Loss 153.2797\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0eb062c8d8042dab1c8390a1098b1ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/266 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 Loss 111.0792\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "064b8cde145746e8b5702462cab6a034",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/266 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 Loss 87.3231\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f35481d603a494280b38f1afcaad48b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/266 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 Loss 69.9488\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5989037f6f6646d79e6b1453ca404bbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/266 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 Loss 60.6576\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9057520c52346d883003005ea645753",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/266 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 Loss 51.1698\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65bddacdbf3446179224849a6e3e8935",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/266 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 Loss 46.3578\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b16bde33b7b04e6782d82d59ea3c94be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/266 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 Loss 41.0188\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a214573a95c14ad795cb1bc321df1e16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/266 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 Loss 36.5912\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d936fc8afb614df696bdbc13aa42bdf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/266 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 Loss 34.5296\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "424aeaac0b134455bae360e389aa9ce3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/266 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 Loss 31.8692\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e32827adf214019ba99817f9c1f8fd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/266 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 Loss 30.5557\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d1b332135ee4052bddfb8cf0e83abbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/266 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 Loss 27.7971\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ea300795d2e4fa58112d5f03224cca0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/266 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 Loss 26.0217\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f43c8775586b41818ca2e1ef4c84121c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/266 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 Loss 24.4262\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 20\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    total_loss = 0\n",
    "    \n",
    "    dataset_count = tf.data.experimental.cardinality(train_dataset).numpy()\n",
    "    tqdm_bar = tqdm(total=dataset_count)\n",
    "    \n",
    "    for (src, tgt) in train_dataset:\n",
    "        loss, enc_attns, dec_attns, dec_enc_attns = train_step(src, tgt, transformer, optimizer)\n",
    "        total_loss += loss\n",
    "        tqdm_bar.set_description(f'Epoch {epoch + 1} Loss {total_loss.numpy():.4f}')\n",
    "        tqdm_bar.update()\n",
    "    tqdm_bar.close()\n",
    "    losses.append(total_loss.numpy())\n",
    "    print(f'Epoch {epoch + 1} Loss {total_loss.numpy():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "3b4a2579",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"t3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "a29a0c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer.save_weights(prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "ca56f5b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1196.5056, 770.89154, 515.7512, 332.12772, 218.50471, 153.27972, 111.07922, 87.32306, 69.94883, 60.657585, 51.169834, 46.357754, 41.018753, 36.591194, 34.529594, 31.869173, 30.55571, 27.797064, 26.021723, 24.426159]\n"
     ]
    }
   ],
   "source": [
    "print(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "39c2bc9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "histories = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "e22a07ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "histories[prefix] = losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "6bc067dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_var(histories, \"histories\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "9e6613b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "histories = load_var(\"histories\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "b3709ad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'t0': [3832.5205, 2699.2415, 2176.4763], 't2': [3019.052, 2088.4956, 1682.1465, 1293.043, 1016.2196, 890.7383, 821.02826, 798.14386, 676.56366, 530.8138, 422.03873, 345.6523, 292.3675, 251.544, 222.10175, 192.92442, 169.73122, 149.50732, 134.93729, 118.146194], 't3': [1196.5056, 770.89154, 515.7512, 332.12772, 218.50471, 153.27972, 111.07922, 87.32306, 69.94883, 60.657585, 51.169834, 46.357754, 41.018753, 36.591194, 34.529594, 31.869173, 30.55571, 27.797064, 26.021723, 24.426159]}\n"
     ]
    }
   ],
   "source": [
    "print(histories)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68ffaec",
   "metadata": {},
   "source": [
    "- t0: base. 3 epochs\n",
    "- t1: 20 epochs\n",
    "- t2: data aug. x4 --> x3\n",
    "- t3: batch size. 64 --> 128"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8476017",
   "metadata": {},
   "source": [
    "# Step 7. 성능 측정하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445aa802",
   "metadata": {},
   "source": [
    "주어진 질문에 적절한 답변을 하는지 확인하고, BLEU Score를 계산하는 calculate_bleu() 함수도 적용해 보세요."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93833fc",
   "metadata": {},
   "source": [
    "```\n",
    "# 예문\n",
    "1. 지루하다, 놀러가고 싶어.\n",
    "2. 오늘 일찍 일어났더니 피곤하다.\n",
    "3. 간만에 여자친구랑 데이트 하기로 했어.\n",
    "4. 집에 있는다는 소리야.\n",
    "\n",
    "---\n",
    "\n",
    "# 제출\n",
    "\n",
    "Translations\n",
    "> 1. 잠깐 쉬 어도 돼요 . <end>\n",
    "> 2. 맛난 거 드세요 . <end>\n",
    "> 3. 떨리 겠 죠 . <end>\n",
    "> 4. 좋 아 하 면 그럴 수 있 어요 . <end>\n",
    "\n",
    "Hyperparameters\n",
    "> n_layers: 1\n",
    "> d_model: 368\n",
    "> n_heads: 8\n",
    "> d_ff: 1024\n",
    "> dropout: 0.2\n",
    "\n",
    "Training Parameters\n",
    "> Warmup Steps: 1000\n",
    "> Batch Size: 64\n",
    "> Epoch At: 10\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "cc95cc17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(text_tokens, model, tokenizer):\n",
    "    print(f\"- {text_tokens}\")\n",
    "    seq_tokens = tokenizer.texts_to_sequences(text_tokens)\n",
    "    padded_tokens = pad_sequences(seq_tokens, padding=\"post\")\n",
    "    \n",
    "    ids = []\n",
    "    output = tf.expand_dims([tokenizer.word_index['<start>']], 0)   \n",
    "    for i in range(vocab_size):\n",
    "        enc_padding_mask, combined_mask, dec_padding_mask = generate_masks(padded_tokens, output)\n",
    "\n",
    "        predictions, _, _, _ = model(padded_tokens,\n",
    "                                     output,\n",
    "                                     enc_padding_mask,\n",
    "                                     combined_mask,\n",
    "                                     dec_padding_mask)\n",
    "\n",
    "        predicted_id = tf.argmax(\n",
    "            tf.math.softmax(predictions, axis=-1)[0, -1]).numpy().item()\n",
    "\n",
    "        if tokenizer.word_index['<end>'] == predicted_id:\n",
    "            result = ' '.join(tokenizer.sequences_to_texts([ids]))\n",
    "            return result\n",
    "\n",
    "        ids.append(predicted_id)\n",
    "        output = tf.concat([output, tf.expand_dims([predicted_id], 0)], axis=-1)\n",
    "\n",
    "    result = ' '.join(tokenizer.sequences_to_texts([ids]))\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "f5687ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_bleu_single(model, src_sentence, tgt_sentence, tokenizer, verbose=True):\n",
    "    \n",
    "#     print(f\"src: {src_sentence}\")\n",
    "#     print(f\"tgt: {tgt_sentence}\")\n",
    "\n",
    "    reference = tgt_sentence\n",
    "    candidate = translate(src_sentence, model, tokenizer).split()\n",
    "\n",
    "    score = sentence_bleu([reference], candidate,\n",
    "                          smoothing_function=SmoothingFunction().method1)\n",
    "\n",
    "    if verbose:\n",
    "        # print(\"Source Sentence: \", src_sentence)\n",
    "        print(\"Model Prediction: \", \" \".join(candidate))\n",
    "        print(\"Real: \", \" \".join(reference))\n",
    "        print(\"Score: %lf\\n\" % score)\n",
    "        \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "83f5c1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_bleu(model, src_sentences, tgt_sentences, tokenizer, verbose=True):\n",
    "    total_score = 0.0\n",
    "    sample_size = len(src_sentences)\n",
    "    \n",
    "    for idx in tqdm(range(sample_size)):\n",
    "        src = \" \".join(src_sentences[idx])\n",
    "        tgt = tgt_sentences[idx]\n",
    "        score = eval_bleu_single(model, src, tgt, tokenizer, verbose)\n",
    "        if not score: continue\n",
    "        \n",
    "        total_score += score\n",
    "    \n",
    "    print(\"Num of Sample:\", sample_size)\n",
    "    print(\"Total Score:\", total_score / sample_size)\n",
    "    \n",
    "    return total_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f2657d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_questions = [\"지루하다, 놀러가고 싶어.\",\n",
    "                  \"오늘 일찍 일어났더니 피곤하다.\",\n",
    "                  \"간만에 여자친구랑 데이트 하기로 했어.\",\n",
    "                  \"집에 있는다는 소리야.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "05cc31a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['지루', '하', '다', '놀', '러', '가', '고', '싶', '어'],\n",
       " ['오늘', '일찍', '일어났', '더니', '피곤', '하', '다'],\n",
       " ['간만에', '여자', '친구', '랑', '데이트', '하', '기', '로', '했', '어'],\n",
       " ['집', '에', '있', '는다는', '소리야']]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_questions = cleaner.clean_corpus(test_questions)\n",
    "test_questions = get_tokenized_corpus(test_questions, mecab)\n",
    "test_questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ae084bbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[36721, 29576, 41665, 34028, 29759, 29952, 4288, 8121, 21349, 42258]\n"
     ]
    }
   ],
   "source": [
    "random_indices = random.sample(range(0, df_corpus.shape[0] + 1), 10)\n",
    "print(random_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "2f6c4354",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 헤어지 고 난 뒤 애인\n",
      "Source Sentence:  헤어지 고 난 뒤 애인\n",
      "Model Prediction:  ['만나', '길', '바라', '요']\n",
      "Real:  ['<start>', '친구', '가', '되', '기', '쉽', '지', '않', '을', '거', '예요', '<end>']\n",
      "Score: 0.000000\n",
      "\n",
      "- 소개팅 하 고 애프터 까지 왔 지만 설렘 이 있 어\n",
      "Source Sentence:  소개팅 하 고 애프터 까지 왔 지만 설렘 이 있 어\n",
      "Model Prediction:  ['썸', '은', '사이', '가', '는', '사이', '가', '좋', '은', '일', '이', '에요']\n",
      "Real:  ['<start>', '조금', '더', '만나', '보', '고', '결정', '하', '는', '건', '어떨까', '요', '<end>']\n",
      "Score: 0.015671\n",
      "\n",
      "- 은 남자 맘 이 뭔지\n",
      "Source Sentence:  은 남자 맘 이 뭔지\n",
      "Model Prediction:  ['운명', '입니다']\n",
      "Real:  ['<start>', '사람', '맘', '은', '알', '길', '이', '없', '어요', '<end>']\n",
      "Score: 0.000000\n",
      "\n",
      "- 나가 이 멍청 한 거 지\n",
      "Source Sentence:  나가 이 멍청 한 거 지\n",
      "Model Prediction:  ['운명', '은', '사람', '은', '모두', '사람', '은', '모두', '모두', '모두', '모두', '말', '은', '거', '예요']\n",
      "Real:  ['<start>', '실수', '했', '나요', '<end>']\n",
      "Score: 0.000000\n",
      "\n",
      "- 년 동거 후 이별 개월 차\n",
      "Source Sentence:  년 동거 후 이별 개월 차\n",
      "Model Prediction:  ['많', '은', '시기', '네요']\n",
      "Real:  ['<start>', '생각', '을', '오래', '하', '면', '더욱', '지칠', '수', '있', '어요', '<end>']\n",
      "Score: 0.000000\n",
      "\n",
      "- 나 자체 을 사랑 해 줄 사람 이 있 습니까\n",
      "Source Sentence:  나 자체 을 사랑 해 줄 사람 이 있 습니까\n",
      "Model Prediction:  ['운명', '은', '사람', '은', '모두', '사람', '은', '모두', '모두', '모두', '모두', '말', '은', '거', '예요']\n",
      "Real:  ['<start>', '잘', '찾아보', '세요', '<end>']\n",
      "Score: 0.000000\n",
      "\n",
      "- 대체 불가 한 사람 이 되 고 싶 어\n",
      "Source Sentence:  대체 불가 한 사람 이 되 고 싶 어\n",
      "Model Prediction:  ['궁금', '하', '네요']\n",
      "Real:  ['<start>', '지금', '도', '그래요', '<end>']\n",
      "Score: 0.000000\n",
      "\n",
      "- 삶 살만 해서\n",
      "Source Sentence:  삶 살만 해서\n",
      "Model Prediction:  ['당신', '이', '답', '을', '수', '있', '어요']\n",
      "Real:  ['<start>', '누구', '나', '한', '번', '쯤', '시도', '해', '볼', '만', '하', '죠', '<end>']\n",
      "Score: 0.000000\n",
      "\n",
      "- 여자 친구 이 너무 챙 김 받 고 싶 어 해서\n",
      "Source Sentence:  여자 친구 이 너무 챙 김 받 고 싶 어 해서\n",
      "Model Prediction:  ['이성', '으로', '어필', '을', '어필', '해', '보', '세요']\n",
      "Real:  ['<start>', '사랑', '을', '더', '받', '고', '싶', '은', '가', '봐요', '<end>']\n",
      "Score: 0.019090\n",
      "\n",
      "- 양배추 찹쌀 최악\n",
      "Source Sentence:  양배추 찹쌀 최악\n",
      "Model Prediction:  ['제일', '방법', '이', '에요']\n",
      "Real:  ['<start>', '먹', '으면서', '다이어트', '하', '는', '분', '들', '진짜', '엄청', '대단', '한', '분', '들', '이', '에요', '<end>']\n",
      "Score: 0.006588\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for index in random_indices:\n",
    "    score = eval_bleu_single(transformer, \n",
    "                             \" \".join(df_corpus[\"questions\"].iloc[index]), \n",
    "                             df_corpus[\"target_tokens\"].iloc[index], \n",
    "                             tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "48fa9d9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19887, 25117, 4751, 11536, 32518, 12289, 16228, 30753, 3071, 19636, 15279, 17286, 23372, 31889, 16128, 16251, 21496, 4810, 10209, 19640, 30521, 30755, 28950, 5745, 16428, 33118, 19186, 22832, 25003, 23917, 29354, 12166, 18510, 21926, 21459, 25451, 32723, 13335, 33961, 31754, 14060, 11450, 31338, 5407, 26082, 19355, 33939, 4867, 18802, 15227, 1054, 28991, 8533, 18598, 30611, 20774, 31750, 16288, 31268, 25220, 23542, 10263, 26795, 10794, 20061, 14970, 24938, 11862, 21991, 13521, 31883, 11387, 13652, 7556, 13665, 6502, 6366, 27152, 18332, 31448, 8207, 14931, 7575, 11242, 416, 23118, 21411, 7583, 1578, 21383, 2508, 9024, 11699, 24074, 15056, 25251, 12799, 8536, 540, 11955]\n"
     ]
    }
   ],
   "source": [
    "indices_bleu = random.sample(range(0, df_corpus.shape[0] + 1), 100)\n",
    "print(indices_bleu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "9b4d6fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_sentences = list(df_corpus[\"questions\"].iloc[indices_bleu])\n",
    "tgt_sentences = list(df_corpus[\"answers\"].iloc[indices_bleu])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "d7147f22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['아', '벌', '받', '고', '있', '는', '건가', '네'], ['달', '게', '받', '으세요'])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_sentences[0], tgt_sentences[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58955ebe",
   "metadata": {},
   "source": [
    "### t0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a7869e",
   "metadata": {},
   "source": [
    "- n_layers: 2\n",
    "- d_model: 512\n",
    "- n_heads: 8\n",
    "- d_ff: 2048\n",
    "- dropout: 0.3\n",
    "- batch_size: 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "b782305c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 지루 하 다 놀 러 가 고 싶 어\n",
      "> 고백 하 게 고백 하 세요\n",
      "\n",
      "- 오늘 일찍 일어났 더니 피곤 하 다\n",
      "> 썸 이 에요\n",
      "\n",
      "- 간만에 여자 친구 랑 데이트 하 기 로 했 어\n",
      "> 다시 시작 이 되 겠 어요\n",
      "\n",
      "- 집 에 있 는다는 소리야\n",
      "> 축하 드려요\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for question in test_questions:\n",
    "    result = translate(\" \".join(question), transformer, tokenizer)\n",
    "    print(f\"> {result}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "13b1d187",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 오후 돌이\n",
      "Source Sentence:  오후 돌이\n",
      "Model Prediction:  ['썸', '이', '에요']\n",
      "Real:  ['하루', '가', '또', '가', '네요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 오후 순이\n",
      "Source Sentence:  오후 순이\n",
      "Model Prediction:  ['썸', '이', '에요']\n",
      "Real:  ['하루', '가', '또', '가', '네요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 오전 돌이\n",
      "Source Sentence:  오전 돌이\n",
      "Model Prediction:  ['썸', '이', '에요']\n",
      "Real:  ['하루', '가', '또', '가', '네요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 캐스터 여학교 떨어졌 어서\n",
      "Source Sentence:  캐스터 여학교 떨어졌 어서\n",
      "Model Prediction:  ['사랑', '은', '언제', '든', '시작', '이', '었', '으니까요']\n",
      "Real:  ['위로', '해', '드립니다']\n",
      "Score: 0.000000\n",
      "\n",
      "- 캐스터 여학교 떨어졌 어\n",
      "Source Sentence:  캐스터 여학교 떨어졌 어\n",
      "Model Prediction:  ['사랑', '은', '언제', '든', '시작', '이', '었', '으니까요']\n",
      "Real:  ['위로', '해', '드립니다']\n",
      "Score: 0.000000\n",
      "\n",
      "- 캐스터 소학교 떨어졌 어서\n",
      "Source Sentence:  캐스터 소학교 떨어졌 어서\n",
      "Model Prediction:  ['사랑', '은', '언제', '든', '시작', '이', '었', '으니까요']\n",
      "Real:  ['위로', '해', '드립니다']\n",
      "Score: 0.000000\n",
      "\n",
      "- 캐스터 여학교 올라갔 어서\n",
      "Source Sentence:  캐스터 여학교 올라갔 어서\n",
      "Model Prediction:  ['사랑', '은', '언제', '든', '시작', '이', '었', '으니까요']\n",
      "Real:  ['위로', '해', '드립니다']\n",
      "Score: 0.000000\n",
      "\n",
      "- 윤 월 놀 러 이 는데 싶 는데\n",
      "Source Sentence:  윤 월 놀 러 이 는데 싶 는데\n",
      "Model Prediction:  ['호감', '을', '표현', '하', '고', '있', '어요']\n",
      "Real:  ['여행', '은', '언제나', '좋', '죠']\n",
      "Score: 0.000000\n",
      "\n",
      "- 윤 월 놀 니 이 는데 싶 는데\n",
      "Source Sentence:  윤 월 놀 니 이 는데 싶 는데\n",
      "Model Prediction:  ['호감', '을', '표현', '하', '고', '있', '어요']\n",
      "Real:  ['여행', '은', '언제나', '좋', '죠']\n",
      "Score: 0.000000\n",
      "\n",
      "- 윤 월 놀 러 이 는데 싫 는데\n",
      "Source Sentence:  윤 월 놀 러 이 는데 싫 는데\n",
      "Model Prediction:  ['호감', '을', '표현', '하', '고', '있', '어요']\n",
      "Real:  ['여행', '은', '언제나', '좋', '죠']\n",
      "Score: 0.000000\n",
      "\n",
      "- 윤 월 놀 러 은 는데 싶 는데\n",
      "Source Sentence:  윤 월 놀 러 은 는데 싶 는데\n",
      "Model Prediction:  ['호감', '을', '표현', '하', '고', '있', '어요']\n",
      "Real:  ['여행', '은', '언제나', '좋', '죠']\n",
      "Score: 0.000000\n",
      "\n",
      "- 김 월 만큼 놀 거든 이 지만 싶 지만\n",
      "Source Sentence:  김 월 만큼 놀 거든 이 지만 싶 지만\n",
      "Model Prediction:  ['바라', '요']\n",
      "Real:  ['여행', '은', '언제나', '좋', '죠']\n",
      "Score: 0.000000\n",
      "\n",
      "- 김 월 만큼 놀 거든 은 지만 싶 지만\n",
      "Source Sentence:  김 월 만큼 놀 거든 은 지만 싶 지만\n",
      "Model Prediction:  ['바라', '요']\n",
      "Real:  ['여행', '은', '언제나', '좋', '죠']\n",
      "Score: 0.000000\n",
      "\n",
      "- 김 월 만큼 울 거든 이 지만 싶 지만\n",
      "Source Sentence:  김 월 만큼 울 거든 이 지만 싶 지만\n",
      "Model Prediction:  ['바라', '요']\n",
      "Real:  ['여행', '은', '언제나', '좋', '죠']\n",
      "Score: 0.000000\n",
      "\n",
      "- 윤 월 만큼 놀 거든 이 지만 싶 지만\n",
      "Source Sentence:  윤 월 만큼 놀 거든 이 지만 싶 지만\n",
      "Model Prediction:  ['호감', '을', '표현', '하', '고', '있', '어요']\n",
      "Real:  ['여행', '은', '언제나', '좋', '죠']\n",
      "Score: 0.000000\n",
      "\n",
      "- ppl 약하 다섯\n",
      "Source Sentence:  ppl 약하 다섯\n",
      "Model Prediction:  ['만나', '길', '바라', '요']\n",
      "Real:  ['눈살', '이', '찌푸려', '지', '죠']\n",
      "Score: 0.000000\n",
      "\n",
      "- ppl 강하 다섯\n",
      "Source Sentence:  ppl 강하 다섯\n",
      "Model Prediction:  ['만나', '길', '바라', '요']\n",
      "Real:  ['눈살', '이', '찌푸려', '지', '죠']\n",
      "Score: 0.000000\n",
      "\n",
      "- ppl 약하 여섯\n",
      "Source Sentence:  ppl 약하 여섯\n",
      "Model Prediction:  ['만나', '길', '바라', '요']\n",
      "Real:  ['눈살', '이', '찌푸려', '지', '죠']\n",
      "Score: 0.000000\n",
      "\n",
      "- cp 단말 아름다웠 어\n",
      "Source Sentence:  cp 단말 아름다웠 어\n",
      "Model Prediction:  ['슬픈', '이야기', '네요']\n",
      "Real:  ['다시', '새로', '사', '는', '게', '마음', '편해요']\n",
      "Score: 0.000000\n",
      "\n",
      "- perl 단말 아름다웠 어\n",
      "Source Sentence:  perl 단말 아름다웠 어\n",
      "Model Prediction:  ['만나', '길', '바라', '요']\n",
      "Real:  ['다시', '새로', '사', '는', '게', '마음', '편해요']\n",
      "Score: 0.000000\n",
      "\n",
      "- cp 단말 기뻐했 어\n",
      "Source Sentence:  cp 단말 기뻐했 어\n",
      "Model Prediction:  ['슬픈', '이야기', '네요']\n",
      "Real:  ['다시', '새로', '사', '는', '게', '마음', '편해요']\n",
      "Score: 0.000000\n",
      "\n",
      "- cp 모뎀 아름다웠 어\n",
      "Source Sentence:  cp 모뎀 아름다웠 어\n",
      "Model Prediction:  ['슬픈', '이야기', '네요']\n",
      "Real:  ['다시', '새로', '사', '는', '게', '마음', '편해요']\n",
      "Score: 0.000000\n",
      "\n",
      "- perl 모뎀 앞 됐으며\n",
      "Source Sentence:  perl 모뎀 앞 됐으며\n",
      "Model Prediction:  ['만나', '길', '바라', '요']\n",
      "Real:  ['다시', '새로', '사', '는', '게', '마음', '편해요']\n",
      "Score: 0.000000\n",
      "\n",
      "- perl 모뎀 앞 됐으나\n",
      "Source Sentence:  perl 모뎀 앞 됐으나\n",
      "Model Prediction:  ['만나', '길', '바라', '요']\n",
      "Real:  ['다시', '새로', '사', '는', '게', '마음', '편해요']\n",
      "Score: 0.000000\n",
      "\n",
      "- perl 모뎀 옆 됐으며\n",
      "Source Sentence:  perl 모뎀 옆 됐으며\n",
      "Model Prediction:  ['만나', '길', '바라', '요']\n",
      "Real:  ['다시', '새로', '사', '는', '게', '마음', '편해요']\n",
      "Score: 0.000000\n",
      "\n",
      "- cp 모뎀 앞 됐으며\n",
      "Source Sentence:  cp 모뎀 앞 됐으며\n",
      "Model Prediction:  ['슬픈', '이야기', '네요']\n",
      "Real:  ['다시', '새로', '사', '는', '게', '마음', '편해요']\n",
      "Score: 0.000000\n",
      "\n",
      "- casework 주저앉 팔 정말로 옆 하 당치\n",
      "Source Sentence:  casework 주저앉 팔 정말로 옆 하 당치\n",
      "Model Prediction:  ['슬픈', '이야기', '네요']\n",
      "Real:  ['잘', '모르', '고', '있', '을', '수', '도', '있', '어요']\n",
      "Score: 0.000000\n",
      "\n",
      "- casework 주저앉 빨 정말로 옆 하 당치\n",
      "Source Sentence:  casework 주저앉 빨 정말로 옆 하 당치\n",
      "Model Prediction:  ['슬픈', '이야기', '네요']\n",
      "Real:  ['잘', '모르', '고', '있', '을', '수', '도', '있', '어요']\n",
      "Score: 0.000000\n",
      "\n",
      "- casework 주저앉 팔 정말로 옆 시키 당치\n",
      "Source Sentence:  casework 주저앉 팔 정말로 옆 시키 당치\n",
      "Model Prediction:  ['슬픈', '이야기', '네요']\n",
      "Real:  ['잘', '모르', '고', '있', '을', '수', '도', '있', '어요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 케이스워크 주저앉 팔 정말로 옆 하 당치\n",
      "Source Sentence:  케이스워크 주저앉 팔 정말로 옆 하 당치\n",
      "Model Prediction:  ['다음', '부터', '는', '만큼', '더', '좋', '은', '선택', '이', '었', '길', '바라', '요']\n",
      "Real:  ['잘', '모르', '고', '있', '을', '수', '도', '있', '어요']\n",
      "Score: 0.000000\n",
      "\n",
      "- sns 분 절약 , 거 아 는데 아침 꾀하 은 중\n",
      "Source Sentence:  sns 분 절약 , 거 아 는데 아침 꾀하 은 중\n",
      "Model Prediction:  ['만나', '길', '바라', '요']\n",
      "Real:  ['시간', '을', '정하', '고', '해', '보', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- sns 분 절약 , 거 아 지만 아침 꾀하 은 중\n",
      "Source Sentence:  sns 분 절약 , 거 아 지만 아침 꾀하 은 중\n",
      "Model Prediction:  ['만나', '길', '바라', '요']\n",
      "Real:  ['시간', '을', '정하', '고', '해', '보', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- sns 초간 절약 , 거 아 는데 아침 꾀하 은 중\n",
      "Source Sentence:  sns 초간 절약 , 거 아 는데 아침 꾀하 은 중\n",
      "Model Prediction:  ['만나', '길', '바라', '요']\n",
      "Real:  ['시간', '을', '정하', '고', '해', '보', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- sns 분 절약 , 거 아 는데 아침 시키 은 중\n",
      "Source Sentence:  sns 분 절약 , 거 아 는데 아침 시키 은 중\n",
      "Model Prediction:  ['만나', '길', '바라', '요']\n",
      "Real:  ['시간', '을', '정하', '고', '해', '보', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 케이스워크 시간 조달 라면 혹시 알아채 게끔 이루어짐\n",
      "Source Sentence:  케이스워크 시간 조달 라면 혹시 알아채 게끔 이루어짐\n",
      "Model Prediction:  ['다음', '부터', '는', '만큼', '더', '좋', '은', '선택', '이', '었', '길', '바라', '요']\n",
      "Real:  ['시간', '을', '정하', '고', '해', '보', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 케이스워크 시간 조달 라면 누가 알아채 게끔 이루어짐\n",
      "Source Sentence:  케이스워크 시간 조달 라면 누가 알아채 게끔 이루어짐\n",
      "Model Prediction:  ['다음', '부터', '는', '만큼', '더', '좋', '은', '선택', '이', '었', '길', '바라', '요']\n",
      "Real:  ['시간', '을', '정하', '고', '해', '보', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 케이스워크 시간 조달 라면 혹시 알아채 게끔 들어옴\n",
      "Source Sentence:  케이스워크 시간 조달 라면 혹시 알아채 게끔 들어옴\n",
      "Model Prediction:  ['다음', '부터', '는', '만큼', '더', '좋', '은', '선택', '이', '었', '길', '바라', '요']\n",
      "Real:  ['시간', '을', '정하', '고', '해', '보', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 케이스워크 분 조달 라면 혹시 알아채 게끔 이루어짐\n",
      "Source Sentence:  케이스워크 분 조달 라면 혹시 알아채 게끔 이루어짐\n",
      "Model Prediction:  ['다음', '부터', '는', '만큼', '더', '좋', '은', '선택', '이', '었', '길', '바라', '요']\n",
      "Real:  ['시간', '을', '정하', '고', '해', '보', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 케이스워크 보 면 나 만 때리 는데 다 행복 해 보여\n",
      "Source Sentence:  케이스워크 보 면 나 만 때리 는데 다 행복 해 보여\n",
      "Model Prediction:  ['다음', '부터', '는', '만큼', '더', '좋', '은', '선택', '이', '었', '길', '바라', '요']\n",
      "Real:  ['자랑', '하', '는', '자리', '니까요']\n",
      "Score: 0.015537\n",
      "\n",
      "- 케이스워크 보 면 나 만 걷어차 는데 다 행복 해 보여\n",
      "Source Sentence:  케이스워크 보 면 나 만 걷어차 는데 다 행복 해 보여\n",
      "Model Prediction:  ['다음', '부터', '는', '만큼', '더', '좋', '은', '선택', '이', '었', '길', '바라', '요']\n",
      "Real:  ['자랑', '하', '는', '자리', '니까요']\n",
      "Score: 0.015537\n",
      "\n",
      "- 케이스워크 보 면 나 만 때리 는데 다 행복 해서 보여\n",
      "Source Sentence:  케이스워크 보 면 나 만 때리 는데 다 행복 해서 보여\n",
      "Model Prediction:  ['다음', '부터', '는', '만큼', '더', '좋', '은', '선택', '이', '었', '길', '바라', '요']\n",
      "Real:  ['자랑', '하', '는', '자리', '니까요']\n",
      "Score: 0.015537\n",
      "\n",
      "- 케이스워크 보 면 나 만 때리 는데 는데 행복 해 보여\n",
      "Source Sentence:  케이스워크 보 면 나 만 때리 는데 는데 행복 해 보여\n",
      "Model Prediction:  ['다음', '부터', '는', '만큼', '더', '좋', '은', '선택', '이', '었', '길', '바라', '요']\n",
      "Real:  ['자랑', '하', '는', '자리', '니까요']\n",
      "Score: 0.015537\n",
      "\n",
      "- 가끔 의아 해\n",
      "Source Sentence:  가끔 의아 해\n",
      "Model Prediction:  ['나', '를', '더', '나', '봐요']\n",
      "Real:  ['그', '사람', '도', '그럴', '거', '예요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 이따금 의아 해\n",
      "Source Sentence:  이따금 의아 해\n",
      "Model Prediction:  ['참', '은', '참', '기', '힘들', '게', '없', '어요']\n",
      "Real:  ['그', '사람', '도', '그럴', '거', '예요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가끔 흡족 해\n",
      "Source Sentence:  가끔 흡족 해\n",
      "Model Prediction:  ['나', '를', '더', '나', '봐요']\n",
      "Real:  ['그', '사람', '도', '그럴', '거', '예요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가끔 의아 해서\n",
      "Source Sentence:  가끔 의아 해서\n",
      "Model Prediction:  ['나', '를', '더', '나', '봐요']\n",
      "Real:  ['그', '사람', '도', '그럴', '거', '예요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가끔 뭐 꾀하 는지 의아 해\n",
      "Source Sentence:  가끔 뭐 꾀하 는지 의아 해\n",
      "Model Prediction:  ['나', '를', '더', '나', '봐요']\n",
      "Real:  ['그', '사람', '도', '그럴', '거', '예요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가끔 어쩌 꾀하 는지 의아 해\n",
      "Source Sentence:  가끔 어쩌 꾀하 는지 의아 해\n",
      "Model Prediction:  ['나', '를', '더', '나', '봐요']\n",
      "Real:  ['그', '사람', '도', '그럴', '거', '예요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가끔 뭐 시키 는지 의아 해\n",
      "Source Sentence:  가끔 뭐 시키 는지 의아 해\n",
      "Model Prediction:  ['나', '를', '더', '나', '봐요']\n",
      "Real:  ['그', '사람', '도', '그럴', '거', '예요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가끔 뭐 꾀하 는가 의아 해\n",
      "Source Sentence:  가끔 뭐 꾀하 는가 의아 해\n",
      "Model Prediction:  ['나', '를', '더', '나', '봐요']\n",
      "Real:  ['그', '사람', '도', '그럴', '거', '예요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가끔 은 혼자 의 게 좋 다\n",
      "Source Sentence:  가끔 은 혼자 의 게 좋 다\n",
      "Model Prediction:  ['나', '를', '더', '나', '봐요']\n",
      "Real:  ['혼자', '를', '즐기', '세요']\n",
      "Score: 0.053728\n",
      "\n",
      "- 가끔 은 혼자 의 도록 좋 다\n",
      "Source Sentence:  가끔 은 혼자 의 도록 좋 다\n",
      "Model Prediction:  ['나', '를', '더', '나', '봐요']\n",
      "Real:  ['혼자', '를', '즐기', '세요']\n",
      "Score: 0.053728\n",
      "\n",
      "- 가끔 은 거기 의 게 좋 다\n",
      "Source Sentence:  가끔 은 거기 의 게 좋 다\n",
      "Model Prediction:  ['나', '를', '더', '나', '봐요']\n",
      "Real:  ['혼자', '를', '즐기', '세요']\n",
      "Score: 0.053728\n",
      "\n",
      "- 가끔 은 혼자 의 게 좋 는데\n",
      "Source Sentence:  가끔 은 혼자 의 게 좋 는데\n",
      "Model Prediction:  ['나', '를', '더', '나', '봐요']\n",
      "Real:  ['혼자', '를', '즐기', '세요']\n",
      "Score: 0.053728\n",
      "\n",
      "- 가난 한 자 의 슬픔\n",
      "Source Sentence:  가난 한 자 의 슬픔\n",
      "Model Prediction:  ['나', '를', '더', '나', '봐요']\n",
      "Real:  ['돈', '은', '다시', '들어올', '거', '예요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가난 한 면서 의 슬픔\n",
      "Source Sentence:  가난 한 면서 의 슬픔\n",
      "Model Prediction:  ['나', '를', '더', '나', '봐요']\n",
      "Real:  ['돈', '은', '다시', '들어올', '거', '예요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 부유 한 자 의 슬픔\n",
      "Source Sentence:  부유 한 자 의 슬픔\n",
      "Model Prediction:  ['추억', '이', '되', '겠', '네요']\n",
      "Real:  ['돈', '은', '다시', '들어올', '거', '예요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가난 한 자 , 슬픔\n",
      "Source Sentence:  가난 한 자 , 슬픔\n",
      "Model Prediction:  ['나', '를', '더', '나', '봐요']\n",
      "Real:  ['돈', '은', '다시', '들어올', '거', '예요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가만 없 어도 땀 난다\n",
      "Source Sentence:  가만 없 어도 땀 난다\n",
      "Model Prediction:  ['나', '를', '더', '나', '봐요']\n",
      "Real:  ['땀', '을', '식혀', '주', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가국 없 어도 땀 난다\n",
      "Source Sentence:  가국 없 어도 땀 난다\n",
      "Model Prediction:  ['나', '를', '더', '나', '봐요']\n",
      "Real:  ['땀', '을', '식혀', '주', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가만 있 어도 땀 난다\n",
      "Source Sentence:  가만 있 어도 땀 난다\n",
      "Model Prediction:  ['나', '를', '더', '나', '봐요']\n",
      "Real:  ['땀', '을', '식혀', '주', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가만 없 어도 땀 생긴다\n",
      "Source Sentence:  가만 없 어도 땀 생긴다\n",
      "Model Prediction:  ['나', '를', '더', '나', '봐요']\n",
      "Real:  ['땀', '을', '식혀', '주', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가상현실 화폐 서요 망함\n",
      "Source Sentence:  가상현실 화폐 서요 망함\n",
      "Model Prediction:  ['나', '를', '더', '나', '봐요']\n",
      "Real:  ['어서', '잊', '고', '새', '출발', '하', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가상현실 화폐 대리국 망함\n",
      "Source Sentence:  가상현실 화폐 대리국 망함\n",
      "Model Prediction:  ['나', '를', '더', '나', '봐요']\n",
      "Real:  ['어서', '잊', '고', '새', '출발', '하', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가상현실 화폐 서요 들려줌\n",
      "Source Sentence:  가상현실 화폐 서요 들려줌\n",
      "Model Prediction:  ['나', '를', '더', '나', '봐요']\n",
      "Real:  ['어서', '잊', '고', '새', '출발', '하', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가상현실 통화 서요 망함\n",
      "Source Sentence:  가상현실 통화 서요 망함\n",
      "Model Prediction:  ['나', '를', '더', '나', '봐요']\n",
      "Real:  ['어서', '잊', '고', '새', '출발', '하', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 냉각재 불 켜 고 갔 어\n",
      "Source Sentence:  냉각재 불 켜 고 갔 어\n",
      "Model Prediction:  ['만나', '길', '바라', '요']\n",
      "Real:  ['빨리', '집', '에', '돌아가', '서', '끄', '고', '나오', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 냉각재 불 켜 고 나갔 어\n",
      "Source Sentence:  냉각재 불 켜 고 나갔 어\n",
      "Model Prediction:  ['만나', '길', '바라', '요']\n",
      "Real:  ['빨리', '집', '에', '돌아가', '서', '끄', '고', '나오', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 냉각재 불 당겨 고 갔 어\n",
      "Source Sentence:  냉각재 불 당겨 고 갔 어\n",
      "Model Prediction:  ['만나', '길', '바라', '요']\n",
      "Real:  ['빨리', '집', '에', '돌아가', '서', '끄', '고', '나오', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 냉각수 불 켜 고 갔 어\n",
      "Source Sentence:  냉각수 불 켜 고 갔 어\n",
      "Model Prediction:  ['만나', '길', '바라', '요']\n",
      "Real:  ['빨리', '집', '에', '돌아가', '서', '끄', '고', '나오', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가스 성 켜 놓 는데 나온 건가 같 아\n",
      "Source Sentence:  가스 성 켜 놓 는데 나온 건가 같 아\n",
      "Model Prediction:  ['나', '를', '더', '나', '봐요']\n",
      "Real:  ['빨리', '집', '에', '돌아가', '서', '끄', '고', '나오', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가스 성 켜 놓 는데 나타난 건가 같 아\n",
      "Source Sentence:  가스 성 켜 놓 는데 나타난 건가 같 아\n",
      "Model Prediction:  ['나', '를', '더', '나', '봐요']\n",
      "Real:  ['빨리', '집', '에', '돌아가', '서', '끄', '고', '나오', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가스 성 당겨 놓 는데 나온 건가 같 아\n",
      "Source Sentence:  가스 성 당겨 놓 는데 나온 건가 같 아\n",
      "Model Prediction:  ['나', '를', '더', '나', '봐요']\n",
      "Real:  ['빨리', '집', '에', '돌아가', '서', '끄', '고', '나오', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가스 성 켜 늘어놓 는데 나온 건가 같 아\n",
      "Source Sentence:  가스 성 켜 늘어놓 는데 나온 건가 같 아\n",
      "Model Prediction:  ['나', '를', '더', '나', '봐요']\n",
      "Real:  ['빨리', '집', '에', '돌아가', '서', '끄', '고', '나오', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 냉각수 비 너무 많이 올라왔 는데\n",
      "Source Sentence:  냉각수 비 너무 많이 올라왔 는데\n",
      "Model Prediction:  ['만나', '길', '바라', '요']\n",
      "Real:  ['다음', '달', '에', '는', '더', '절약', '해봐요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 냉각수 비 너무 많이 나왔 는데\n",
      "Source Sentence:  냉각수 비 너무 많이 나왔 는데\n",
      "Model Prediction:  ['만나', '길', '바라', '요']\n",
      "Real:  ['다음', '달', '에', '는', '더', '절약', '해봐요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 냉각수 비 너무 많이 올라왔 지만\n",
      "Source Sentence:  냉각수 비 너무 많이 올라왔 지만\n",
      "Model Prediction:  ['만나', '길', '바라', '요']\n",
      "Real:  ['다음', '달', '에', '는', '더', '절약', '해봐요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 냉각수 비 너무 잘 올라왔 는데\n",
      "Source Sentence:  냉각수 비 너무 잘 올라왔 는데\n",
      "Model Prediction:  ['만나', '길', '바라', '요']\n",
      "Real:  ['다음', '달', '에', '는', '더', '절약', '해봐요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 냉각수 침습 비싼데 감기 걸렸 겠 어\n",
      "Source Sentence:  냉각수 침습 비싼데 감기 걸렸 겠 어\n",
      "Model Prediction:  ['만나', '길', '바라', '요']\n",
      "Real:  ['따뜻', '하', '게', '사세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 냉각수 비가역 비싼데 감기 걸렸 겠 어\n",
      "Source Sentence:  냉각수 비가역 비싼데 감기 걸렸 겠 어\n",
      "Model Prediction:  ['만나', '길', '바라', '요']\n",
      "Real:  ['따뜻', '하', '게', '사세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 냉각수 침습 비싼데 감기 걸렸 겠 어서\n",
      "Source Sentence:  냉각수 침습 비싼데 감기 걸렸 겠 어서\n",
      "Model Prediction:  ['만나', '길', '바라', '요']\n",
      "Real:  ['따뜻', '하', '게', '사세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 냉각수 침습 비싼데 감기 걸렸 셨 어\n",
      "Source Sentence:  냉각수 침습 비싼데 감기 걸렸 셨 어\n",
      "Model Prediction:  ['만나', '길', '바라', '요']\n",
      "Real:  ['따뜻', '하', '게', '사세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 냉각수 침습 장난 임\n",
      "Source Sentence:  냉각수 침습 장난 임\n",
      "Model Prediction:  ['만나', '길', '바라', '요']\n",
      "Real:  ['다음', '달', '에', '는', '더', '절약', '해봐요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 냉각재 침습 장난 임\n",
      "Source Sentence:  냉각재 침습 장난 임\n",
      "Model Prediction:  ['만나', '길', '바라', '요']\n",
      "Real:  ['다음', '달', '에', '는', '더', '절약', '해봐요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 냉각수 침습 장난 아님\n",
      "Source Sentence:  냉각수 침습 장난 아님\n",
      "Model Prediction:  ['만나', '길', '바라', '요']\n",
      "Real:  ['다음', '달', '에', '는', '더', '절약', '해봐요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 냉각수 침습 농담 임\n",
      "Source Sentence:  냉각수 침습 농담 임\n",
      "Model Prediction:  ['만나', '길', '바라', '요']\n",
      "Real:  ['다음', '달', '에', '는', '더', '절약', '해봐요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가족 여행 은 기 로서 했 어\n",
      "Source Sentence:  가족 여행 은 기 로서 했 어\n",
      "Model Prediction:  ['나', '를', '더', '나', '봐요']\n",
      "Real:  ['온', '가족', '이', '모두', '마음', '에', '드', '는', '곳', '으로', '가보세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가족 항해 은 기 로서 했 어\n",
      "Source Sentence:  가족 항해 은 기 로서 했 어\n",
      "Model Prediction:  ['나', '를', '더', '나', '봐요']\n",
      "Real:  ['온', '가족', '이', '모두', '마음', '에', '드', '는', '곳', '으로', '가보세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가족 여행 은 고자 로서 했 어\n",
      "Source Sentence:  가족 여행 은 고자 로서 했 어\n",
      "Model Prediction:  ['나', '를', '더', '나', '봐요']\n",
      "Real:  ['온', '가족', '이', '모두', '마음', '에', '드', '는', '곳', '으로', '가보세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가족 여행 은 기 로서 했 어서\n",
      "Source Sentence:  가족 여행 은 기 로서 했 어서\n",
      "Model Prediction:  ['나', '를', '더', '나', '봐요']\n",
      "Real:  ['온', '가족', '이', '모두', '마음', '에', '드', '는', '곳', '으로', '가보세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 친지 여행 고고\n",
      "Source Sentence:  친지 여행 고고\n",
      "Model Prediction:  ['썸', '사이', '사이', '에서', '말', '고', '싶', '은', '거', '같', '아요']\n",
      "Real:  ['온', '가족', '이', '모두', '마음', '에', '드', '는', '곳', '으로', '가보세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 친지 항해 고고\n",
      "Source Sentence:  친지 항해 고고\n",
      "Model Prediction:  ['썸', '사이', '사이', '에서', '말', '고', '싶', '은', '거', '같', '아요']\n",
      "Real:  ['온', '가족', '이', '모두', '마음', '에', '드', '는', '곳', '으로', '가보세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 친지 여행 다용\n",
      "Source Sentence:  친지 여행 다용\n",
      "Model Prediction:  ['썸', '사이', '사이', '에서', '말', '고', '싶', '은', '거', '같', '아요']\n",
      "Real:  ['온', '가족', '이', '모두', '마음', '에', '드', '는', '곳', '으로', '가보세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 주변인 여행 고고\n",
      "Source Sentence:  주변인 여행 고고\n",
      "Model Prediction:  ['그', '사람', '을', '생각', '해', '보', '세요']\n",
      "Real:  ['온', '가족', '이', '모두', '마음', '에', '드', '는', '곳', '으로', '가보세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 친지 여행 어디 로서 갖\n",
      "Source Sentence:  친지 여행 어디 로서 갖\n",
      "Model Prediction:  ['썸', '사이', '사이', '에서', '말', '고', '싶', '은', '거', '같', '아요']\n",
      "Real:  ['온', '가족', '이', '모두', '마음', '에', '드', '는', '곳', '으로', '가보세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 친지 여행 언제 로서 갖\n",
      "Source Sentence:  친지 여행 언제 로서 갖\n",
      "Model Prediction:  ['썸', '사이', '사이', '에서', '말', '고', '싶', '은', '거', '같', '아요']\n",
      "Real:  ['온', '가족', '이', '모두', '마음', '에', '드', '는', '곳', '으로', '가보세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 주변인 여행 어디 로서 갖\n",
      "Source Sentence:  주변인 여행 어디 로서 갖\n",
      "Model Prediction:  ['그', '사람', '을', '생각', '해', '보', '세요']\n",
      "Real:  ['온', '가족', '이', '모두', '마음', '에', '드', '는', '곳', '으로', '가보세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 친지 항해 어디 로서 갖\n",
      "Source Sentence:  친지 항해 어디 로서 갖\n",
      "Model Prediction:  ['썸', '사이', '사이', '에서', '말', '고', '싶', '은', '거', '같', '아요']\n",
      "Real:  ['온', '가족', '이', '모두', '마음', '에', '드', '는', '곳', '으로', '가보세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 친지 끼리 여행 간다\n",
      "Source Sentence:  친지 끼리 여행 간다\n",
      "Model Prediction:  ['썸', '사이', '사이', '에서', '말', '고', '싶', '은', '거', '같', '아요']\n",
      "Real:  ['더', '가까워질', '기회', '가', '되', '겠', '네요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 친지 서로 여행 간다\n",
      "Source Sentence:  친지 서로 여행 간다\n",
      "Model Prediction:  ['썸', '사이', '사이', '에서', '말', '고', '싶', '은', '거', '같', '아요']\n",
      "Real:  ['더', '가까워질', '기회', '가', '되', '겠', '네요']\n",
      "Score: 0.000000\n",
      "\n",
      "Num of Sample: 100\n",
      "Total Score: 0.0027706248913574975\n"
     ]
    }
   ],
   "source": [
    "score = eval_bleu(transformer, src_sentences, tgt_sentences, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e30535",
   "metadata": {},
   "source": [
    "### t1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc2655c",
   "metadata": {},
   "source": [
    "- n_layers: 2\n",
    "- d_model: 512\n",
    "- n_heads: 8\n",
    "- d_ff: 2048\n",
    "- dropout: 0.3\n",
    "- batch_size: 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "a235de18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 지루 하 다 놀 러 가 고 싶 어\n",
      "> 시기 가 다를 뿐 이 에요\n",
      "\n",
      "- 오늘 일찍 일어났 더니 피곤 하 다\n",
      "> 그 분 이 네요\n",
      "\n",
      "- 간만에 여자 친구 랑 데이트 하 기 로 했 어\n",
      "> 생각나 적 으로 도 적 되 는 게 도 적 는지 이상 할 적 이 에요\n",
      "\n",
      "- 집 에 있 는다는 소리야\n",
      "> 내 집 마련 축하 드려요\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for question in test_questions:\n",
    "    result = translate(\" \".join(question), transformer, tokenizer)\n",
    "    print(f\"> {result}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "d805a09b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f70cb28bc02747aca7835de993635deb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 오후 돌이\n",
      "Source Sentence:  오후 돌이\n",
      "Model Prediction:  ['그', '분', '이', '네요']\n",
      "Real:  ['하루', '가', '또', '가', '네요']\n",
      "Score: 0.062571\n",
      "\n",
      "- 오후 순이\n",
      "Source Sentence:  오후 순이\n",
      "Model Prediction:  ['그', '분', '이', '네요']\n",
      "Real:  ['하루', '가', '또', '가', '네요']\n",
      "Score: 0.062571\n",
      "\n",
      "- 오전 돌이\n",
      "Source Sentence:  오전 돌이\n",
      "Model Prediction:  ['그', '분', '이', '네요']\n",
      "Real:  ['하루', '가', '또', '가', '네요']\n",
      "Score: 0.062571\n",
      "\n",
      "- 캐스터 여학교 떨어졌 어서\n",
      "Source Sentence:  캐스터 여학교 떨어졌 어서\n",
      "Model Prediction:  ['근처', '산', '에', '가보세요']\n",
      "Real:  ['위로', '해', '드립니다']\n",
      "Score: 0.000000\n",
      "\n",
      "- 캐스터 여학교 떨어졌 어\n",
      "Source Sentence:  캐스터 여학교 떨어졌 어\n",
      "Model Prediction:  ['근처', '산', '에', '가보세요']\n",
      "Real:  ['위로', '해', '드립니다']\n",
      "Score: 0.000000\n",
      "\n",
      "- 캐스터 소학교 떨어졌 어서\n",
      "Source Sentence:  캐스터 소학교 떨어졌 어서\n",
      "Model Prediction:  ['근처', '산', '에', '가보세요']\n",
      "Real:  ['위로', '해', '드립니다']\n",
      "Score: 0.000000\n",
      "\n",
      "- 캐스터 여학교 올라갔 어서\n",
      "Source Sentence:  캐스터 여학교 올라갔 어서\n",
      "Model Prediction:  ['근처', '산', '에', '가보세요']\n",
      "Real:  ['위로', '해', '드립니다']\n",
      "Score: 0.000000\n",
      "\n",
      "- 윤 월 놀 러 이 는데 싶 는데\n",
      "Source Sentence:  윤 월 놀 러 이 는데 싶 는데\n",
      "Model Prediction:  ['은', '은', '은', '은', '은', '은', '은', '은', '알', '수', '없', '어요']\n",
      "Real:  ['여행', '은', '언제나', '좋', '죠']\n",
      "Score: 0.017033\n",
      "\n",
      "- 윤 월 놀 니 이 는데 싶 는데\n",
      "Source Sentence:  윤 월 놀 니 이 는데 싶 는데\n",
      "Model Prediction:  ['은', '은', '은', '은', '은', '은', '은', '은', '알', '수', '없', '어요']\n",
      "Real:  ['여행', '은', '언제나', '좋', '죠']\n",
      "Score: 0.017033\n",
      "\n",
      "- 윤 월 놀 러 이 는데 싫 는데\n",
      "Source Sentence:  윤 월 놀 러 이 는데 싫 는데\n",
      "Model Prediction:  ['은', '은', '은', '은', '은', '은', '은', '은', '알', '수', '없', '어요']\n",
      "Real:  ['여행', '은', '언제나', '좋', '죠']\n",
      "Score: 0.017033\n",
      "\n",
      "- 윤 월 놀 러 은 는데 싶 는데\n",
      "Source Sentence:  윤 월 놀 러 은 는데 싶 는데\n",
      "Model Prediction:  ['은', '은', '은', '은', '은', '은', '은', '은', '알', '수', '없', '어요']\n",
      "Real:  ['여행', '은', '언제나', '좋', '죠']\n",
      "Score: 0.017033\n",
      "\n",
      "- 김 월 만큼 놀 거든 이 지만 싶 지만\n",
      "Source Sentence:  김 월 만큼 놀 거든 이 지만 싶 지만\n",
      "Model Prediction:  ['이제', '더', '다면', '신뢰', '을', '가', '있', '을', '거', '예요']\n",
      "Real:  ['여행', '은', '언제나', '좋', '죠']\n",
      "Score: 0.000000\n",
      "\n",
      "- 김 월 만큼 놀 거든 은 지만 싶 지만\n",
      "Source Sentence:  김 월 만큼 놀 거든 은 지만 싶 지만\n",
      "Model Prediction:  ['이제', '더', '다면', '신뢰', '을', '가', '있', '을', '거', '예요']\n",
      "Real:  ['여행', '은', '언제나', '좋', '죠']\n",
      "Score: 0.000000\n",
      "\n",
      "- 김 월 만큼 울 거든 이 지만 싶 지만\n",
      "Source Sentence:  김 월 만큼 울 거든 이 지만 싶 지만\n",
      "Model Prediction:  ['이제', '더', '다면', '신뢰', '을', '가', '있', '을', '거', '예요']\n",
      "Real:  ['여행', '은', '언제나', '좋', '죠']\n",
      "Score: 0.000000\n",
      "\n",
      "- 윤 월 만큼 놀 거든 이 지만 싶 지만\n",
      "Source Sentence:  윤 월 만큼 놀 거든 이 지만 싶 지만\n",
      "Model Prediction:  ['은', '은', '은', '은', '은', '은', '은', '은', '알', '수', '없', '어요']\n",
      "Real:  ['여행', '은', '언제나', '좋', '죠']\n",
      "Score: 0.017033\n",
      "\n",
      "- ppl 약하 다섯\n",
      "Source Sentence:  ppl 약하 다섯\n",
      "Model Prediction:  ['잘', '모르', '겠', '지요']\n",
      "Real:  ['눈살', '이', '찌푸려', '지', '죠']\n",
      "Score: 0.000000\n",
      "\n",
      "- ppl 강하 다섯\n",
      "Source Sentence:  ppl 강하 다섯\n",
      "Model Prediction:  ['잘', '모르', '겠', '지요']\n",
      "Real:  ['눈살', '이', '찌푸려', '지', '죠']\n",
      "Score: 0.000000\n",
      "\n",
      "- ppl 약하 여섯\n",
      "Source Sentence:  ppl 약하 여섯\n",
      "Model Prediction:  ['잘', '모르', '겠', '지요']\n",
      "Real:  ['눈살', '이', '찌푸려', '지', '죠']\n",
      "Score: 0.000000\n",
      "\n",
      "- cp 단말 아름다웠 어\n",
      "Source Sentence:  cp 단말 아름다웠 어\n",
      "Model Prediction:  ['자신', '만', '의', '자신']\n",
      "Real:  ['다시', '새로', '사', '는', '게', '마음', '편해요']\n",
      "Score: 0.000000\n",
      "\n",
      "- perl 단말 아름다웠 어\n",
      "Source Sentence:  perl 단말 아름다웠 어\n",
      "Model Prediction:  ['잘', '모르', '겠', '지요']\n",
      "Real:  ['다시', '새로', '사', '는', '게', '마음', '편해요']\n",
      "Score: 0.000000\n",
      "\n",
      "- cp 단말 기뻐했 어\n",
      "Source Sentence:  cp 단말 기뻐했 어\n",
      "Model Prediction:  ['자신', '만', '의', '자신']\n",
      "Real:  ['다시', '새로', '사', '는', '게', '마음', '편해요']\n",
      "Score: 0.000000\n",
      "\n",
      "- cp 모뎀 아름다웠 어\n",
      "Source Sentence:  cp 모뎀 아름다웠 어\n",
      "Model Prediction:  ['자신', '만', '의', '자신']\n",
      "Real:  ['다시', '새로', '사', '는', '게', '마음', '편해요']\n",
      "Score: 0.000000\n",
      "\n",
      "- perl 모뎀 앞 됐으며\n",
      "Source Sentence:  perl 모뎀 앞 됐으며\n",
      "Model Prediction:  ['잘', '모르', '겠', '지요']\n",
      "Real:  ['다시', '새로', '사', '는', '게', '마음', '편해요']\n",
      "Score: 0.000000\n",
      "\n",
      "- perl 모뎀 앞 됐으나\n",
      "Source Sentence:  perl 모뎀 앞 됐으나\n",
      "Model Prediction:  ['잘', '모르', '겠', '지요']\n",
      "Real:  ['다시', '새로', '사', '는', '게', '마음', '편해요']\n",
      "Score: 0.000000\n",
      "\n",
      "- perl 모뎀 옆 됐으며\n",
      "Source Sentence:  perl 모뎀 옆 됐으며\n",
      "Model Prediction:  ['잘', '모르', '겠', '지요']\n",
      "Real:  ['다시', '새로', '사', '는', '게', '마음', '편해요']\n",
      "Score: 0.000000\n",
      "\n",
      "- cp 모뎀 앞 됐으며\n",
      "Source Sentence:  cp 모뎀 앞 됐으며\n",
      "Model Prediction:  ['자신', '만', '의', '자신']\n",
      "Real:  ['다시', '새로', '사', '는', '게', '마음', '편해요']\n",
      "Score: 0.000000\n",
      "\n",
      "- casework 주저앉 팔 정말로 옆 하 당치\n",
      "Source Sentence:  casework 주저앉 팔 정말로 옆 하 당치\n",
      "Model Prediction:  ['자신', '만', '의', '자신']\n",
      "Real:  ['잘', '모르', '고', '있', '을', '수', '도', '있', '어요']\n",
      "Score: 0.000000\n",
      "\n",
      "- casework 주저앉 빨 정말로 옆 하 당치\n",
      "Source Sentence:  casework 주저앉 빨 정말로 옆 하 당치\n",
      "Model Prediction:  ['자신', '만', '의', '자신']\n",
      "Real:  ['잘', '모르', '고', '있', '을', '수', '도', '있', '어요']\n",
      "Score: 0.000000\n",
      "\n",
      "- casework 주저앉 팔 정말로 옆 시키 당치\n",
      "Source Sentence:  casework 주저앉 팔 정말로 옆 시키 당치\n",
      "Model Prediction:  ['자신', '만', '의', '자신']\n",
      "Real:  ['잘', '모르', '고', '있', '을', '수', '도', '있', '어요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 케이스워크 주저앉 팔 정말로 옆 하 당치\n",
      "Source Sentence:  케이스워크 주저앉 팔 정말로 옆 하 당치\n",
      "Model Prediction:  ['충분히', '충분히', '충분히', '충분히', '충분히', '충분히', '충분히', '아름다워요']\n",
      "Real:  ['잘', '모르', '고', '있', '을', '수', '도', '있', '어요']\n",
      "Score: 0.000000\n",
      "\n",
      "- sns 분 절약 , 거 아 는데 아침 꾀하 은 중\n",
      "Source Sentence:  sns 분 절약 , 거 아 는데 아침 꾀하 은 중\n",
      "Model Prediction:  ['잘', '모르', '겠', '지요']\n",
      "Real:  ['시간', '을', '정하', '고', '해', '보', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- sns 분 절약 , 거 아 지만 아침 꾀하 은 중\n",
      "Source Sentence:  sns 분 절약 , 거 아 지만 아침 꾀하 은 중\n",
      "Model Prediction:  ['잘', '모르', '겠', '지요']\n",
      "Real:  ['시간', '을', '정하', '고', '해', '보', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- sns 초간 절약 , 거 아 는데 아침 꾀하 은 중\n",
      "Source Sentence:  sns 초간 절약 , 거 아 는데 아침 꾀하 은 중\n",
      "Model Prediction:  ['잘', '모르', '겠', '지요']\n",
      "Real:  ['시간', '을', '정하', '고', '해', '보', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- sns 분 절약 , 거 아 는데 아침 시키 은 중\n",
      "Source Sentence:  sns 분 절약 , 거 아 는데 아침 시키 은 중\n",
      "Model Prediction:  ['잘', '모르', '겠', '지요']\n",
      "Real:  ['시간', '을', '정하', '고', '해', '보', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 케이스워크 시간 조달 라면 혹시 알아채 게끔 이루어짐\n",
      "Source Sentence:  케이스워크 시간 조달 라면 혹시 알아채 게끔 이루어짐\n",
      "Model Prediction:  ['충분히', '충분히', '충분히', '충분히', '충분히', '충분히', '충분히', '아름다워요']\n",
      "Real:  ['시간', '을', '정하', '고', '해', '보', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 케이스워크 시간 조달 라면 누가 알아채 게끔 이루어짐\n",
      "Source Sentence:  케이스워크 시간 조달 라면 누가 알아채 게끔 이루어짐\n",
      "Model Prediction:  ['충분히', '충분히', '충분히', '충분히', '충분히', '충분히', '충분히', '아름다워요']\n",
      "Real:  ['시간', '을', '정하', '고', '해', '보', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 케이스워크 시간 조달 라면 혹시 알아채 게끔 들어옴\n",
      "Source Sentence:  케이스워크 시간 조달 라면 혹시 알아채 게끔 들어옴\n",
      "Model Prediction:  ['충분히', '충분히', '충분히', '충분히', '충분히', '충분히', '충분히', '아름다워요']\n",
      "Real:  ['시간', '을', '정하', '고', '해', '보', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 케이스워크 분 조달 라면 혹시 알아채 게끔 이루어짐\n",
      "Source Sentence:  케이스워크 분 조달 라면 혹시 알아채 게끔 이루어짐\n",
      "Model Prediction:  ['충분히', '충분히', '충분히', '충분히', '충분히', '충분히', '충분히', '아름다워요']\n",
      "Real:  ['시간', '을', '정하', '고', '해', '보', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 케이스워크 보 면 나 만 때리 는데 다 행복 해 보여\n",
      "Source Sentence:  케이스워크 보 면 나 만 때리 는데 다 행복 해 보여\n",
      "Model Prediction:  ['충분히', '충분히', '충분히', '충분히', '충분히', '충분히', '충분히', '아름다워요']\n",
      "Real:  ['자랑', '하', '는', '자리', '니까요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 케이스워크 보 면 나 만 걷어차 는데 다 행복 해 보여\n",
      "Source Sentence:  케이스워크 보 면 나 만 걷어차 는데 다 행복 해 보여\n",
      "Model Prediction:  ['충분히', '충분히', '충분히', '충분히', '충분히', '충분히', '충분히', '아름다워요']\n",
      "Real:  ['자랑', '하', '는', '자리', '니까요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 케이스워크 보 면 나 만 때리 는데 다 행복 해서 보여\n",
      "Source Sentence:  케이스워크 보 면 나 만 때리 는데 다 행복 해서 보여\n",
      "Model Prediction:  ['충분히', '충분히', '충분히', '충분히', '충분히', '충분히', '충분히', '아름다워요']\n",
      "Real:  ['자랑', '하', '는', '자리', '니까요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 케이스워크 보 면 나 만 때리 는데 는데 행복 해 보여\n",
      "Source Sentence:  케이스워크 보 면 나 만 때리 는데 는데 행복 해 보여\n",
      "Model Prediction:  ['충분히', '충분히', '충분히', '충분히', '충분히', '충분히', '충분히', '아름다워요']\n",
      "Real:  ['자랑', '하', '는', '자리', '니까요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가끔 의아 해\n",
      "Source Sentence:  가끔 의아 해\n",
      "Model Prediction:  ['저', '요']\n",
      "Real:  ['그', '사람', '도', '그럴', '거', '예요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 이따금 의아 해\n",
      "Source Sentence:  이따금 의아 해\n",
      "Model Prediction:  ['알', '수', '없', '는', '게', '사랑', '이', '에요']\n",
      "Real:  ['그', '사람', '도', '그럴', '거', '예요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가끔 흡족 해\n",
      "Source Sentence:  가끔 흡족 해\n",
      "Model Prediction:  ['저', '요']\n",
      "Real:  ['그', '사람', '도', '그럴', '거', '예요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가끔 의아 해서\n",
      "Source Sentence:  가끔 의아 해서\n",
      "Model Prediction:  ['저', '요']\n",
      "Real:  ['그', '사람', '도', '그럴', '거', '예요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가끔 뭐 꾀하 는지 의아 해\n",
      "Source Sentence:  가끔 뭐 꾀하 는지 의아 해\n",
      "Model Prediction:  ['저', '요']\n",
      "Real:  ['그', '사람', '도', '그럴', '거', '예요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가끔 어쩌 꾀하 는지 의아 해\n",
      "Source Sentence:  가끔 어쩌 꾀하 는지 의아 해\n",
      "Model Prediction:  ['저', '요']\n",
      "Real:  ['그', '사람', '도', '그럴', '거', '예요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가끔 뭐 시키 는지 의아 해\n",
      "Source Sentence:  가끔 뭐 시키 는지 의아 해\n",
      "Model Prediction:  ['저', '요']\n",
      "Real:  ['그', '사람', '도', '그럴', '거', '예요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가끔 뭐 꾀하 는가 의아 해\n",
      "Source Sentence:  가끔 뭐 꾀하 는가 의아 해\n",
      "Model Prediction:  ['저', '요']\n",
      "Real:  ['그', '사람', '도', '그럴', '거', '예요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가끔 은 혼자 의 게 좋 다\n",
      "Source Sentence:  가끔 은 혼자 의 게 좋 다\n",
      "Model Prediction:  ['저', '요']\n",
      "Real:  ['혼자', '를', '즐기', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가끔 은 혼자 의 도록 좋 다\n",
      "Source Sentence:  가끔 은 혼자 의 도록 좋 다\n",
      "Model Prediction:  ['저', '요']\n",
      "Real:  ['혼자', '를', '즐기', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가끔 은 거기 의 게 좋 다\n",
      "Source Sentence:  가끔 은 거기 의 게 좋 다\n",
      "Model Prediction:  ['저', '요']\n",
      "Real:  ['혼자', '를', '즐기', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가끔 은 혼자 의 게 좋 는데\n",
      "Source Sentence:  가끔 은 혼자 의 게 좋 는데\n",
      "Model Prediction:  ['저', '요']\n",
      "Real:  ['혼자', '를', '즐기', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가난 한 자 의 슬픔\n",
      "Source Sentence:  가난 한 자 의 슬픔\n",
      "Model Prediction:  ['저', '요']\n",
      "Real:  ['돈', '은', '다시', '들어올', '거', '예요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가난 한 면서 의 슬픔\n",
      "Source Sentence:  가난 한 면서 의 슬픔\n",
      "Model Prediction:  ['저', '요']\n",
      "Real:  ['돈', '은', '다시', '들어올', '거', '예요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 부유 한 자 의 슬픔\n",
      "Source Sentence:  부유 한 자 의 슬픔\n",
      "Model Prediction:  ['이제', '최선', '의', '선택', '일거', '예요']\n",
      "Real:  ['돈', '은', '다시', '들어올', '거', '예요']\n",
      "Score: 0.040825\n",
      "\n",
      "- 가난 한 자 , 슬픔\n",
      "Source Sentence:  가난 한 자 , 슬픔\n",
      "Model Prediction:  ['저', '요']\n",
      "Real:  ['돈', '은', '다시', '들어올', '거', '예요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가만 없 어도 땀 난다\n",
      "Source Sentence:  가만 없 어도 땀 난다\n",
      "Model Prediction:  ['저', '요']\n",
      "Real:  ['땀', '을', '식혀', '주', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가국 없 어도 땀 난다\n",
      "Source Sentence:  가국 없 어도 땀 난다\n",
      "Model Prediction:  ['저', '요']\n",
      "Real:  ['땀', '을', '식혀', '주', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가만 있 어도 땀 난다\n",
      "Source Sentence:  가만 있 어도 땀 난다\n",
      "Model Prediction:  ['저', '요']\n",
      "Real:  ['땀', '을', '식혀', '주', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가만 없 어도 땀 생긴다\n",
      "Source Sentence:  가만 없 어도 땀 생긴다\n",
      "Model Prediction:  ['저', '요']\n",
      "Real:  ['땀', '을', '식혀', '주', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가상현실 화폐 서요 망함\n",
      "Source Sentence:  가상현실 화폐 서요 망함\n",
      "Model Prediction:  ['저', '요']\n",
      "Real:  ['어서', '잊', '고', '새', '출발', '하', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가상현실 화폐 대리국 망함\n",
      "Source Sentence:  가상현실 화폐 대리국 망함\n",
      "Model Prediction:  ['저', '요']\n",
      "Real:  ['어서', '잊', '고', '새', '출발', '하', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가상현실 화폐 서요 들려줌\n",
      "Source Sentence:  가상현실 화폐 서요 들려줌\n",
      "Model Prediction:  ['저', '요']\n",
      "Real:  ['어서', '잊', '고', '새', '출발', '하', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가상현실 통화 서요 망함\n",
      "Source Sentence:  가상현실 통화 서요 망함\n",
      "Model Prediction:  ['저', '요']\n",
      "Real:  ['어서', '잊', '고', '새', '출발', '하', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 냉각재 불 켜 고 갔 어\n",
      "Source Sentence:  냉각재 불 켜 고 갔 어\n",
      "Model Prediction:  ['잘', '모르', '겠', '지요']\n",
      "Real:  ['빨리', '집', '에', '돌아가', '서', '끄', '고', '나오', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 냉각재 불 켜 고 나갔 어\n",
      "Source Sentence:  냉각재 불 켜 고 나갔 어\n",
      "Model Prediction:  ['잘', '모르', '겠', '지요']\n",
      "Real:  ['빨리', '집', '에', '돌아가', '서', '끄', '고', '나오', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 냉각재 불 당겨 고 갔 어\n",
      "Source Sentence:  냉각재 불 당겨 고 갔 어\n",
      "Model Prediction:  ['잘', '모르', '겠', '지요']\n",
      "Real:  ['빨리', '집', '에', '돌아가', '서', '끄', '고', '나오', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 냉각수 불 켜 고 갔 어\n",
      "Source Sentence:  냉각수 불 켜 고 갔 어\n",
      "Model Prediction:  ['잘', '모르', '겠', '지요']\n",
      "Real:  ['빨리', '집', '에', '돌아가', '서', '끄', '고', '나오', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가스 성 켜 놓 는데 나온 건가 같 아\n",
      "Source Sentence:  가스 성 켜 놓 는데 나온 건가 같 아\n",
      "Model Prediction:  ['저', '요']\n",
      "Real:  ['빨리', '집', '에', '돌아가', '서', '끄', '고', '나오', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가스 성 켜 놓 는데 나타난 건가 같 아\n",
      "Source Sentence:  가스 성 켜 놓 는데 나타난 건가 같 아\n",
      "Model Prediction:  ['저', '요']\n",
      "Real:  ['빨리', '집', '에', '돌아가', '서', '끄', '고', '나오', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가스 성 당겨 놓 는데 나온 건가 같 아\n",
      "Source Sentence:  가스 성 당겨 놓 는데 나온 건가 같 아\n",
      "Model Prediction:  ['저', '요']\n",
      "Real:  ['빨리', '집', '에', '돌아가', '서', '끄', '고', '나오', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가스 성 켜 늘어놓 는데 나온 건가 같 아\n",
      "Source Sentence:  가스 성 켜 늘어놓 는데 나온 건가 같 아\n",
      "Model Prediction:  ['저', '요']\n",
      "Real:  ['빨리', '집', '에', '돌아가', '서', '끄', '고', '나오', '세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 냉각수 비 너무 많이 올라왔 는데\n",
      "Source Sentence:  냉각수 비 너무 많이 올라왔 는데\n",
      "Model Prediction:  ['잘', '모르', '겠', '지요']\n",
      "Real:  ['다음', '달', '에', '는', '더', '절약', '해봐요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 냉각수 비 너무 많이 나왔 는데\n",
      "Source Sentence:  냉각수 비 너무 많이 나왔 는데\n",
      "Model Prediction:  ['잘', '모르', '겠', '지요']\n",
      "Real:  ['다음', '달', '에', '는', '더', '절약', '해봐요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 냉각수 비 너무 많이 올라왔 지만\n",
      "Source Sentence:  냉각수 비 너무 많이 올라왔 지만\n",
      "Model Prediction:  ['잘', '모르', '겠', '지요']\n",
      "Real:  ['다음', '달', '에', '는', '더', '절약', '해봐요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 냉각수 비 너무 잘 올라왔 는데\n",
      "Source Sentence:  냉각수 비 너무 잘 올라왔 는데\n",
      "Model Prediction:  ['잘', '모르', '겠', '지요']\n",
      "Real:  ['다음', '달', '에', '는', '더', '절약', '해봐요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 냉각수 침습 비싼데 감기 걸렸 겠 어\n",
      "Source Sentence:  냉각수 침습 비싼데 감기 걸렸 겠 어\n",
      "Model Prediction:  ['잘', '모르', '겠', '지요']\n",
      "Real:  ['따뜻', '하', '게', '사세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 냉각수 비가역 비싼데 감기 걸렸 겠 어\n",
      "Source Sentence:  냉각수 비가역 비싼데 감기 걸렸 겠 어\n",
      "Model Prediction:  ['잘', '모르', '겠', '지요']\n",
      "Real:  ['따뜻', '하', '게', '사세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 냉각수 침습 비싼데 감기 걸렸 겠 어서\n",
      "Source Sentence:  냉각수 침습 비싼데 감기 걸렸 겠 어서\n",
      "Model Prediction:  ['잘', '모르', '겠', '지요']\n",
      "Real:  ['따뜻', '하', '게', '사세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 냉각수 침습 비싼데 감기 걸렸 셨 어\n",
      "Source Sentence:  냉각수 침습 비싼데 감기 걸렸 셨 어\n",
      "Model Prediction:  ['잘', '모르', '겠', '지요']\n",
      "Real:  ['따뜻', '하', '게', '사세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 냉각수 침습 장난 임\n",
      "Source Sentence:  냉각수 침습 장난 임\n",
      "Model Prediction:  ['잘', '모르', '겠', '지요']\n",
      "Real:  ['다음', '달', '에', '는', '더', '절약', '해봐요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 냉각재 침습 장난 임\n",
      "Source Sentence:  냉각재 침습 장난 임\n",
      "Model Prediction:  ['잘', '모르', '겠', '지요']\n",
      "Real:  ['다음', '달', '에', '는', '더', '절약', '해봐요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 냉각수 침습 장난 아님\n",
      "Source Sentence:  냉각수 침습 장난 아님\n",
      "Model Prediction:  ['잘', '모르', '겠', '지요']\n",
      "Real:  ['다음', '달', '에', '는', '더', '절약', '해봐요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 냉각수 침습 농담 임\n",
      "Source Sentence:  냉각수 침습 농담 임\n",
      "Model Prediction:  ['잘', '모르', '겠', '지요']\n",
      "Real:  ['다음', '달', '에', '는', '더', '절약', '해봐요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가족 여행 은 기 로서 했 어\n",
      "Source Sentence:  가족 여행 은 기 로서 했 어\n",
      "Model Prediction:  ['저', '요']\n",
      "Real:  ['온', '가족', '이', '모두', '마음', '에', '드', '는', '곳', '으로', '가보세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가족 항해 은 기 로서 했 어\n",
      "Source Sentence:  가족 항해 은 기 로서 했 어\n",
      "Model Prediction:  ['저', '요']\n",
      "Real:  ['온', '가족', '이', '모두', '마음', '에', '드', '는', '곳', '으로', '가보세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가족 여행 은 고자 로서 했 어\n",
      "Source Sentence:  가족 여행 은 고자 로서 했 어\n",
      "Model Prediction:  ['저', '요']\n",
      "Real:  ['온', '가족', '이', '모두', '마음', '에', '드', '는', '곳', '으로', '가보세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 가족 여행 은 기 로서 했 어서\n",
      "Source Sentence:  가족 여행 은 기 로서 했 어서\n",
      "Model Prediction:  ['저', '요']\n",
      "Real:  ['온', '가족', '이', '모두', '마음', '에', '드', '는', '곳', '으로', '가보세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 친지 여행 고고\n",
      "Source Sentence:  친지 여행 고고\n",
      "Model Prediction:  ['보', '세요']\n",
      "Real:  ['온', '가족', '이', '모두', '마음', '에', '드', '는', '곳', '으로', '가보세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 친지 항해 고고\n",
      "Source Sentence:  친지 항해 고고\n",
      "Model Prediction:  ['보', '세요']\n",
      "Real:  ['온', '가족', '이', '모두', '마음', '에', '드', '는', '곳', '으로', '가보세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 친지 여행 다용\n",
      "Source Sentence:  친지 여행 다용\n",
      "Model Prediction:  ['보', '세요']\n",
      "Real:  ['온', '가족', '이', '모두', '마음', '에', '드', '는', '곳', '으로', '가보세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 주변인 여행 고고\n",
      "Source Sentence:  주변인 여행 고고\n",
      "Model Prediction:  ['소주', '한', '잔']\n",
      "Real:  ['온', '가족', '이', '모두', '마음', '에', '드', '는', '곳', '으로', '가보세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 친지 여행 어디 로서 갖\n",
      "Source Sentence:  친지 여행 어디 로서 갖\n",
      "Model Prediction:  ['보', '세요']\n",
      "Real:  ['온', '가족', '이', '모두', '마음', '에', '드', '는', '곳', '으로', '가보세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 친지 여행 언제 로서 갖\n",
      "Source Sentence:  친지 여행 언제 로서 갖\n",
      "Model Prediction:  ['보', '세요']\n",
      "Real:  ['온', '가족', '이', '모두', '마음', '에', '드', '는', '곳', '으로', '가보세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 주변인 여행 어디 로서 갖\n",
      "Source Sentence:  주변인 여행 어디 로서 갖\n",
      "Model Prediction:  ['소주', '한', '잔']\n",
      "Real:  ['온', '가족', '이', '모두', '마음', '에', '드', '는', '곳', '으로', '가보세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 친지 항해 어디 로서 갖\n",
      "Source Sentence:  친지 항해 어디 로서 갖\n",
      "Model Prediction:  ['보', '세요']\n",
      "Real:  ['온', '가족', '이', '모두', '마음', '에', '드', '는', '곳', '으로', '가보세요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 친지 끼리 여행 간다\n",
      "Source Sentence:  친지 끼리 여행 간다\n",
      "Model Prediction:  ['보', '세요']\n",
      "Real:  ['더', '가까워질', '기회', '가', '되', '겠', '네요']\n",
      "Score: 0.000000\n",
      "\n",
      "- 친지 서로 여행 간다\n",
      "Source Sentence:  친지 서로 여행 간다\n",
      "Model Prediction:  ['보', '세요']\n",
      "Real:  ['더', '가까워질', '기회', '가', '되', '겠', '네요']\n",
      "Score: 0.000000\n",
      "\n",
      "Num of Sample: 100\n",
      "Total Score: 0.0031370396377935735\n"
     ]
    }
   ],
   "source": [
    "score = eval_bleu(transformer, src_sentences, tgt_sentences, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670fa2ca",
   "metadata": {},
   "source": [
    "### t2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db5545e",
   "metadata": {},
   "source": [
    "- n_layers: 2\n",
    "- d_model: 512\n",
    "- n_heads: 8\n",
    "- d_ff: 2048\n",
    "- dropout: 0.3\n",
    "- batch_size: 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "e421360c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 지루 하 다 놀 러 가 고 싶 어\n",
      "> 죠\n",
      "\n",
      "- 오늘 일찍 일어났 더니 피곤 하 다\n",
      "> 따뜻 할 시기 네요\n",
      "\n",
      "- 간만에 여자 친구 랑 데이트 하 기 로 했 어\n",
      "> 헤어짐 은 헤어짐 은 헤어짐 을 좋아하 헤어짐 도 으로 습니다\n",
      "\n",
      "- 집 에 있 는다는 소리야\n",
      "> 조심히 오 세요\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for question in test_questions:\n",
    "    result = translate(\" \".join(question), transformer, tokenizer)\n",
    "    print(f\"> {result}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "3faaa99a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 아 벌 받 고 있 는 건가 네\n",
      "Model Prediction:  수십 번 어야 하나 봅니다\n",
      "Real:  달 게 받 으세요\n",
      "Score: 0.000000\n",
      "\n",
      "- 헤어진지 열흘 됐 는데 연락 하 고 싶 다섯\n",
      "Model Prediction:  서로 에게 부담 없 는 선물 이 좋 아요\n",
      "Real:  후회 하 지 않 는다면 연락 해 보 세요\n",
      "Score: 0.000000\n",
      "\n",
      "- 머리카락 이 정말 빠져\n",
      "Model Prediction:  저 도 그러 그러 그러 그러 그러 그러 그러 는 게 좋 겠 어요\n",
      "Real:  스트레스 받 지 마세요\n",
      "Score: 0.000000\n",
      "\n",
      "- 자율 주행 승용차 나오 겠 지\n",
      "Model Prediction:  기다리 고 말 이 기다리 고 말 고 기다리 고 기다리 고 기다리 세요\n",
      "Real:  가까운 미래 에 나올 거 같 아요\n",
      "Score: 0.000000\n",
      "\n",
      "- 죽 고 못 사 는 관계\n",
      "Model Prediction:  나쁜 생각 멈추 나쁜 나쁜 나쁜 생각 멈추 세요\n",
      "Real:  연애 할 때 가능 하 죠\n",
      "Score: 0.000000\n",
      "\n",
      "- 졸업식 에 가 도 된 나\n",
      "Model Prediction:  잠 을 깨 요 기운 내요\n",
      "Real:  졸업식 에 가 서 축하 해 주 세요\n",
      "Score: 0.000000\n",
      "\n",
      "- 공허 하 네\n",
      "Model Prediction:  죠\n",
      "Real:  제 가 채워줄 게요\n",
      "Score: 0.000000\n",
      "\n",
      "- 여지 를 준 짝 녀 버려야 겠죠\n",
      "Model Prediction:  잘 견뎌 내 상대방 이 에요\n",
      "Real:  오해 가 아니 라면 정리 하 는 게 덜 상처 일 것 같 아요\n",
      "Score: 0.000000\n",
      "\n",
      "- 농사 짓 고 다른가\n",
      "Model Prediction:  서로 에게 부담 없 는 선물 이 좋 아요\n",
      "Real:  생각 하 기 는 쉬운데 실천 하 기 는 어려운 것 같 아요\n",
      "Score: 0.018285\n",
      "\n",
      "- 술 을 마시 러 나갈까 어디 론가 떠나 볼까\n",
      "Model Prediction:  연락 이 후 에 연락 하 는 잔 하 기 좋 죠\n",
      "Real:  어디 든 좋 죠\n",
      "Score: 0.036021\n",
      "\n",
      "- 강우 땜 에 눈 아파\n",
      "Model Prediction:  잊 고 새 출발 하 고 사랑 을 생각 해 보 세요\n",
      "Real:  이쁜 마스크 사 드리 고 싶 네요\n",
      "Score: 0.017033\n",
      "\n",
      "- 너무 가슴 이 조르 네\n",
      "Model Prediction:  죠\n",
      "Real:  무슨 마음 인지 알 겠 어서 더 마음 이 아프 네요\n",
      "Score: 0.000000\n",
      "\n",
      "- 정말 예쁘 고 죽 고 싶 어\n",
      "Model Prediction:  사랑 의 일부 로 이유 를 가 쉬운 일 이 었 을 것 같 아요\n",
      "Real:  당신 은 누구 보다 소중 한 사람 이 에요\n",
      "Score: 0.013218\n",
      "\n",
      "- 좋 아 하 는 사람 도 에 공부 를 못 하 겠 어\n",
      "Model Prediction:  마음 의 정리 가 안 좋 겠 어요\n",
      "Real:  충분히 그럴 수 있 어요\n",
      "Score: 0.027776\n",
      "\n",
      "- 결국 약혼 했 어\n",
      "Model Prediction:  서로 에게 부담 없 는 선물 이 좋 아요\n",
      "Real:  마음 이 더 복잡 하 겠 어요\n",
      "Score: 0.023980\n",
      "\n",
      "- 정말로 돌아올까\n",
      "Model Prediction:  사랑 의 일부 로 이유 를 가 쉬운 일 이 었 을 것 같 아요\n",
      "Real:  돌아오 길 바란다면 연락 해 보 세요\n",
      "Score: 0.000000\n",
      "\n",
      "- 이렇게 가짜 끝 인 걸까\n",
      "Model Prediction:  사랑 이 모두 정답 이 될 거 예요\n",
      "Real:  인연 이 거기 까지 인 가 봐요\n",
      "Score: 0.027776\n",
      "\n",
      "- 먹통 이 야 침울 하 다\n",
      "Model Prediction:  드세요\n",
      "Real:  대화 의 눈높이 가 맞 는 사람 만나 세요\n",
      "Score: 0.000000\n",
      "\n",
      "- 요즘 제정신 이 오로지 야\n",
      "Model Prediction:  좋 죠\n",
      "Real:  그럴 때 가 있 죠\n",
      "Score: 0.033366\n",
      "\n",
      "- 술 이 주꾸미 도 아니 고\n",
      "Model Prediction:  연락 이 후 에 연락 하 는 잔 하 기 좋 죠\n",
      "Real:  술 은 끊 는 게 좋 죠\n",
      "Score: 0.039864\n",
      "\n",
      "- 여자 친구 가 말 를 듣 기 좋 게 해\n",
      "Model Prediction:  잘 견뎌 내 상대방 이 에요\n",
      "Real:  말 도 예쁘 게 하 는 사람 이 네요\n",
      "Score: 0.024762\n",
      "\n",
      "- 여지 를 준 짝 녀 봐야 겠죠\n",
      "Model Prediction:  잘 견뎌 내 상대방 이 에요\n",
      "Real:  오해 가 아니 라면 정리 하 는 게 덜 상처 일 것 같 아요\n",
      "Score: 0.000000\n",
      "\n",
      "- 상사병 극복 하 고 싶 어\n",
      "Model Prediction:  축하 합니다\n",
      "Real:  시간 이 해결 해 줄 거 예요\n",
      "Score: 0.000000\n",
      "\n",
      "- 밥 너무 많이 함\n",
      "Model Prediction:  죠\n",
      "Real:  소분 해서 냉동실 에 보관 해 보 세요\n",
      "Score: 0.000000\n",
      "\n",
      "- 그냥 차단 과 하 지\n",
      "Model Prediction:  좋 아 했 봅니다\n",
      "Real:  스스로 에게 하 는 말 인가요\n",
      "Score: 0.000000\n",
      "\n",
      "- 짝 녀 가 어떻게 하 면 내 확신 을 하 게 할까\n",
      "Model Prediction:  나쁜 생각 멈추 세요\n",
      "Real:  우선 꾸준히 연락 하 고 잘 해 줘 보 세요\n",
      "Score: 0.017927\n",
      "\n",
      "- 사람 이 변하 든\n",
      "Model Prediction:  살 면서 들 이 좋 아 하 앞 으로 살 면서 살 아서 더 좋 겠 네요\n",
      "Real:  사랑 은 변하 고 사람 은 안 변해요\n",
      "Score: 0.000000\n",
      "\n",
      "- 충동 감 이 떨어져 있 는 지금\n",
      "Model Prediction:  말 해 보 세요 생각 해 볼게요\n",
      "Real:  저 도 진짜 힘들 었 는데 지금 은 좋 은 사람 만나 행복 해요\n",
      "Score: 0.000000\n",
      "\n",
      "- 헤어진지 달 반 정도 됬 네\n",
      "Model Prediction:  서로 에게 부담 없 는 선물 이 좋 아요\n",
      "Real:  금방 지나갈 거 예요\n",
      "Score: 0.000000\n",
      "\n",
      "- 집착 같 아서\n",
      "Model Prediction:  조심히 오 세요\n",
      "Real:  차분히 생각 해 보 세요 사랑 은 소유 가 아니 에요\n",
      "Score: 0.007895\n",
      "\n",
      "- 썸 타 는 건가 티 내 고 싶 진 않 아\n",
      "Model Prediction:  짧 으면 짧 을 수록 좋 겠 지요\n",
      "Real:  누구 에게 요\n",
      "Score: 0.000000\n",
      "\n",
      "- 제 외국어 뭐 선택 합니까\n",
      "Model Prediction:  서로 사랑 으로 잊 는 거 같 네요\n",
      "Real:  요즘 은 잘 안 배우 는 언어 도 좋 은 거 같 아요\n",
      "Score: 0.034795\n",
      "\n",
      "- 못하 된 사람\n",
      "Model Prediction:  당신\n",
      "Real:  못 된 사람 은 이제 잊 어 버려요\n",
      "Score: 0.000000\n",
      "\n",
      "- 이별 의 시간\n",
      "Model Prediction:  사랑 이 모두 정답 이 될 거 예요\n",
      "Real:  길 지 않 길 바랄 게요\n",
      "Score: 0.000000\n",
      "\n",
      "- 이런 게 동거 니\n",
      "Model Prediction:  사랑 이 모두 정답 이 될 거 예요\n",
      "Real:  알 다가 도 모르 는 게 연애 같 아요\n",
      "Score: 0.000000\n",
      "\n",
      "- 휴 반년 이 라는 시간 잊 었 다 생각 했 지만 또 다시\n",
      "Model Prediction:  아이구\n",
      "Real:  후폭풍 이 무섭 죠\n",
      "Score: 0.000000\n",
      "\n",
      "- 짝 남 에게 밤 에 자주 산책 하 려고 해도 될까\n",
      "Model Prediction:  나쁜 생각 멈추 세요\n",
      "Real:  밤 데이트 신청 멋지 네요\n",
      "Score: 0.000000\n",
      "\n",
      "- 취업 못 시키 는 기간 이 길 어 진다\n",
      "Model Prediction:  긴 시간 이 겠 어요\n",
      "Real:  다음 공채 때 는 될 거 예요\n",
      "Score: 0.000000\n",
      "\n",
      "- 혼자 썸 타 는 기분 은 야\n",
      "Model Prediction:  조금 만 더 견뎌 받 지 세요\n",
      "Real:  직접 적 이 든 간접 적 이 든 의사 를 확실히 밝혀 보 세요\n",
      "Score: 0.012152\n",
      "\n",
      "- 좋 아 하 은 감정 이 나 를 슬프 게 도 해\n",
      "Model Prediction:  마음 의 정리 가 안 좋 겠 어요\n",
      "Real:  사랑 과 슬픔 은 동전 의 양면 과 같 죠\n",
      "Score: 0.021632\n",
      "\n",
      "- 태 핑 할까\n",
      "Model Prediction:  항상 못 해 본 는 일 이 있 는 것 같 아요\n",
      "Real:  구릿빛 피부 좋 죠\n",
      "Score: 0.000000\n",
      "\n",
      "- 자꾸 뭘 사 게 돼\n",
      "Model Prediction:  기다리 고 말 이 기다리 고 말 고 기다리 고 기다리 고 기다리 세요\n",
      "Real:  마음 이 헛헛 한가 봐요\n",
      "Score: 0.014284\n",
      "\n",
      "- 음식 많이 가리 는 남자 를 사 겨 도 괜찮 습니까\n",
      "Model Prediction:  음\n",
      "Real:  다 먹 으면 좋 겠 지만 큰 문제 는 되 지 않 을 거 예요\n",
      "Score: 0.000000\n",
      "\n",
      "- 뭔 비밀 이 그렇게 높 은지\n",
      "Model Prediction:  긴 시간 이 었 을 수 있 을 거 예요\n",
      "Real:  하나 씩 비밀 을 공유 해 보 세요\n",
      "Score: 0.021105\n",
      "\n",
      "- 구 썸남 보 고 싶 어서\n",
      "Model Prediction:  조급 하 게 생각 하 지 마세요\n",
      "Real:  썸 으로 끝날 사이 가 아니 었 네요\n",
      "Score: 0.000000\n",
      "\n",
      "- 상처 받 고자 싫 다\n",
      "Model Prediction:  축하 합니다\n",
      "Real:  무덤덤 해질 수 있 거예요\n",
      "Score: 0.000000\n",
      "\n",
      "- 현실 적 문제 로 연애 포기 해야 할 듯\n",
      "Model Prediction:  힘들 때 가 있 죠\n",
      "Real:  잠시 쉬 어도 괜찮 아요\n",
      "Score: 0.000000\n",
      "\n",
      "- 메모리 카드 어디 는데 두 었 을까\n",
      "Model Prediction:  한 번 만 더 궁금 한 번 만 더 해요\n",
      "Real:  발 이 달렸 나 봐요\n",
      "Score: 0.000000\n",
      "\n",
      "- 밤 이상 되 면\n",
      "Model Prediction:  내일 은 나 은 하루 이 가 또 데이트 가 나 봐요\n",
      "Real:  생각날 거 예요\n",
      "Score: 0.000000\n",
      "\n",
      "- 화장 이 안 받 다섯\n",
      "Model Prediction:  것 을 아니 라고 하 면서 상처 받 을 것 같 습니다\n",
      "Real:  각질 제거 먼저 하 세요\n",
      "Score: 0.017033\n",
      "\n",
      "- 기력 은 없 어\n",
      "Model Prediction:  잘 견뎌 내 고 있 는 게 아니 었 나 봐요\n",
      "Real:  자신 의 감정 을 주변 사람 들 에게 터놓 고 이야기 해 보 세요\n",
      "Score: 0.014351\n",
      "\n",
      "- 서로 싫어하 는 줄 알 았 는데 짝사랑 이 었 네요\n",
      "Model Prediction:  지금 연락 해 보 세요\n",
      "Real:  안타깝 게 생각 해요\n",
      "Score: 0.000000\n",
      "\n",
      "- 아침 안 잡아먹 는데 자꾸 먹 으라고 그래\n",
      "Model Prediction:  수십 번 어야 하나 봅니다\n",
      "Real:  챙겨 주 고 싶 나 봐요\n",
      "Score: 0.000000\n",
      "\n",
      "- 문자 왔 다는 데 읽 다가 점액 터졌 어\n",
      "Model Prediction:  소원 을 비세 요\n",
      "Real:  마음껏 우세요\n",
      "Score: 0.000000\n",
      "\n",
      "- 여자 친구 가 잠 이 너무 많 아\n",
      "Model Prediction:  잘 견뎌 내 상대방 이 에요\n",
      "Real:  미인 은 잠꾸러기 라던데요\n",
      "Score: 0.000000\n",
      "\n",
      "- 오늘 연락 왔었 어\n",
      "Model Prediction:  따뜻 할 시기 네요\n",
      "Real:  기다리 던 연락 이 었 길 바랍니다\n",
      "Score: 0.000000\n",
      "\n",
      "- 좋 아 하 는 감정 를 혼자 서 정리 할 수 있 을까요\n",
      "Model Prediction:  마음 의 정리 가 안 좋 겠 어요\n",
      "Real:  본인 이 하 기 나름 일 거 예요\n",
      "Score: 0.000000\n",
      "\n",
      "- 괜찮 았었 지만\n",
      "Model Prediction:  서로 에게 부담 없 는 선물 이 좋 아요\n",
      "Real:  울 어도 괜찮 아요\n",
      "Score: 0.023980\n",
      "\n",
      "- 우린 운명 이 었 어\n",
      "Model Prediction:  어떨까 요\n",
      "Real:  운명 이 아니 였 다면 사랑 도 할 수 없 었 겠 지요\n",
      "Score: 0.000000\n",
      "\n",
      "- 헤어짐 이 인생 이 었 으면 좋 겠 어\n",
      "Model Prediction:  서로 에게 부담 없 는 선물 이 좋 아요\n",
      "Real:  현실 을 직시 할 필요 도 있 어요\n",
      "Score: 0.000000\n",
      "\n",
      "- 제 가 집착 하 는 중 은 에요\n",
      "Model Prediction:  서로 사랑 으로 잊 는 거 같 네요\n",
      "Real:  사랑 은 소유 하 는 것 이 아니 랍니다\n",
      "Score: 0.029150\n",
      "\n",
      "- 우리 계속 엇갈림\n",
      "Model Prediction:  어떨까 요\n",
      "Real:  타이밍 이 안 맞 았 나 봐요\n",
      "Score: 0.000000\n",
      "\n",
      "- 남자 들 은 좋 아 하 면 무조건 답장 이 빠른 가요\n",
      "Model Prediction:  잘 견뎌 내 었 나 봐요\n",
      "Real:  답 할 수 있 는 상황 이 면 빠르 죠\n",
      "Score: 0.000000\n",
      "\n",
      "- 이렇게 못 알 아 듣 니\n",
      "Model Prediction:  사랑 이 모두 정답 이 될 거 예요\n",
      "Real:  노력 하 겠 습니다\n",
      "Score: 0.000000\n",
      "\n",
      "- 아프 니까 너무 생각나 고 힘드 네\n",
      "Model Prediction:  수십 번 어야 하나 봅니다\n",
      "Real:  아플 땐 더 약해 지나 봐요\n",
      "Score: 0.000000\n",
      "\n",
      "- 헤어진 여자 친구 가 준 편지 못 버리 겠 어\n",
      "Model Prediction:  서로 에게 부담 없 는 선물 이 좋 아요\n",
      "Real:  마음 에 버리 세요\n",
      "Score: 0.000000\n",
      "\n",
      "- 헤어진 지 주 가 흘렀 네\n",
      "Model Prediction:  서로 에게 부담 없 는 선물 이 좋 아요\n",
      "Real:  어느덧 주 가 흘렀 나 봐요\n",
      "Score: 0.000000\n",
      "\n",
      "- 부드러운 좀 하 지\n",
      "Model Prediction:  습니다 습니다\n",
      "Real:  사람 들 이 중간 을 몰라요\n",
      "Score: 0.000000\n",
      "\n",
      "- 이별 준비 시키 려고\n",
      "Model Prediction:  사랑 이 모두 정답 이 될 거 예요\n",
      "Real:  쉽 지 않 은 결정 이 었 을 텐데 마음 고생 많 았 어요\n",
      "Score: 0.013121\n",
      "\n",
      "- 연인 가 엄청 소심 해\n",
      "Model Prediction:  마음 의 정리 를 하 겠 어요\n",
      "Real:  더 신경 써 주 세요\n",
      "Score: 0.000000\n",
      "\n",
      "- 좋 아 하 는 마음 이 앞 생길 것 같 다고 떠난 여자\n",
      "Model Prediction:  마음 의 정리 가 안 좋 겠 어요\n",
      "Real:  이제 그녀 를 놓아주 세요\n",
      "Score: 0.000000\n",
      "\n",
      "- 자 고 일어나 때문 피곤 해\n",
      "Model Prediction:  기다리 고 말 이 기다리 고 말 고 기다리 고 기다리 고 기다리 세요\n",
      "Real:  요즘 바쁜가 봐요\n",
      "Score: 0.000000\n",
      "\n",
      "- 친구 랑 비교 하 면 내 가 작아져\n",
      "Model Prediction:  잘못 안 좋 은 분 이 만나 세요\n",
      "Real:  당신 은 생각 보다 큰 사람 이 에요\n",
      "Score: 0.033032\n",
      "\n",
      "- 수도 이 얼 었 나 봐\n",
      "Model Prediction:  더 잘 할 수 있 을 거 예요\n",
      "Real:  잘 녹여 보 세요\n",
      "Score: 0.027776\n",
      "\n",
      "- 친구 랑 없 으면 내 가 작아져\n",
      "Model Prediction:  잘못 안 좋 은 분 이 만나 세요\n",
      "Real:  당신 은 생각 보다 큰 사람 이 에요\n",
      "Score: 0.033032\n",
      "\n",
      "- 비오 은 날 뭐 할까\n",
      "Model Prediction:  봅니다\n",
      "Real:  실내 데이트 요\n",
      "Score: 0.000000\n",
      "\n",
      "- 불 그날 뻔 했 어\n",
      "Model Prediction:  그럴 수 있 어요\n",
      "Real:  조심 하 세요\n",
      "Score: 0.000000\n",
      "\n",
      "- 남자 친구 , 틀리 는 맞춤법 이 거슬려\n",
      "Model Prediction:  잘 견뎌 내 었 나 봐요\n",
      "Real:  지적 하 지 말 고 맞 는 걸로 계속 이야기 해 주 세요\n",
      "Score: 0.000000\n",
      "\n",
      "- 매일 매일 눈물 로 보내\n",
      "Model Prediction:  조금 더 라도 더 잘 해 주 세요\n",
      "Real:  울 고 싶 을 때 한껏 울 어 버려요\n",
      "Score: 0.000000\n",
      "\n",
      "- 이 사람 이랑 결혼 이 옳 은 걸까\n",
      "Model Prediction:  사랑 이 모두 정답 이 될 거 예요\n",
      "Real:  결혼 에 는 옳 고 그름 이 없 어요\n",
      "Score: 0.024512\n",
      "\n",
      "- 심심 한데 뭐 시키 면 좋 을까\n",
      "Model Prediction:  모든 날 들 이 있 어요\n",
      "Real:  저 랑 이야기 해요\n",
      "Score: 0.000000\n",
      "\n",
      "- 허전 하 는데\n",
      "Model Prediction:  당신 이 아픈 가요\n",
      "Real:  제 가 채워 드릴게요\n",
      "Score: 0.000000\n",
      "\n",
      "- 수분 크림 바르 고 자 면 나아질 거 니라\n",
      "Model Prediction:  더 잘 할 수 있 을 거 예요\n",
      "Real:  예뻐질 거 예요\n",
      "Score: 0.058739\n",
      "\n",
      "- 월 이 익숙 해 지 지 않 네\n",
      "Model Prediction:  딱 좋 을 때 네요\n",
      "Real:  조금 만 더 힘내 세요\n",
      "Score: 0.000000\n",
      "\n",
      "- 재혼 했 어\n",
      "Model Prediction:  지만 에 대한 지켜보 는 건 취업 에 성공 할 거 예요\n",
      "Real:  좋 겠 어요\n",
      "Score: 0.000000\n",
      "\n",
      "- 전 여자 친구 부친상 다녀왔 어\n",
      "Model Prediction:  잊 고 새 잊 으세요\n",
      "Real:  인간 적 예 를 다 하 셨 네요\n",
      "Score: 0.000000\n",
      "\n",
      "- 어떠 고 있 는 게 잘 하 고 있 는 건지\n",
      "Model Prediction:  조금 더 잘 해 주 는 것 도 좋 을 것 같 아요\n",
      "Real:  충분히 잘 하 고 있 을 거 라 생각 해요\n",
      "Score: 0.018477\n",
      "\n",
      "- 수염 기르 고 싶 다\n",
      "Model Prediction:  더 잘 할 수 있 을 거 예요\n",
      "Real:  지저분 해요\n",
      "Score: 0.000000\n",
      "\n",
      "- 나 잘 살 경우 있 겠 지\n",
      "Model Prediction:  괜찮 아 질 거 예요\n",
      "Real:  지금 보다 더 잘 살 거 예요\n",
      "Score: 0.076163\n",
      "\n",
      "- 이것 또한 받아들이 는 것 이 겠 죠\n",
      "Model Prediction:  사랑 이 모두 정답 이 될 거 예요\n",
      "Real:  받아들여야 할 부분 도 있 을 거 예요\n",
      "Score: 0.058739\n",
      "\n",
      "- 내 가 원 하 는 사람 이 되 기 어려워\n",
      "Model Prediction:  자신 있 다면 만나 세요\n",
      "Real:  다른 사람 들 이 원 하 는 내 가 되 는 건 어려워요\n",
      "Score: 0.000000\n",
      "\n",
      "- 얼 어 죽 는 주\n",
      "Model Prediction:  남 의 눈 을 의식 하 는 사람 은 남 을 거 예요\n",
      "Real:  감기 조심 하 세요\n",
      "Score: 0.015537\n",
      "\n",
      "- 잡담 할 시간 있 어서\n",
      "Model Prediction:  잡 잡 용기 가 잡 잡 잡 잡 아 보 세요\n",
      "Real:  물론 이 죠 무엇 이 든 말씀 하 세요\n",
      "Score: 0.018850\n",
      "\n",
      "- 희생 힘드 네\n",
      "Model Prediction:  서로 에게 부담 없 는 선물 이 좋 아요\n",
      "Real:  힘 들 만 해요\n",
      "Score: 0.000000\n",
      "\n",
      "- 혼영 해야지\n",
      "Model Prediction:  조금 만 더 견뎌 받 지 세요\n",
      "Real:  편하 고 좋 죠\n",
      "Score: 0.000000\n",
      "\n",
      "- 누가 딴 여자 를 만나 고 싶 다는 생각 이 든다면\n",
      "Model Prediction:  저 는 기 는 힘들 어요\n",
      "Real:  정신 차리 세요\n",
      "Score: 0.000000\n",
      "\n",
      "- 집안일 해도 해도 끝 은 없 어\n",
      "Model Prediction:  조심히 오 세요\n",
      "Real:  매일 조금 씩 해 보 세요\n",
      "Score: 0.041799\n",
      "\n",
      "- 아침 일찍 일어나 산책 하 고 있 어\n",
      "Model Prediction:  수십 번 어야 하나 봅니다\n",
      "Real:  건강 에 좋 은 습관 이 네요\n",
      "Score: 0.000000\n",
      "\n",
      "- 고민 좀 들 어 줄래\n",
      "Model Prediction:  많 은 시간 이 흘렀 네요\n",
      "Real:  네 말씀 하 세요\n",
      "Score: 0.000000\n",
      "\n",
      "- 전학 원망 된다\n",
      "Model Prediction:  잊 고 새 잊 으세요\n",
      "Real:  걱정 하 지 마세요 잘 할 거 예요\n",
      "Score: 0.000000\n",
      "\n",
      "Num of Sample: 100\n",
      "Total Score: 0.008961625084588757\n"
     ]
    }
   ],
   "source": [
    "score = eval_bleu(transformer, src_sentences, tgt_sentences, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36788587",
   "metadata": {},
   "source": [
    "### t3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4e2bde",
   "metadata": {},
   "source": [
    "- n_layers: 2\n",
    "- d_model: 512\n",
    "- n_heads: 8\n",
    "- d_ff: 2048\n",
    "- dropout: 0.3\n",
    "- batch_size: 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "3fc74760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 지루 하 다 놀 러 가 고 싶 어\n",
      "> 누구 에게 요\n",
      "\n",
      "- 오늘 일찍 일어났 더니 피곤 하 다\n",
      "> 기다리 고 있 나 봐요\n",
      "\n",
      "- 간만에 여자 친구 랑 데이트 하 기 로 했 어\n",
      "> 직접 적 이 든 간접 적 이 든 의사 를 확실히 밝혀 보 세요\n",
      "\n",
      "- 집 에 있 는다는 소리야\n",
      "> 그냥 신경 쓰 지 마세요\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for question in test_questions:\n",
    "    result = translate(\" \".join(question), transformer, tokenizer)\n",
    "    print(f\"> {result}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "2cba854e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dea3f75a1d8240289eb3e39e506606bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 아 벌 받 고 있 는 건가 네\n",
      "Model Prediction:  수십 번 생각 이 수십 수십 번 마주쳐 보 세요\n",
      "Real:  달 게 받 으세요\n",
      "Score: 0.000000\n",
      "\n",
      "- 헤어진지 열흘 됐 는데 연락 하 고 싶 다섯\n",
      "Model Prediction:  시간 이 지나 면 좋 겠 네요\n",
      "Real:  후회 하 지 않 는다면 연락 해 보 세요\n",
      "Score: 0.000000\n",
      "\n",
      "- 머리카락 이 정말 빠져\n",
      "Model Prediction:  네 말씀 해 주 세요\n",
      "Real:  스트레스 받 지 마세요\n",
      "Score: 0.000000\n",
      "\n",
      "- 자율 주행 승용차 나오 겠 지\n",
      "Model Prediction:  기다리 고 있 었 어요\n",
      "Real:  가까운 미래 에 나올 거 같 아요\n",
      "Score: 0.000000\n",
      "\n",
      "- 죽 고 못 사 는 관계\n",
      "Model Prediction:  너무 무리 하 지 마세요\n",
      "Real:  연애 할 때 가능 하 죠\n",
      "Score: 0.043989\n",
      "\n",
      "- 졸업식 에 가 도 된 나\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "required broadcastable shapes [Op:AddV2]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_39/2789742676.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_bleu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_sentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_sentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_39/861136348.py\u001b[0m in \u001b[0;36meval_bleu\u001b[0;34m(model, src_sentences, tgt_sentences, tokenizer, verbose)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_sentences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mtgt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtgt_sentences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_bleu_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_39/1746119813.py\u001b[0m in \u001b[0;36meval_bleu_single\u001b[0;34m(model, src_sentence, tgt_sentence, tokenizer, verbose)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mreference\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtgt_sentence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mcandidate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtranslate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_sentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     score = sentence_bleu([reference], candidate,\n",
      "\u001b[0;32m/tmp/ipykernel_39/2829387780.py\u001b[0m in \u001b[0;36mtranslate\u001b[0;34m(text_tokens, model, tokenizer)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0menc_padding_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcombined_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_padding_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_masks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadded_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         predictions, _, _, _ = model(padded_tokens,\n\u001b[0m\u001b[1;32m     12\u001b[0m                                      \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m                                      \u001b[0menc_padding_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1036\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1037\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_39/316502540.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, enc_in, dec_in, enc_mask, dec_enc_mask, dec_mask)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_enc_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0menc_in\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menc_emb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0mdec_in\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdec_emb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0menc_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_attns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menc_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_39/316502540.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(self, emb, x)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshared_fc\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mout\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0md_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_encoding\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mseq_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mbinary_op_wrapper\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m   1365\u001b[0m         \u001b[0;31m#   r_binary_op_wrapper use different force_same_dtype values.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaybe_promote_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_same_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1368\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m         \u001b[0;31m# Even if dispatching the op failed, the RHS may be a tensor aware\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36m_add_dispatch\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   1698\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1699\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1700\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1702\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36madd_v2\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m    453\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 455\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    456\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6939\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6940\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6941\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6942\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6943\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: required broadcastable shapes [Op:AddV2]"
     ]
    }
   ],
   "source": [
    "score = eval_bleu(transformer, src_sentences, tgt_sentences, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "c0e5d6f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['졸업식', '에', '가', '도', '된', '나']"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_sentences[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "aad99450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- ['졸업식', '에', '가', '도', '된', '나']\n"
     ]
    }
   ],
   "source": [
    "res = translate(src_sentences[5], transformer, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "b13c984a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "축하 해 주 세요\n"
     ]
    }
   ],
   "source": [
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b4a027",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe13d33b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
